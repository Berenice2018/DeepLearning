{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "PySyft Secure DL CIFAR10 with CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/PySyft_Secure_DL_CIFAR10_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvzawttS3MLP",
        "colab_type": "code",
        "outputId": "f5694cd6-8695-4b12-ab80-f34f6fc8b577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 42.5MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 41.8MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 42.2MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 26.3MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 35.3MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/cc/bfd45ea90c178184ee490a404430ccd628d365da01d2761b3ca28e598e7f/python_socketio-4.2.1-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Collecting python-engineio<3.9.0,>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted, websocket-client, zstd, lz4, websockets, msgpack, python-engineio, python-socketio, flask-socketio, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.1 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "ivs8-ENd00Yu",
        "colab_type": "code",
        "outputId": "2b540c11-c819-42d0-db7c-6273e9c30f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0728 15:57:28.478803 139846959867776 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0728 15:57:28.612729 139846959867776 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ts1OWDl500Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize plot\n",
        "def plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(14,6), ncols=2)\n",
        "    ax1.plot(valid_losses, label='Validation loss')\n",
        "    ax1.plot(train_losses, label='Training loss')\n",
        "    ax1.legend(frameon=False)\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    #x_ticks = [x for x in range(0,n_epochs,2)]\n",
        "    #plt.xticks(x_ticks)\n",
        "    \n",
        "    ax2.plot(valid_accuracies, label = 'Validation accuracy')\n",
        "    ax2.legend(frameon=False)\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    \n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "ebvd-gxR00Y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create workers, \n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "ada = sy.VirtualWorker(hook, 'ada')\n",
        "bob = sy.VirtualWorker(hook, 'bob')\n",
        "#cyd = sy.VirtualWorker(hook, 'cyd')\n",
        "\n",
        "client = sy.VirtualWorker(hook, 'client')\n",
        "crypto_provdr = sy.VirtualWorker(hook, 'crypto_provdr') #gives crypto primitives we may need"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AJPFWAdq00Y3",
        "colab_type": "code",
        "outputId": "9742335d-9e48-4a56-f48a-6099a2ec20f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# define the transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5 ), (0.5,0.5,0.5 ))\n",
        "])\n",
        "\n",
        "# load the datasets\n",
        "#fulltrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "fulltrainset = datasets.CIFAR10(root='./CIFAR10_data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR10('~/.pytorch/CIFAR10_data', download=True, train=False, transform=transform)\n",
        "\n",
        "train_size = int(len(fulltrainset)* 0.8)\n",
        "valid_size = len(fulltrainset) - train_size\n",
        "\n",
        "# split the dataset\n",
        "trainset, validationset = torch.utils.data.random_split(fulltrainset, [train_size, valid_size])\n",
        "trainset = trainset.dataset\n",
        "validationset = validationset.dataset\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10_data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 41342302.97it/s]                               \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10_data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 42012797.47it/s]                               \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8lWlrhm500Y6",
        "colab_type": "code",
        "outputId": "70c0dc57-1fe4-4d42-cf47-8913b683061b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we assume that the server has access to some data to first train its model\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# The client has some data and gets predictions on it using the server's model. \n",
        "# The client encrypts its data by sharing it additively across the workers ada, bob, cyd.\n",
        "valid_loader = torch.utils.data.DataLoader(validationset, batch_size=64, shuffle=True)\n",
        "\n",
        "private_valid_loader = []\n",
        "for data, target in valid_loader:\n",
        "    private_valid_loader.append(\n",
        "        (data.fix_precision().share(ada, bob, crypto_provider=crypto_provdr),\n",
        "        target.fix_precision().share(ada, bob, crypto_provider=crypto_provdr)\n",
        "        ))\n",
        "\n",
        "    \n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=64, shuffle=True)\n",
        "\n",
        "len_trainloader = len(train_loader)\n",
        "len_validloader = len(valid_loader)\n",
        "print('len_trainloader= {}, len_validloader={}'.format(len_trainloader, len_validloader))\n",
        "\n",
        "# Let's check that our trainloader returns a pointer to a batch, and that transformations are applied\n",
        "#data, labels = next(iter(train_loader))\n",
        "#data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len_trainloader= 782, len_validloader=782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyfojvT500Y9",
        "colab_type": "text"
      },
      "source": [
        "**Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qc5Gl8cU00Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # F.log_softmax(x, dim=1)\n",
        "    \n",
        "    \n",
        "    # (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "class MyCifarNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCifarNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print('x {}, size {}'.format(x.shape, x.size(0))) # x torch.Size([64, 1, 28, 28]), size 0\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x # F.log_softmax(x, dim=1)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJlP2Y6G00Y_",
        "colab_type": "text"
      },
      "source": [
        "**Functions train, test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_UyCRdO100ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)\n",
        "            \n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader): # <-- now it is a distributed dataset\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(' \\tTrain. Loss: {:.6f}'.format(current_loss))    \n",
        "\n",
        "        # get the loss per batch and accumulate\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        \n",
        "    # calculate the average loss per epoch\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    #print('Epoch: {} \\tTrain. Loss: {:.6f}'.format(epoch, train_loss))    \n",
        "    return train_loss\n",
        "        \n",
        "    #    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3QhvLvDS00ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct/len(test_loader.dataset)\n",
        "    #print('Epoch: {} \\tValid. Loss: {:.6f}'.format(epoch, test_loss))    \n",
        "    return test_loss, accuracy\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AeHYcLD500ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 2\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvZ4qc800ZG",
        "colab_type": "text"
      },
      "source": [
        "**Start the training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cYA4kBVS00ZG",
        "colab_type": "code",
        "outputId": "e943a389-b41b-43f6-cfe2-34b5b0741c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "model = MyCifarNet()\n",
        "model.apply(weights_init_normal)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [5, 10, 14], 0.1)\n",
        "\n",
        "valid_losses = []\n",
        "train_losses = []\n",
        "valid_accuracies = []\n",
        "valid_loss_min = np.Inf\n",
        "    \n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    \n",
        "    # initialize variables to monitor training and validation loss\n",
        "    training_loss = 0.0\n",
        "    training_accuracy = 0.0\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "        \n",
        "    training_loss =  train(args, model, device, train_loader, optimizer, epoch)\n",
        "    validation_loss, validation_accuracy = validate(args, model, device, test_loader)\n",
        "\n",
        "    #if scheduler is not None:\n",
        "      #scheduler.step(validation_loss) # in case of ReduceOnPlateau \n",
        "\n",
        "    ###### print training/validation statistics \n",
        "    # calculate the average loss per epoch\n",
        "    #training_loss = training_loss/len_trainloader\n",
        "    train_losses.append(training_loss)\n",
        "\n",
        "    #validation_loss = validation_loss/len_validloader\n",
        "    valid_losses.append(validation_loss)\n",
        "    #temp_n = loaders[1]\n",
        "\n",
        "    #validation_accuracy = validation_accuracy/len_validloader\n",
        "    valid_accuracies.append(validation_accuracy)\n",
        "\n",
        "    #hour, minute, second = get_time()\n",
        "    print('Epoch: {} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.6f}'.format(\n",
        "              epoch,\n",
        "              training_loss,\n",
        "              validation_loss,\n",
        "              validation_accuracy ))\n",
        "\n",
        "    ###### TODO: save the model if validation loss has decreased\n",
        "    if validation_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased by {:.6f}'.format(validation_loss - valid_loss_min))\n",
        "        #torch.save(model.state_dict(), save_path)\n",
        "        valid_loss_min = validation_loss\n",
        "    \n",
        "##### visualize\n",
        "plot_loss_acc(args.epochs, train_losses, valid_losses, valid_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTrain. Loss: -0.314627 \tValid. Loss: -4.072765 \t Accur.: 10.000000\n",
            "Validation loss decreased by -inf\n",
            "Epoch: 2 \tTrain. Loss: nan \tValid. Loss: nan \t Accur.: 10.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAGoCAYAAADVZM+hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GX2YAaaC00ZK",
        "colab_type": "code",
        "outputId": "b49275b6-4e05-4f88-d635-d315d745c3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# As the server, send the model to the workers holding the data. The weights are not disclosed\n",
        "model.fix_precision().share(ada,bob, crypto_provider=crypto_provdr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py:672: RuntimeWarning: invalid value encountered in greater\n",
            "  np.log2(np.abs(self.clone().detach().numpy()) + 1) + base_fractional > max_precision\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCifarNet(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P3rNjoIK00ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform the encrypted evaluation. The model weights, the data inputs, the prediction and \n",
        "#  the target used for scoring are encrypted!\n",
        "\n",
        "def validate_encrypted(args, model, valid_loader):\n",
        "    model.eval()\n",
        "    n_correct_private = 0\n",
        "    n_total = 0\n",
        "    \n",
        "    with torch.no_grad(): \n",
        "        for data, target in valid_loader:\n",
        "            output = model(data)\n",
        "            prediction = output.argmax(dim=1)\n",
        "            n_correct_private += prediction.eq(target.view_as(prediction)).sum()\n",
        "            n_total += args.test_batch_size\n",
        "            \n",
        "            #decrypt from the server side the final score of the batch items, \n",
        "            # to verify if the predictions were on average good\n",
        "            n_correct = n_correct_private.copy().get().float_precision().long().item()\n",
        "            print('Valid. set: Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "                n_correct, n_total,\n",
        "                100. * n_correct / n_total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jT28-9i700ZO",
        "colab_type": "code",
        "outputId": "5b9ddffd-61e0-46f4-f476-a84542bde3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "validate_encrypted(args, model, private_valid_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3227373c4454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate_encrypted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate_valid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-9ebeeb195c14>\u001b[0m in \u001b[0;36mvalidate_encrypted\u001b[0;34m(args, model, valid_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mn_correct_private\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b6cec7fb6ae9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#print('x {}, size {}'.format(x.shape, x.size(0))) # x torch.Size([64, 1, 28, 28]), size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mnew_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             response = syft.frameworks.torch.hook_args.hook_response(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;31m# Try to get recursively the attributes in cmd = \"<attr1>.<attr2>.<attr3>...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups, padding_mode)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Add a bias if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m# ... And reshape it back to an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"Add two fixed precision tensors together.\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/overload_torch.py\u001b[0m in \u001b[0;36mhook_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/precision.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, _self, other)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"add\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/overload_torch.py\u001b[0m in \u001b[0;36mhook_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, shares, other)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# if someone passes in a constant, we cast it to a tensor, share it and keep the dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             other = (\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrypto_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not a sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7iBiXzPT00ZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(f'objects of ada= {len(ada._objects)}, bob= {len(bob._objects)}')\n",
        "\n",
        "#ada.clear_objects()\n",
        "#bob.clear_objects()\n",
        "#cyd.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}