{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "PySyft Keystone 2 with Secure Training CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/PySyft_Keystone_2_with_Secure_Training_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf9WwGD-uu5Q",
        "colab_type": "text"
      },
      "source": [
        "(notebook copy from Kaggle)\n",
        "\n",
        "**Issues with PySyft: (state of 2019, August 20th)** \n",
        "\n",
        "1.   Unfortunately, PySyft does not support CUDA. https://github.com/OpenMined/PySyft/issues/1893\n",
        "That is why I decided for a simple and small dataset. \n",
        "2.   https://github.com/OpenMined/PySyft/issues/2425\n",
        "3.https://github.com/OpenMined/PySyft/issues/2426 \n",
        "4. \"AttributeError: 'Linear' object has no attribute 'fix_prec'\"\n",
        "https://github.com/OpenMined/PySyft/pull/2364\n",
        "5. Running PySyft code often ends up with an empty AssertionError. It is related to the installation process, because `pip install` could not install succesfully. The current PySyft version does not fit with the current PyTorch, TorchVision versions. \n",
        "6. PySyft currenlty only supports exactly 2 workers, neither more no less. \n",
        "7. We get error messages, when we train with non-linear models, for example while using Convolutional and BatchNorm layers\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA0pO5YODqCl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Data is shared in an encrypted way across multiple end devices via workers\n",
        "```(data.fix_precision().share(ada, bob, crypto_provider= crypto_provdr)```\n",
        "\n",
        "The end device downloads the current model, i.e. the model is shared with the end devices: \n",
        "``` model.fix_precision().share(ada,bob, crypto_provider=crypto_provdr)```\n",
        "\n",
        "\n",
        "The end device improves the model by learning from data on that end device, \n",
        "and then summarizes the changes as a small focused update. \n",
        "\n",
        "It is just this update to the model that is sent to the cloud (secure worker), using encryption, where it is averaged with other updates (coming from end devices) to improve the shared model. \n",
        "\n",
        "All the training data remains on the end devices. The model, the inputs, the model outputs, the weights, etc. will be encrypted as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2SWovhrtGBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "q1DbkeJZxdAq",
        "colab_type": "code",
        "outputId": "1654fbfe-6715-4a73-92bc-fb8025047302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "import os\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 19:48:44.512621 140054480209792 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0827 19:48:44.530401 140054480209792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dbYGqMYoxdAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize plot\n",
        "def plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(14,6), ncols=2)\n",
        "    ax1.plot(valid_losses, label='Validation loss')\n",
        "    ax1.plot(train_losses, label='Training loss')\n",
        "    ax1.legend(frameon=False)\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    #x_ticks = [x for x in range(0,n_epochs,2)]\n",
        "    #plt.xticks(x_ticks)\n",
        "    \n",
        "    ax2.plot(valid_accuracies, label = 'Validation accuracy')\n",
        "    ax2.legend(frameon=False)\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    \n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "hxADDCgNxdAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d830fa2c-69c4-45e2-8ea0-e9fe1f5a816b"
      },
      "source": [
        "# create workers, \n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "ada = sy.VirtualWorker(hook, 'ada')\n",
        "bob = sy.VirtualWorker(hook, 'bob')\n",
        "\n",
        "crypto_provdr = sy.VirtualWorker(hook, 'crypto_provdr') #gives crypto primitives we may need"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 19:48:57.118300 140054480209792 hook.py:102] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WXENc3QoxdAy",
        "colab_type": "code",
        "outputId": "0a0a5ae1-20e9-46f4-b08c-f75c435b05f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# define the transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5 ), (0.5,0.5,0.5 ))\n",
        "])\n",
        "\n",
        "# load the datasets\n",
        "fulltrainset = datasets.CIFAR10(root='./CIFAR10_data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR10('~/.pytorch/CIFAR10_data', download=True, train=False, transform=transform)\n",
        "\n",
        "train_size = int(len(fulltrainset)* 0.8)\n",
        "valid_size = len(fulltrainset) - train_size\n",
        "\n",
        "# split the dataset\n",
        "trainset, validationset = torch.utils.data.random_split(fulltrainset, [train_size, valid_size])\n",
        "trainset = trainset.dataset\n",
        "validationset = validationset.dataset\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10_data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 25740523.05it/s]                               \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/CIFAR10_data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 26959878.12it/s]                               \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "azt73D0ixdA0",
        "colab_type": "code",
        "outputId": "15d3f84c-665b-40d9-c40f-f042e9dea14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "batch_size = 64\n",
        "number_train_items = 640\n",
        "number_valid_items = 256\n",
        "\n",
        "# we assume that the server has access to some data to first train its model\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# The client has some data and gets predictions on it using the server's model. \n",
        "# The client encrypts its data by sharing it additively across the workers ada, bob.\n",
        "valid_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "private_train_loader = []\n",
        "for i, data, target in enumerate(train_loader):\n",
        "  if i < number_train_items / batch_size:\n",
        "    private_train_loader.append(\n",
        "        (data.fix_precision().share(ada, bob, crypto_provider= crypto_provdr),\n",
        "        target.fix_precision().share(ada, bob, crypto_provider=crypto_provdr)\n",
        "        ))\n",
        "    \n",
        "private_valid_loader = []\n",
        "for i, data, target in enumerate(valid_loader):\n",
        "  if i < number_valid_items / batch_size:\n",
        "    private_valid_loader.append(\n",
        "        (data.fix_precision().share(ada, bob, crypto_provider= crypto_provdr),\n",
        "        target.fix_precision().share(ada, bob, crypto_provider=crypto_provdr)\n",
        "        ))\n",
        "\n",
        "    \n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "len_trainloader = len(private_train_loader)\n",
        "len_validloader = len(private_valid_loader)\n",
        "print(len_trainloader)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6afd1e722455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# we assume that the server has access to some data to first train its model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# The client has some data and gets predictions on it using the server's model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63epObo5xdA2",
        "colab_type": "text"
      },
      "source": [
        "**Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ll1P35xoxdA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x # F.log_softmax(x, dim=1) Do not call log_softmax here, it is not supported yet. \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_P1_Ma_xdA4",
        "colab_type": "text"
      },
      "source": [
        "**Functions train, test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jelf7lf7xdA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)\n",
        "            \n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader): # <-- now it is a distributed dataset\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        \n",
        "        #output = F.log_softmax(output)\n",
        "        #loss = F.nll_loss(output, target) # NLLLoss does not work with PySyft encryption\n",
        "        batch_size = output.shape[0]\n",
        "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(' \\tTrain. Loss: {:.6f}'.format(current_loss))    \n",
        "\n",
        "        # get the loss per batch and accumulate\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        \n",
        "    # calculate the average loss per epoch\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    #print('Epoch: {} \\tTrain. Loss: {:.6f}'.format(epoch, train_loss))    \n",
        "    return train_loss\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ULhlb5y8xdA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 32\n",
        "        self.epochs = 2\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "\n",
        "model = Model()\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [3, 10, 14], 0.1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnFlwvaNULeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform the encrypted evaluation. The model weights, the data inputs, the prediction and \n",
        "# the target used for scoring are encrypted!\n",
        "\n",
        "def valid_encrypted(args, model, device, loader, optimizer, epoch):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    valid_loss = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(loader): # <-- now it is a distributed dataset\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        batch_size = output.shape[0]\n",
        "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
        "\n",
        "        # get the loss per batch and accumulate\n",
        "        valid_loss += loss.item()\n",
        "        \n",
        "        \n",
        "    # calculate the average loss per epoch\n",
        "    valid_loss = valid_loss/len(loader)\n",
        "    return valid_loss\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU4-pNJOxdA-",
        "colab_type": "text"
      },
      "source": [
        "**Start the training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bYWWeC3mxdA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "valid_losses = []\n",
        "train_losses = []\n",
        "valid_accuracies = []\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "model = model.fix_precision().share(ada, bob, crypto_provider=crypto_provdr, requires_grad=True)\n",
        "optimizer = optimizer.fix_precision()\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    \n",
        "    # initialize variables to monitor training and validation loss\n",
        "    training_loss = 0.0\n",
        "    training_accuracy = 0.0\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "        \n",
        "    training_loss =  train(args, model, device, private_train_loader, optimizer, epoch)\n",
        "    validation_loss, validation_accuracy = valid_encrypted(args, model, device, private_valid_loader)\n",
        "\n",
        "    #if scheduler is not None:\n",
        "      #scheduler.step(validation_loss) # in case of ReduceOnPlateau \n",
        "\n",
        "    ###### print training/validation statistics \n",
        "    train_losses.append(training_loss)\n",
        "    valid_losses.append(validation_loss)\n",
        "    valid_accuracies.append(validation_accuracy)\n",
        "\n",
        "    #hour, minute, second = get_time()\n",
        "    print('Epoch: {} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.6f}'.format(\n",
        "              epoch,\n",
        "              training_loss,\n",
        "              validation_loss,\n",
        "              validation_accuracy ))\n",
        "\n",
        "    ###### TODO: save the model if validation loss has decreased\n",
        "    if validation_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased by {:.6f}'.format(validation_loss - valid_loss_min))\n",
        "        #torch.save(model.state_dict(), save_path)\n",
        "        valid_loss_min = validation_loss\n",
        "    \n",
        "##### visualize\n",
        "plot_loss_acc(args.epochs, train_losses, valid_losses, valid_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cfLBVlAoxdBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(f'objects of ada= {len(ada._objects)}, bob= {len(bob._objects)}')\n",
        "\n",
        "#ada.clear_objects()\n",
        "#bob.clear_objects()\n",
        "#cyd.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}