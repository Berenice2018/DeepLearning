{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Section_3_Securing_Federated_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "_jZIJJNAlEr-",
        "4MWBTOjXn60s",
        "lbOFEETbtjb6"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/Section_3_Securing_Federated_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsxK3YC6tjaw",
        "colab_type": "text"
      },
      "source": [
        "# Section: Securing Federated Learning\n",
        "\n",
        "- Lesson 1: Trusted Aggregator\n",
        "- Lesson 2: Intro to Additive Secret Sharing\n",
        "- Lesson 3: Intro to Fixed Precision Encoding\n",
        "- Lesson 4: Secret Sharing + Fixed Precision in PySyft\n",
        "- Final Project: Federated Learning wtih Encrypted Gradient Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8OYMmftjax",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Federated Learning with a Trusted Aggregator\n",
        "\n",
        "In the last section, we learned how to train a model on a distributed dataset using Federated Learning. In particular, the last project aggregated gradients directly from one data owner to another. \n",
        "\n",
        "However, while in some cases it could be ideal to do this, what would be even better is to be able to choose a neutral third party to perform the aggregation.\n",
        "\n",
        "As it turns out, we can use the same tools we used previously to accomplish this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7PtF5wItjay",
        "colab_type": "text"
      },
      "source": [
        "# Project: Federated Learning with a Trusted Aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j30Tjq7aw6qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvtvVuBJtjay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install syft\n",
        "\n",
        "!pip install tf-encrypted\n",
        "! URL=\"https://github.com/Berenice2018/PySyft-Bc.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b master --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft-Bc; python setup.py install\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('./PySyft-Bc'))\n",
        "if module_path not in sys.path:\n",
        "     sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHlCFrTufxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install multiprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6x7quYurXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocess import Pool, TimeoutError, cpu_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zszyJgXYtja1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5d0e914f-991a-4ef5-a531-ddce8b1577cb"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import syft as sy\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 14:11:05.855855 140007913944960 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0806 14:11:05.876252 140007913944960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh0SuYiEtja2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "ada = sy.VirtualWorker(hook, 'ada')\n",
        "bob = sy.VirtualWorker(hook, 'bob')\n",
        "secure_worker = sy.VirtualWorker(hook, 'secure_worker')\n",
        "\n",
        "# create data owners\n",
        "bob.add_workers([ada, secure_worker])\n",
        "ada.add_workers([bob, secure_worker])\n",
        "secure_worker.add_workers([ada, bob])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM8KWF1rWHBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions for printing oput training progress data\n",
        "def print_epoch_start_stats(e_start, e_end, current_lr, current_vmin):\n",
        "\n",
        "    print('*** Epoch [{}/{}]: Training with LR [{:.6f}], current VLoss Min [{:.4f}]'.format(\n",
        "    e_start, e_end, current_lr, current_vmin))\n",
        "\n",
        "def print_epoch_end_stats(train_loss, valid_loss, valid_acc, epoch_time):\n",
        "\n",
        "    print('   Train loss: \\t{:.6f}'.format(train_loss))\n",
        "    print('   Valid loss: \\t{:.6f}'.format(valid_loss))\n",
        "    print('   Valid acc: \\t{:.6f}'.format(valid_acc))\n",
        "    print('*** Epoch completed in {:.0f}m {:.0f}s'.format(epoch_time // 60, epoch_time % 60))   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CDxp3VRWYxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper functions\n",
        "import datetime\n",
        "\n",
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "\n",
        "def train_epoch(worker_name, model, \n",
        "                criterion, optimizer, train_on_gpu=False):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()        \n",
        "\n",
        "\n",
        "    ## find the loss and update the model parameters accordingly\n",
        "    for batch_idx, (data, target) in enumerate(fed_train_loader):\n",
        "        # train ada's model\n",
        "        if worker_name is 'ada' and batch_idx < len(fed_train_loader)*0.5:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss = loss.get().data\n",
        "\n",
        "            # get the loss per batch and accumulate\n",
        "            train_loss += current_loss.item()\n",
        "\n",
        "            # get the class, highest probability\n",
        "            probabilities = torch.exp(output)\n",
        "            _, top_class = probabilities.topk(1, dim=1)\n",
        "\n",
        "            # check if the predicted class is correct\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "\n",
        "            #train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            train_accuracy += torch.mean(torch.tensor(equals))\n",
        "        \n",
        "        # train bob's model:\n",
        "        if worker_name is 'bob' and batch_idx > len(fed_train_loader)*0.5:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.requires_grad = True\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss = loss.get().data\n",
        "\n",
        "            # get the loss per batch and accumulate\n",
        "            train_loss += current_loss.item()\n",
        "\n",
        "            # get the class, highest probability\n",
        "            probabilities = torch.exp(output)\n",
        "            _, top_class = probabilities.topk(1, dim=1)\n",
        "\n",
        "            # check if the predicted class is correct\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "\n",
        "            #train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            train_accuracy += torch.mean(torch.tensor(equals))\n",
        "\n",
        "    #print('worker {} train loss= {:.6f}, train acc= {:.6f}'\n",
        "          #.format(worker_name, train_loss, train_accuracy))\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch(worker_name, model, criterion, train_on_gpu=False):\n",
        "    valid_loss = 0.0\n",
        "    valid_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        #for idx, (data, target) in enumerate(adas_train_loader.federated_dataset[worker_name]):\n",
        "        for batch_idx, (data, target) in enumerate(fed_train_loader):\n",
        "            \n",
        "            # train ada's model\n",
        "            if worker_name is 'ada' and batch_idx < len(fed_train_loader)*0.5:\n",
        "                ## update the average validation loss\n",
        "                output = model(data)\n",
        "                loss = criterion(output,target)\n",
        "\n",
        "                current_loss = loss.get().data\n",
        "\n",
        "                # get the loss per batch and accumulate\n",
        "                valid_loss += current_loss.item()\n",
        "\n",
        "                # get the class, highest probability\n",
        "                probabilities = torch.exp(output)\n",
        "                _, top_class = probabilities.topk(1, dim=1)\n",
        "\n",
        "                # check if the predicted class is correct\n",
        "                equals = top_class == target.view(*top_class.shape)\n",
        "                valid_accuracy += torch.mean(torch.tensor(equals))\n",
        "                \n",
        "            if worker_name is 'bob' and batch_idx > len(fed_train_loader)*0.5:\n",
        "                ## update the average validation loss\n",
        "                output = model(data)\n",
        "                loss = criterion(output,target)\n",
        "                current_loss = loss.get().data\n",
        "                \n",
        "                # get the loss per batch and accumulate\n",
        "                valid_loss += current_loss.item()\n",
        "\n",
        "                # get the class, highest probability\n",
        "                probabilities = torch.exp(output)\n",
        "                _, top_class = probabilities.topk(1, dim=1)\n",
        "\n",
        "                # check if the predicted class is correct\n",
        "                equals = top_class == target.view(*top_class.shape)\n",
        "                valid_accuracy += torch.mean(torch.tensor(equals))\n",
        "\n",
        "    print(valid_loss, valid_accuracy)\n",
        "    return valid_loss, valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5sfHXSRXyvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_my_model(n_epochs, workername, model, \n",
        "                   optimizer, criterion, scheduler, use_cuda=False):    \n",
        "    \n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "         # initialize variables to monitor training and validation loss\n",
        "        training_loss = 0.0\n",
        "        training_accuracy = 0.0\n",
        "    \n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        #train_epoch: worker_name, model, dataloader, criterion, optimizer, train_on_gpu=False):\n",
        "        model.train()\n",
        "        training_loss, training_accuracy = train_epoch(\n",
        "            workername, model, criterion, optimizer, use_cuda)\n",
        "    \n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        validation_loss, validation_accuracy = validate_epoch(\n",
        "            workername, model, criterion, use_cuda) #validation_accuracy\n",
        "        \n",
        "        #if scheduler is not None:\n",
        "          #scheduler.step(validation_loss)\n",
        "        \n",
        "        ###### print training/validation statistics \n",
        "        # calculate the average loss per epoch\n",
        "        training_loss = training_loss/len(fed_train_loader)*0.5\n",
        "                \n",
        "        validation_loss =  validation_loss/len(fed_train_loader)*0.5\n",
        "        \n",
        "        validation_accuracy = validation_accuracy/len(fed_train_loader)*0.5\n",
        "        \n",
        "        #hour, minute, second = get_time()\n",
        "        print('Worker {}, Epoch: {} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  workername,\n",
        "                  epoch,\n",
        "                  training_loss,\n",
        "                  validation_loss,\n",
        "                  validation_accuracy \n",
        "        ))\n",
        "      \n",
        "    \n",
        "    return model, training_loss, validation_loss, validation_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87ChfdhWYe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 10)\n",
        "        #self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.fc1(x)\n",
        "        #x = F.relu(x)\n",
        "        #x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 2\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2G-R8uEXfWR",
        "colab_type": "code",
        "outputId": "028f38ef-2318-4153-852b-3c58fc35710e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the datasets\n",
        "\n",
        "ada.clear_objects()\n",
        "bob.clear_objects()\n",
        "secure_worker.clear_objects()\n",
        "\n",
        "# federate\n",
        "fed_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "                          datasets.FashionMNIST('.', train=False, download=True,\n",
        "                                       transform=transforms.Compose([\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize((0.5,), (0.5,))\n",
        "                                       ]))\n",
        "                          .federate((ada, bob)), # distribute the dataset across the workers, it's now a FederatedDataset\n",
        "                          batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "#print(len(bob._objects))\n",
        "print(fed_train_loader.workers)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ada', 'bob']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A05hylERk1Kw",
        "colab_type": "code",
        "outputId": "3c8eb6ac-8acd-4b76-d6d0-d644de77bbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "\n",
        "# instantiate the model\n",
        "model = Model()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "print('Training started at ', get_time())\n",
        "\n",
        "avr_train_losses = []\n",
        "avr_valid_losses = []\n",
        "avr_valid_accuracies = []\n",
        "  \n",
        "for a_iter in range(2):\n",
        "    # send a copy of the current model to Ada and Bob so that each trains on its own dataset.\n",
        "    \n",
        "    bobs_model = model.copy().send(bob)\n",
        "    adas_model = model.copy().send(ada)\n",
        "    \n",
        "    # momentum is not supported by PySyft at the moment\n",
        "    bobs_optim = optim.SGD(params=bobs_model.parameters(), lr=args.lr) \n",
        "    adas_optim = optim.SGD(params=adas_model.parameters(), lr=args.lr)\n",
        "        \n",
        "# train_my_model(n_epochs, loaders, workername, model, optimizer, criterion, scheduler, use_cuda=False):    \n",
        "    #start training of each model\n",
        "    trained_ada, ada_trainloss, ada_validloss, ada_accuracy = train_my_model(\n",
        "        args.epochs, 'ada', adas_model, \n",
        "        adas_optim, criterion, None, use_cuda=False)\n",
        "    \n",
        "    trained_bob, bob_trainloss, bob_validloss, bob_accuracy = train_my_model(\n",
        "        args.epochs, 'bob', bobs_model,\n",
        "        bobs_optim, criterion, None, use_cuda=False)\n",
        "\n",
        "    # append for plots\n",
        "    avr_train_losses.append((ada_trainloss + bob_trainloss) *0.5)\n",
        "    avr_valid_losses.append((ada_validloss + bob_validloss) *0.5)\n",
        "    avr_valid_accuracies.append((ada_accuracy + bob_accuracy) * 0.5)\n",
        "\n",
        "    # Let Ada and Bob send their model to the secure (trusted) server.\n",
        "    adas_model.move(secure_worker)\n",
        "    bobs_model.move(secure_worker)\n",
        "    \n",
        "    #print(model.fc1.weight.data)\n",
        "    # average ada's and bob's trained models together\n",
        "    # then use this to set the values for our global \"model\".\n",
        "    with torch.no_grad():\n",
        "       model.fc1.weight.set_(((adas_model.fc1.weight.data + bobs_model.fc1.weight.data) / 2).get())\n",
        "       model.fc1.bias.set_(((adas_model.fc1.bias.data + bobs_model.fc1.bias.data) / 2).get())\n",
        "\n",
        "\n",
        "      \n",
        "    print('Finished iteration {}'.format(a_iter))\n",
        "    \n",
        "##### visualize\n",
        "#plot_loss_acc(iterations, avr_train_losses, avr_valid_losses, avr_valid_accuracies)\n",
        "  \n",
        "  "
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training started at  (17, 25, 59)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft-Bc/syft/frameworks/torch/hook/hook.py:764: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "402.02957198023796 tensor(nan)\n",
            "Worker ada, Epoch: 0 \tTrain. Loss: 0.503791 \tValid. Loss: 0.642220 \t Accur.: nan\n",
            "910.2596864700317 tensor(nan)\n",
            "Worker ada, Epoch: 1 \tTrain. Loss: 0.953144 \tValid. Loss: 1.454089 \t Accur.: nan\n",
            "496.8485232591629 tensor(nan)\n",
            "Worker bob, Epoch: 0 \tTrain. Loss: 0.583349 \tValid. Loss: 0.793688 \t Accur.: nan\n",
            "1266.5203031301498 tensor(nan)\n",
            "Worker bob, Epoch: 1 \tTrain. Loss: 1.159447 \tValid. Loss: 2.023195 \t Accur.: nan\n",
            "Finished iteration 0\n",
            "644.2435631155968 tensor(nan)\n",
            "Worker ada, Epoch: 0 \tTrain. Loss: 1.088050 \tValid. Loss: 1.029143 \t Accur.: nan\n",
            "520.7973588705063 tensor(nan)\n",
            "Worker ada, Epoch: 1 \tTrain. Loss: 0.732672 \tValid. Loss: 0.831945 \t Accur.: nan\n",
            "706.6598414778709 tensor(nan)\n",
            "Worker bob, Epoch: 0 \tTrain. Loss: 1.220080 \tValid. Loss: 1.128850 \t Accur.: nan\n",
            "967.3924889564514 tensor(nan)\n",
            "Worker bob, Epoch: 1 \tTrain. Loss: 1.121564 \tValid. Loss: 1.545355 \t Accur.: nan\n",
            "Finished iteration 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8gGB1HAWOlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # store code\n",
        "    with torch.no_grad():\n",
        "        gamma = 0.5 # interpolation parameter    \n",
        "        params_ada = ada_scr_ptr.named_parameters()\n",
        "        params_bob = bob_scr_ptr.named_parameters()\n",
        "\n",
        "        dict_params_bob = dict(params_bob)\n",
        "\n",
        "        for name1, param1 in params_ada:\n",
        "            if name1 in dict_params_bob:\n",
        "                dict_params_bob[name1].data.copy_(gamma*param1.data + (1-gamma)* dict_params_bob[name1].data)\n",
        "\n",
        "        model.load_state_dict(dict_params_bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jZIJJNAlEr-",
        "colab_type": "text"
      },
      "source": [
        "### test  version 1 without FederatedDataLoader\n",
        "### it does not use batches !!! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A_IQLW3lChi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ada.clear_objects()\n",
        "bob.clear_objects()\n",
        "secure_worker.clear_objects()\n",
        "\n",
        "# instantiate the model\n",
        "model = Model()\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "# load the datasets\n",
        "# define the transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, ), (0.5, ))\n",
        "])\n",
        "\n",
        "fulltrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        " # split the dataset\n",
        "ada_size = int(len(fulltrainset)* 0.5)\n",
        "bob_size = len(fulltrainset) - ada_size\n",
        "ada_set, bob_set = torch.utils.data.random_split(fulltrainset, [ada_size, bob_size])\n",
        "bob_set = bob_set.dataset\n",
        "\n",
        "bob_data = transform(bob_set.data)\n",
        "\n",
        "bobs_data_ptr = bob_data.send(bob)\n",
        "bobs_target_ptr = bobset.targets.send(bob)\n",
        "\n",
        "print(bobs_data_ptr.copy().get())\n",
        "\n",
        "# send a copy of the current model to Ada and Bob so that each trains on its own dataset.\n",
        "bobs_model = model.copy().send(bob)\n",
        "\n",
        "# momentum is not supported by PySyft at the moment\n",
        "bobs_optim = optim.SGD(params=bobs_model.parameters(), lr=args.lr) \n",
        "\n",
        "## find the loss and update the model parameters accordingly\n",
        "output = bobs_model(bobs_data_ptr)\n",
        "bobs_loss = criterion(output, bobs_target_ptr)\n",
        "bobs_loss.backward()\n",
        "bobs_optim.step()\n",
        "\n",
        "bobs_loss = bobs_loss.get()\n",
        "print(bobs_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MWBTOjXn60s",
        "colab_type": "text"
      },
      "source": [
        "### Test with federated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muUOEv6Tn39Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test  version 2 with FederatedDataLoader\n",
        "ada.clear_objects()\n",
        "bob.clear_objects()\n",
        "secure_worker.clear_objects()\n",
        "\n",
        " #test\n",
        "# instantiate the model\n",
        "model = Model()\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "# load the datasets\n",
        "# federate\n",
        "fed_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "                          datasets.FashionMNIST('.', train=False, download=True,\n",
        "                                       transform=transforms.Compose([\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize((0.5,), (0.5,))\n",
        "                                       ]))\n",
        "                          .federate((ada, bob)), # distribute the dataset across the workers, it's now a FederatedDataset\n",
        "                          batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "#print(len(bob._objects))\n",
        "print(fed_train_loader.workers)\n",
        "\n",
        "adasmodel = model.copy().send(ada)\n",
        "bobsmodel = model.copy().send(bob)\n",
        "\n",
        "print(len(bob._objects), len(ada._objects))\n",
        "\n",
        "# momentum is not supported by PySyft at the moment\n",
        "adas_optim = optim.SGD(params=adasmodel.parameters(), lr=args.lr) \n",
        "bobs_optim = optim.SGD(params=bobsmodel.parameters(), lr=args.lr) \n",
        "\n",
        "## find the loss and update the model parameters accordingly\n",
        "for batch_idx, (data, target) in enumerate(fed_train_loader):\n",
        "    # train ada's model\n",
        "    if  batch_idx < len(fed_train_loader)*0.5:\n",
        "        adas_output = adasmodel(data)\n",
        "        adas_loss = criterion(adas_output, target)\n",
        "        adas_loss.requires_grad = True\n",
        "\n",
        "        adas_loss.backward()\n",
        "        adas_optim.step()\n",
        "\n",
        "        adas_loss = adas_loss.get()\n",
        "        print('adas loss {}'.format(adas_loss))\n",
        "        \n",
        "    # train bob's model\n",
        "    else:\n",
        "        bobs_output = bobsmodel(data)\n",
        "        bobs_loss = criterion(bobs_output, target)\n",
        "        bobs_loss.requires_grad = True\n",
        "\n",
        "        bobs_loss.backward()\n",
        "        bobs_optim.step()\n",
        "\n",
        "        bobs_loss = bobs_loss.get()\n",
        "        print('bobs loss {}'.format(bobs_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OKuMHL3tja9",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Additive Secret Sharing\n",
        "\n",
        "While being able to have a trusted third party to perform the aggregation is certainly nice, in an ideal setting we wouldn't have to trust anyone at all. This is where Cryptography can provide an interesting alterantive. \n",
        "\n",
        "Specifically, we're going to be looking at a simple protocol for Secure Multi-Party Computation called Additive Secret Sharing. This protocol will allow multiple parties (of size 3 or more) to aggregate their gradients without the use of a trusted 3rd party to perform the aggregation. In other words, we can add 3 numbers together from 3 different people without anyone ever learning the inputs of any other actors.\n",
        "\n",
        "Let's start by considering the number 5, which we'll put into a varible x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvxdpGSGtja9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUNll8r4tja_",
        "colab_type": "text"
      },
      "source": [
        "Let's say we wanted to SHARE the ownership of this number between two people, Alice and Bob. We could split this number into two shares, 2, and 3, and give one to Alice and one to Bob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NZrdw-Rtja_",
        "colab_type": "code",
        "outputId": "e1cba700-df3c-4142-b50d-487a86bf1f1f",
        "colab": {}
      },
      "source": [
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXYsj1CdtjbE",
        "colab_type": "text"
      },
      "source": [
        "Note that neither Bob nor Alice know the value of x. They only know the value of their own SHARE of x. Thus, the true value of X is hidden (i.e., encrypted). \n",
        "\n",
        "The truly amazing thing, however, is that Alice and Bob can still compute using this value! They can perform arithmetic over the hidden value! Let's say Bob and Alice wanted to multiply this value by 2! If each of them multiplied their respective share by 2, then the hidden number between them is also multiplied! Check it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpM1845tjbE",
        "colab_type": "code",
        "outputId": "440cbee1-5991-4577-a1de-b7d531b98c0c",
        "colab": {}
      },
      "source": [
        "bob_x_share = 2 * 2\n",
        "alice_x_share = 3 * 2\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bQ1CgCbtjbH",
        "colab_type": "text"
      },
      "source": [
        "This even works for addition between two shared values!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqX4N8UktjbH",
        "colab_type": "code",
        "outputId": "d0747b26-9207-410b-f610-cdda2ef58c51",
        "colab": {}
      },
      "source": [
        "# encrypted \"5\"\n",
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "# encrypted \"7\"\n",
        "bob_y_share = 5\n",
        "alice_y_share = 2\n",
        "\n",
        "# encrypted 5 + 7\n",
        "bob_z_share = bob_x_share + bob_y_share\n",
        "alice_z_share = alice_x_share + alice_y_share\n",
        "\n",
        "decrypted_z = bob_z_share + alice_z_share\n",
        "decrypted_z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_7SDpHBtjbL",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we just added two numbers together while they were still encrypted!!!\n",
        "\n",
        "One small tweak - notice that since all our numbers are positive, it's possible for each share to reveal a little bit of information about the hidden value, namely, it's always greater than the share. Thus, if Bob has a share \"3\" then he knows that the encrypted value is at least 3.\n",
        "\n",
        "This would be quite bad, but can be solved through a simple fix. Decryption happens by summing all the shares together MODULUS some constant. I.e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfiPGKpQtjbM",
        "colab_type": "code",
        "outputId": "8d2942de-aae7-4425-e267-2469748ccf25",
        "colab": {}
      },
      "source": [
        "x = 5\n",
        "\n",
        "Q = 23740629843760239486723\n",
        "\n",
        "bob_x_share = 23552870267 # <- a random number\n",
        "alice_x_share = Q - bob_x_share + x\n",
        "alice_x_share"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23740629843736686616461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE7BXMYVtjbO",
        "colab_type": "code",
        "outputId": "5893df44-b766-46da-c3fa-083e7f6e6850",
        "colab": {}
      },
      "source": [
        "(bob_x_share + alice_x_share) % Q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaFCgmLitjbR",
        "colab_type": "text"
      },
      "source": [
        "So now, as you can see, both shares are wildly larger than the number being shared, meaning that individual shares no longer leak this inforation. However, all the properties we discussed earlier still hold! (addition, encryption, decryption, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw0rWptBtjbS",
        "colab_type": "text"
      },
      "source": [
        "# Project: Build Methods for Encrypt, Decrypt, and Add \n",
        "\n",
        "In this project, you must take the lessons we learned in the last section and write general methods for encrypt, decrypt, and add. Store shares for a variable in a tuple like so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azrQRd4_tjbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_share = (2,5,7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUT1eo9ytjbU",
        "colab_type": "text"
      },
      "source": [
        "Even though normally those shares would be distributed amongst several workers, you can store them in ordered tuples like this for now :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNH5q3tqtjbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!\n",
        "\n",
        "import random\n",
        "\n",
        "Q = 23740629843760239486723\n",
        "\n",
        "def encrypt(x, num_shares=3):\n",
        "  shares = list()\n",
        "  \n",
        "  for i in range(num_shares -1):\n",
        "    shares.append(random.randint(0, Q))\n",
        "    \n",
        "  shares.append(Q - (sum(shares) % Q) + x)\n",
        "  return tuple(shares)\n",
        "\n",
        "\n",
        "\n",
        "def decrypt (shares):\n",
        "  return sum(shares) % Q\n",
        "\n",
        "\n",
        "\n",
        "def add(x, y):\n",
        "  z = list()\n",
        "  for i in range(len(x)):\n",
        "    z.append((x[i] + y[i]) % Q)\n",
        "    \n",
        "  return tuple(z)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NF4rNNVtjbW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd5aa306-c59b-403c-8588-460559a20d97"
      },
      "source": [
        "# test the code\n",
        "\n",
        "my_shares = encrypt(111222333444)\n",
        "my_shares"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17912743069678902165922, 8081878981097731977728, 21486637636855067163240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdZhyz8ctjbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a7106a1-da70-4392-bab9-61fa2491f49a"
      },
      "source": [
        "decrypt(my_shares)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111222333444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDhTxPL-tjbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc64347b-7dba-4e97-ccb8-728e17194226"
      },
      "source": [
        "a = encrypt(111)\n",
        "b = encrypt(222)\n",
        "c = add(a, b)\n",
        "c"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15697646104329093095991, 13138825564471846777692, 18644788018719539100096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnyyPf75tjbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52b223bf-ad0e-4e95-a7ba-3d4e2b8c6061"
      },
      "source": [
        "decrypt(c)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlc4Lk5Otjbf",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Fixed Precision Encoding\n",
        "\n",
        "As you may remember, our goal is to aggregate gradients using this new Secret Sharing technique. However, the protocol we've just explored in the last section uses positive integers. However, our neural network weights are NOT integers. Instead, our weights are decimals (floating point numbers).\n",
        "\n",
        "Not a huge deal! We just need to use a fixed precision encoding, which lets us do computation over decimal numbers using integers!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT30HR8Mtjbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE=10\n",
        "PRECISION=4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGWWGRsptjbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(x):\n",
        "    return int((x * (BASE ** PRECISION)) % Q)\n",
        "\n",
        "def decode(x):\n",
        "    return (x if x <= Q/2 else x - Q) / BASE**PRECISION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RY4F4Bttjbj",
        "colab_type": "code",
        "outputId": "6719c022-a50e-437a-f793-375a77bad1da",
        "colab": {}
      },
      "source": [
        "encode(3.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSX6cZOytjbm",
        "colab_type": "code",
        "outputId": "ece666f0-a9fa-4156-8871-ce81e8a3cc89",
        "colab": {}
      },
      "source": [
        "decode(35000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOW3LAK6tjbo",
        "colab_type": "code",
        "outputId": "e22ecb54-c179-4b4a-882a-b8ea97755342",
        "colab": {}
      },
      "source": [
        "x = encrypt(encode(5.5))\n",
        "y = encrypt(encode(2.3))\n",
        "z = add(x,y)\n",
        "decode(decrypt(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy4wRHf1tjbq",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Secret Sharing + Fixed Precision in PySyft\n",
        "\n",
        "While writing things from scratch is certainly educational, PySyft makes a great deal of this much easier for us through its abstractions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCqD0bvrtjbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = bob.clear_objects()\n",
        "alice = alice.clear_objects()\n",
        "secure_worker = secure_worker.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3xJti6htjbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDmaK1IHtjbu",
        "colab_type": "text"
      },
      "source": [
        "### Secret Sharing Using PySyft\n",
        "\n",
        "We can share using the simple .share() method!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fvl2jTOtjbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBfS54I9tjbw",
        "colab_type": "code",
        "outputId": "f4d8c43d-ac95-4b9a-da9c-a5a262c2ecf8",
        "colab": {}
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{35498656553: tensor([  10235770278698899, 1401398179551373756, 2277280072169145491,\n",
              "          636965538565031298,  913795591610271305])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHssWmeVtjb0",
        "colab_type": "text"
      },
      "source": [
        "and as you can see, Bob now has one of the shares of x! Furthermore, we can still call addition in this state, and PySyft will automatically perform the remote execution for us!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-WwELy-tjb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOrJRJP_tjb2",
        "colab_type": "code",
        "outputId": "de700f19-b78b-486c-bc3e-2508f7a98aff",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:23637986557 -> bob:30254176063]\n",
              "\t-> (Wrapper)>[PointerTensor | me:18229131498 -> alice:75856222543]\n",
              "\t-> (Wrapper)>[PointerTensor | me:34301722959 -> secure_worker:75419815101]\n",
              "\t*crypto provider: me*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaljdUqWtjb4",
        "colab_type": "code",
        "outputId": "f14314cf-c01a-4c3a-c887-3cf266ca2545",
        "colab": {}
      },
      "source": [
        "y.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  6,  8, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbOFEETbtjb6",
        "colab_type": "text"
      },
      "source": [
        "### Fixed Precision using PySyft\n",
        "\n",
        "We can also convert a tensor to fixed precision using .fix_precision()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XepH1Uv1tjb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([0.1,0.2,0.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8joG2ZeYtjb8",
        "colab_type": "code",
        "outputId": "beb01a07-99fd-4d08-f874-d5ecd1f66855",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1000, 0.2000, 0.3000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-N0AirLtjb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.fix_prec()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMshZVZwtjcB",
        "colab_type": "code",
        "outputId": "c437dd03-940d-41aa-eb6d-96569f1dc166",
        "colab": {}
      },
      "source": [
        "x.child.child"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100, 200, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvBuK83ztjcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiXiwppYtjcF",
        "colab_type": "code",
        "outputId": "2a4c02fe-924d-4bc7-81fd-ccb1bb78ac47",
        "colab": {}
      },
      "source": [
        "y = y.float_prec()\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_smEQYRtjcI",
        "colab_type": "text"
      },
      "source": [
        "### Shared Fixed Precision\n",
        "\n",
        "And of course, we can combine the two!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxc1OxHVtjcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([0.1, 0.2, 0.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prPkq0n5tjcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.fix_prec().share(bob, alice, secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwa-wq90tjcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mcOLPhatjcP",
        "colab_type": "code",
        "outputId": "b8abd725-ea88-409e-af20-844b9eea82be",
        "colab": {}
      },
      "source": [
        "y.get().float_prec()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXiAe212tjcR",
        "colab_type": "text"
      },
      "source": [
        "Make sure to make the point that people can see the model averages in the clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF4lnVXltjcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypgAAXCEtjcS",
        "colab_type": "text"
      },
      "source": [
        "# Final Project: Federated Learning with Encrypted Gradient Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwkdyBjrLq0C",
        "colab_type": "text"
      },
      "source": [
        "## See the other notebook here: \n",
        "\n",
        "https://colab.research.google.com/drive/1hDbIS5s8hL6ISd5RTCvhnRPDadt565P0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdXyOvFXtjcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}