{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "PySyft_FashionMNIST_simple.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/PySyft_FashionMNIST-Federated-Learning_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G47OzrDm5lKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXkGUBoscFnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTzDjnD7bXa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-encrypted\n",
        "! URL=\"https://github.com/Berenice2018/PySyft-Bc.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b master --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft-Bc; python setup.py install\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('./PySyft-Bc'))\n",
        "if module_path not in sys.path:\n",
        "     sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "QwfzgfM23mP4",
        "colab_type": "code",
        "outputId": "9b873c61-b287-4f73-9b31-0c9ec6d7412d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 13:27:06.922409 140489880336256 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0725 13:27:06.943093 140489880336256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "l5XImbZc3mP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create workers, \n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "ada = sy.VirtualWorker(hook, 'ada')\n",
        "bob = sy.VirtualWorker(hook, 'bob')\n",
        "cyd = sy.VirtualWorker(hook, 'cyd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vLVEAAfA3mP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_loaders():\n",
        "    print('creating loaders')\n",
        "    # define the transform\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, ), (0.5, ))\n",
        "    ])\n",
        "\n",
        "    # load the datasets\n",
        "    fulltrainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "    testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n",
        "    train_size = int(len(fulltrainset)* 0.8)\n",
        "    valid_size = len(fulltrainset) - train_size\n",
        "\n",
        "    # split the dataset\n",
        "    #trainset, validationset = torch.utils.data.random_split(testset, [train_size, valid_size])\n",
        "    #trainset = trainset.dataset\n",
        "    #validationset = validationset.dataset\n",
        "    \n",
        "    # federate\n",
        "    federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "      datasets.FashionMNIST('.', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5,), (0.5,))\n",
        "                   ]))\n",
        "    .federate((ada, bob, cyd)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=32, shuffle=True)\n",
        "\n",
        "    #federated_valid_loader = sy.FederatedDataLoader(\n",
        "    #    validationset.federate((ada,bob,cyd)), batch_size=32, shuffle=True)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(testset, batch_size=32)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "    \n",
        "    # check that our trainloader returns a pointer to a batch, and that transformations are applied\n",
        "    #data, labels = next(iter(federated_train_loader))\n",
        "    #print(data)\n",
        "    \n",
        "    return federated_train_loader, valid_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Uk9lbh3mQB",
        "colab_type": "text"
      },
      "source": [
        "**Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rf3tKGco3mQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68-ztu2W3mQK",
        "colab_type": "text"
      },
      "source": [
        "**Train and validate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p7wB-ZBj3mQS",
        "colab_type": "code",
        "outputId": "bb592a57-7ad9-4a1f-e092-56c1e6b93167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "\n",
        "# Create the data loaders, federated PySyft loaders are returned\n",
        "fed_train_loader, fed_valid_loader, test_loader = create_loaders()\n",
        "\n",
        "len_train_loader = len(fed_train_loader)\n",
        "len_valid_loader = len(fed_valid_loader)\n",
        "len_train_loader\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating loaders\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff4tIGmbVspk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions for printing oput training progress data\n",
        "def print_epoch_start_stats(e_start, e_end, current_lr, current_vmin):\n",
        "\n",
        "    print('*** Epoch [{}/{}]: Training with LR [{:.6f}], current VLoss Min [{:.4f}]'.format(\n",
        "    e_start, e_end, current_lr, current_vmin))\n",
        "\n",
        "def print_epoch_end_stats(train_loss, valid_loss, valid_acc, epoch_time):\n",
        "\n",
        "    print('   Train loss: \\t{:.6f}'.format(train_loss))\n",
        "    print('   Valid loss: \\t{:.6f}'.format(valid_loss))\n",
        "    print('   Valid acc: \\t{:.6f}'.format(valid_acc))\n",
        "    print('*** Epoch completed in {:.0f}m {:.0f}s'.format(epoch_time // 60, epoch_time % 60))   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s7Hvi6Ik3mQZ",
        "colab_type": "code",
        "outputId": "81814992-ae5f-46ba-e325-b00e2a13dae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "print(f'objects of ada= {len(ada._objects)}, bob= {len(bob._objects)}, cyd= {len(cyd._objects)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "objects of ada= 4, bob= 4, cyd= 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiEvif-sRq_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper functions\n",
        "import datetime\n",
        "\n",
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, train_on_gpu=False):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        # move to GPU\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        model.send(data.location) # send the model to the right location\n",
        "        \n",
        "        ## find the loss and update the model parameters accordingly\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        model.get() # get the model back\n",
        "        current_loss = loss.get()\n",
        "        \n",
        "        # get the loss per batch and accumulate\n",
        "        train_loss += current_loss.item()\n",
        "        \n",
        "        # get the class, highest probability\n",
        "        probabilities = torch.exp(output)\n",
        "        _, top_class = probabilities.topk(1, dim=1)\n",
        "        \n",
        "        # check if the predicted class is correct\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        \n",
        "        #train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        train_accuracy += torch.mean(torch.tensor(equals))\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, train_on_gpu=False):\n",
        "    valid_loss = 0.0\n",
        "    valid_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(dataloader):\n",
        "            # move to GPU\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output,target)\n",
        "            \n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            ps = torch.exp(output)\n",
        "            _ , top_class = ps.topk(1,dim = 1)\n",
        "            #_, top_class = torch.max(ps, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape) # shape is (batch size x 1)\n",
        "            valid_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            \n",
        "            #pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    return valid_loss, valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGTIfJhZkr8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_my_model(n_epochs, loaders, model, optimizer, criterion, scheduler, use_cuda=False):\n",
        "    print('Training started at ', get_time())\n",
        "    \n",
        "    valid_losses = []\n",
        "    train_losses = []\n",
        "    valid_accuracies = []\n",
        "    \n",
        "    \n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "         # initialize variables to monitor training and validation loss\n",
        "        training_loss = 0.0\n",
        "        training_accuracy = 0.0\n",
        "    \n",
        "        #if scheduler is not None:\n",
        "          #scheduler.step()\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        training_loss, training_accuracy = train_epoch(model, loaders[0], criterion, optimizer, use_cuda)\n",
        "    \n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        validation_loss = validate_epoch(model, loaders[1], criterion, use_cuda) #validation_accuracy\n",
        "        \n",
        "        #if scheduler is not None:\n",
        "          #scheduler.step(validation_loss)\n",
        "        \n",
        "        ###### print training/validation statistics \n",
        "        # calculate the average loss per epoch\n",
        "        training_loss = training_loss/len_train_loader\n",
        "        train_losses.append(training_loss)\n",
        "        \n",
        "        training_accuracy = training_accuracy/len_train_loader\n",
        "        \n",
        "        validation_loss = validation_loss/len_valid_loader\n",
        "        valid_losses.append(validation_loss)\n",
        "        \n",
        "        validation_accuracy = validation_accuracy/len_valid_loader\n",
        "        valid_accuracies.append(validation_accuracy)\n",
        "        \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  training_loss,\n",
        "                  #training_accuracy, \n",
        "                  validation_loss,\n",
        "                  validation_accuracy ))\n",
        "        \n",
        "        ###### TODO: save the model if validation loss has decreased\n",
        "        if validation_loss <= valid_loss_min:\n",
        "            '''print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_min,\n",
        "                validation_loss))'''\n",
        "            print('Validation loss decreased by {:.6f}'.format(validation_loss - valid_loss_min))\n",
        "            #torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = validation_loss\n",
        "            \n",
        "            \n",
        "    ##### visualize\n",
        "    #plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "020JH9t5ZSyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model\n",
        "model = Model()\n",
        "\n",
        "\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 2\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 4)\n",
        "criterion = nn.NLLLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JcYqHUIY1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## \n",
        "# start the training\n",
        "###########\n",
        "\n",
        "\n",
        "loaders = [fed_train_loader, fed_valid_loader, test_loader]\n",
        "n_epochs = 2\n",
        "train_my_model(n_epochs, loaders, model, optimizer, criterion, scheduler)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHvTlhxOZcYl",
        "colab_type": "code",
        "outputId": "5432a260-2a44-41a7-a7e4-f71bc5171460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ada.clear_objects()\n",
        "bob.clear_objects()\n",
        "cyd.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:cyd #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}