{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER-squeezenet-berenice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "GcA_vwhUrURY",
        "rj5m7HOg3gHn",
        "ajUS0Xhf4pLc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/FER_squeezenet_berenice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh9XQ8vR84zw",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xdgcVYCJpkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "#!pip install git+https://github.com/pytorch/vision\n",
        "\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torchvision.models as models\n",
        "from torchvision.models.squeezenet import  model_urls\n",
        "squeezenet1_0_state_dict = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "import os,cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#from pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20, 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCJINZX0Kcpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2eaa5e08-76d5-4f2a-e2c7-66d5971c15e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8ynY8-MVOg",
        "colab_type": "code",
        "outputId": "9528d919-3c3a-47cb-d726-577ae996528e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fer= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/fer2013.csv\"\n",
        "ferr= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset\"\n",
        "\n",
        "!ls   '/content/gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.bib  fer2013.csv  PrivateTest  PublicTest  README  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lVhUAPOZa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcA_vwhUrURY",
        "colab_type": "text"
      },
      "source": [
        "### Convert and save images to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5WuBM0VOJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yAg9oU_radg",
        "colab_type": "text"
      },
      "source": [
        "### Load data , image transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvDN0ydqjQ-",
        "colab_type": "code",
        "outputId": "607cccbf-ae0b-480a-f0a0-b291370cdc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "data_dir = \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013\"\n",
        "train_dir = data_dir + '/Training'\n",
        "valid_dir = data_dir + '/PublicTest'\n",
        "test_dir = data_dir + '/PrivateTest'\n",
        "\n",
        "# original img size = 48 x48 px\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        #transforms.CenterCrop(256),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    }\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir,\n",
        "        'test': test_dir}\n",
        "\n",
        "datasets = {x: torchvision.datasets.ImageFolder(dirs[x], transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=7) for x in ['train', 'valid','test']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) \n",
        "                              for x in ['train', 'valid','test']}\n",
        "print(dataset_sizes)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 32556, 'valid': 3589, 'test': 3589}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9fxwj-f-wG",
        "colab_type": "code",
        "outputId": "86ebc428-337c-4192-b606-26a9055cbf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names = datasets['train'].classes\n",
        "print(class_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj5m7HOg3gHn",
        "colab_type": "text"
      },
      "source": [
        "### Show some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9_rLvF03kGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a batch of training images\n",
        "dataiter = iter(dataloaders['train'])\n",
        "images, _ = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy\n",
        "\n",
        "# plot the images of the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 16/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gi4Auz4D_l",
        "colab_type": "text"
      },
      "source": [
        "### Model train helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMm_P_CERmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "    \n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwzo4GzQsAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, name, criteria, optimizer, scheduler = None, epochs=50, device='cuda'):\n",
        "    h, m, s = get_time()\n",
        "    print('starting the training at {}:{}:{}'.format(h, m, s))\n",
        "    since = time.time()\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    # initialize tracker for accuracy \n",
        "    min_loss = np.Inf\n",
        "    TS_loss = pd.DataFrame(np.nan, index = range(1,epochs+1), columns = ['train loss','valid loss'])\n",
        "    TS_acc = pd.DataFrame(np.nan,index = range(1,epochs+1), columns = ['train acc','valid acc'])\n",
        "    \n",
        "    for epoch in range(1, epochs+1):        \n",
        "        # monitor loss/accuracy\n",
        "        train_loss_running = 0.0\n",
        "        valid_loss_running = 0.0\n",
        "        train_acc_running = 0.0\n",
        "        valid_acc_running = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        model.train() # prep model for training\n",
        "        \n",
        "        for data, target in dataloaders['train']:\n",
        "    \n",
        "            # Move input and data tensors to the default device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criteria(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss \n",
        "            train_loss_running += loss.item()*data.size(0)\n",
        "            # accuracy\n",
        "            _, preds = torch.max(output, 1)\n",
        "            train_acc_running  += torch.sum(preds == target.data)\n",
        "    \n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloaders['valid']:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criteria(output, target)\n",
        "                valid_loss_running += loss.item()*data.size(0)\n",
        "                \n",
        "                _, preds = torch.max(output, 1)\n",
        "                valid_acc_running  += torch.sum(preds == target.data)\n",
        "                #print('valid_acc_running {:.6f}'.format(valid_acc_running))\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                #ps = torch.exp(logps)\n",
        "                #top_p, top_class = ps.topk(1, dim=1)\n",
        "                #equals = top_class == labels.view(*top_class.shape)\n",
        "                #valid_loss_running += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        # statistics\n",
        "        train_loss = train_loss_running/ dataset_sizes['train']\n",
        "        valid_loss = valid_loss_running/ dataset_sizes['valid']\n",
        "        train_acc = train_acc_running.double()/ dataset_sizes['train']\n",
        "        valid_acc = valid_acc_running.double()/ dataset_sizes['valid']\n",
        "        \n",
        "        TS_loss.loc[epoch] = [train_loss, valid_loss]\n",
        "        TS_acc.loc[epoch] = [(train_acc.cpu().numpy()), (valid_acc.cpu().numpy())]                                         \n",
        "\n",
        "        # print training/validation statistics \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  train_loss,\n",
        "                  valid_loss,\n",
        "                  valid_acc \n",
        "        ))\n",
        "                                                             \n",
        "        # save model if validation acc has increased\n",
        "        # BC: using the lower validation loss as criterium, when saving a model\n",
        "        if valid_loss <= min_loss:\n",
        "            old_loss_min = min_loss\n",
        "            min_loss = valid_loss\n",
        "            save = True\n",
        "            \n",
        "            print('*** Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            old_loss_min, min_loss))        \n",
        "    \n",
        "    #End\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    #print('Best Valid Acc: {:4f}'.format(best_acc))\n",
        "                                                   \n",
        "    TS_loss.plot(title = 'loss')\n",
        "    TS_acc.plot(title = 'acc')\n",
        "                                                   \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model)\n",
        "    torch.save(model.state_dict(), name)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AGfumpM4Lik",
        "colab_type": "text"
      },
      "source": [
        "### Hyper params, start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeUCHPa_40ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "#model = torch.hub.load('pytorch/vision', 'squeezenet1_0', pretrained=True)\n",
        "\n",
        "no_of_classes = 7\n",
        "transfermodel = models.squeezenet1_0(pretrained =True)\n",
        "\n",
        "for param in transfermodel.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "transfermodel.classifier[1] = nn.Conv2d(512, no_of_classes, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "#transfermodel.apply(weights_init_normal)\n",
        "\n",
        "#transfermodel.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfermodel.to(device);\n",
        "\n",
        "transfermodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hrVk_TkscuM",
        "colab_type": "code",
        "outputId": "e9379b63-c042-483e-9ca6-ac4de810fc32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()    \n",
        "lr = 3e-3 #1e-2 #1e-3\n",
        "optimizer = optim.Adam(transfermodel.parameters(), lr=lr)\n",
        "\n",
        "stepsize = 4\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=stepsize, gamma=0.1)\n",
        "\n",
        "\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname = '{}squeeze1_0-{}-lr{}-{}{}-epo{}.pth'.format(save_path, 'Adam', lr, 'StepLR_', stepsize, epochs)\n",
        "\n",
        "print(modelname)\n",
        "\n",
        "model_ft = train_model(transfermodel, modelname, criteria, optimizer, scheduler, epochs, device)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/squeeze1_0-Adam-lr0.003-StepLR_4-epo15.pth\n",
            "starting the training at 24:33:41\n",
            "Epoch: 1 at 24:36:1 \tTrain. Loss: 1.496034 \tValid. Loss: 1.453339 \t Accur.: 0.4884368905\n",
            "*** Validation loss decreased (inf --> 1.453339).  Saving model ...\n",
            "Epoch: 2 at 24:38:21 \tTrain. Loss: 1.412410 \tValid. Loss: 1.417813 \t Accur.: 0.4814711619\n",
            "*** Validation loss decreased (1.453339 --> 1.417813).  Saving model ...\n",
            "Epoch: 3 at 24:40:41 \tTrain. Loss: 1.393805 \tValid. Loss: 1.429644 \t Accur.: 0.4809139036\n",
            "Epoch: 4 at 24:43:2 \tTrain. Loss: 1.343977 \tValid. Loss: 1.370464 \t Accur.: 0.5059905266\n",
            "*** Validation loss decreased (1.417813 --> 1.370464).  Saving model ...\n",
            "Epoch: 5 at 24:45:23 \tTrain. Loss: 1.338459 \tValid. Loss: 1.356453 \t Accur.: 0.5068264140\n",
            "*** Validation loss decreased (1.370464 --> 1.356453).  Saving model ...\n",
            "Epoch: 6 at 24:47:45 \tTrain. Loss: 1.333208 \tValid. Loss: 1.357773 \t Accur.: 0.5076623015\n",
            "Epoch: 7 at 24:50:6 \tTrain. Loss: 1.326855 \tValid. Loss: 1.349893 \t Accur.: 0.5073836723\n",
            "*** Validation loss decreased (1.356453 --> 1.349893).  Saving model ...\n",
            "Epoch: 8 at 24:52:25 \tTrain. Loss: 1.318625 \tValid. Loss: 1.346767 \t Accur.: 0.5129562552\n",
            "*** Validation loss decreased (1.349893 --> 1.346767).  Saving model ...\n",
            "Epoch: 9 at 24:54:45 \tTrain. Loss: 1.317740 \tValid. Loss: 1.345476 \t Accur.: 0.5098913346\n",
            "*** Validation loss decreased (1.346767 --> 1.345476).  Saving model ...\n",
            "Epoch: 10 at 24:57:6 \tTrain. Loss: 1.319080 \tValid. Loss: 1.342870 \t Accur.: 0.5137921427\n",
            "*** Validation loss decreased (1.345476 --> 1.342870).  Saving model ...\n",
            "Epoch: 11 at 24:59:27 \tTrain. Loss: 1.314914 \tValid. Loss: 1.341298 \t Accur.: 0.5143494009\n",
            "*** Validation loss decreased (1.342870 --> 1.341298).  Saving model ...\n",
            "Epoch: 12 at 25:1:45 \tTrain. Loss: 1.317707 \tValid. Loss: 1.342195 \t Accur.: 0.5137921427\n",
            "Epoch: 13 at 25:4:3 \tTrain. Loss: 1.317392 \tValid. Loss: 1.342535 \t Accur.: 0.5157425467\n",
            "Epoch: 14 at 25:6:22 \tTrain. Loss: 1.318156 \tValid. Loss: 1.342446 \t Accur.: 0.5151852884\n",
            "Epoch: 15 at 25:8:40 \tTrain. Loss: 1.316971 \tValid. Loss: 1.342274 \t Accur.: 0.5154639175\n",
            "Training complete in 34m 59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPX1//HXyWRfgJCENcFERBaR\nNSJuSLUobqBSxa2tfv3W2lbr12pbtFat2u9P7e63tpValypKLVZFRagbYhWUsK8KQiBhzQ7ZJ5Pz\n++NOQhKyTNaZyZzn45HHzF1m5iTK+94593PvFVXFGGNMaAjzdwHGGGN6joW+McaEEAt9Y4wJIRb6\nxhgTQiz0jTEmhFjoG2NMCLHQN8aYEGKhb4wxIcRC3xhjQoiFvjFeIjJPRL4SkaMislVErmiw7Dsi\nsq3Bskne+Wki8i8RyRORAhH5o/9+A2PaFu7vAowJIF8B5wAHgauAF0XkJOBs4EHgciALGA64RcQF\nvAV8AHwT8ACZPV+2Mb4Tu/aOMc0TkfXAA8D3gSWq+ocmy88AFgODVbXGDyUa027W3jHGS0S+JSLr\nRaRYRIqBsUAykIbzLaCpNGCPBb4JJtbeMQYQkROAvwLnAytV1ePd0xcgB6el01QOMExEwi34TbCw\nPX1jHHGAAnkAInITzp4+wNPA3SIyWRwneTcSnwMHgEdFJE5EokXkLH8Ub4yvLPSNAVR1K/AbYCVw\nCDgV+MS77J/AL4GXgKPA60B/VfUAlwEnAXuBXGBujxdvTDvYgVxjjAkhtqdvjDEhxELfGGNCiIW+\nMcaEEAt9Y4wJIQE3Tj85OVnT09P9XYYxxgSVNWvW5KtqSlvrBVzop6enk5WV5e8yjDEmqIjIHl/W\ns/aOMcaEEAt9Y4wJIRb6xhgTQiz0jTEmhFjoG2NMCLHQN8aYEGKhb4wxISTgxukbY0yPUYWibNi/\nDgq+gogYiO4DUX0gKgGi+zrP6+ZFxICIv6vuFAt9Y0xoUIUj+52A37/W+7gOKop8f4+wCO/GwLsR\naLpRaPaxr/MYEQueaqipAk+V81hTCTXVzqPH+1hT1WSdhtPNre999JGFvjGmdyrLh31rG4d86SFn\nmbhgwBgYdSkMnQRDJkLKaCdYK49A1ZEmjyUtzD/ifFNoOE0X36MkLBzCo8EV6TyGRzaZjoKYRJ/f\nzkLfGNM1VP3X+qgohgPrG4T8OijJ8S4USD4ZTvzasYAfOBYiY49/n4hoZ++9o2probq0+Y2Duxxc\nUU5Ih0c1Du3wqMbLGk6HuXz77G/59re30DfGQK2n+aCqfyxpY/kRJ+wiYtpod7TWDvG2QVwRrdda\nXQYHNjjBXhfyhV8dW56YAamnwZRbnJAfNM55354QFuZ8VnQf6MS2oztZ6BsTCg5ugg0LnZ52c6Fd\nXdr2e7iijg/r5AHHwjoyDtwVjTcQlSVQnHNsuqai7c8Jj2l+oxAWAYe2QP4XoLXOun2GOnvuE65z\nAn7wBIjt37m/VS9noW9Mb+WuhK2vw+q/Qe7nTmj3SzsWogmDGu9ht7VnHh7V+Zo87rZ75M19qziy\nzzlYmTIaxsx2gn7IREgY2PmaQoyFvjG+8NTAln85rYeTZkBUvL8ralnBV7DmWVi3ACoKIWkEXPj/\nYMK17Trg1y1cERCX5PwYv7DQN6Ytu1fAOz+Fw1udaVcUnHQ+jJ4FI2f6P0jB2Sh9+Y6zV7/rQ2fE\nx6hLIPNmyJgW9GPLTdex0DemJcV74d8/d1okfYfB1X+H2GTYthi2vQlfLHHCNf0cGDPLGf4XP6Bn\nazxyANY+D2ueh6P7nR73134Gk77ltG+MaUJUu3hMaSdlZmaq3TnL+JW7Aj55Av7zO2f6nB/Bmbc7\nI1PqqDpjv7cudjYChbsAgWFnHNsA9Evrnvpqa2H3R5D1N9i+BNQDw8+H026GEReCy/blQpGIrFHV\nzDbXs9A3xkvVCfBl90HJXjjlCpjxcNvhreq0fra96WwEDm9x5g+Z6LSARs+C5JM6X195Iax/CbKe\ncYYoxvSHiTdA5k3Q/8TOv78Jahb6xrTH4W3wzk+c/v2AU+CixyDjnI69V8FXx1pA+9Y48waMgdGX\nORuAgaf43mNXdd5j9d+cA8k1lZB2utOrHzPbOZkoQLg9tUS47BqO/tKloS8iM4E/AC7gaVV9tMny\nG4FfAfu8s/6oqk97ly0FpgL/UdVL2/osC33ToyqKYPmj8PlfnWuqnHcfTL6p61okJbmw7S1nI7Dn\nU0CdvfK6DcCQSc4JPU1Vl8Gmfzphf3AjRMbDuKudsB80tmtqa0Ol20NhWTWFZdXkl1ZRWFZNQWk1\nBWXVFHin88uqKSyroqC0mvJqD4mxEQxLiiM9KZYTkuI4oX8s6cmxDOsfR3J8JGIHlLtNl4W+iLiA\nL4EZQC6wGrhWVbc2WOdGIFNVb2vm9ecDscB3LfRNwKj1wLoX4P2HnLZJ5k3wtfu6dyhh6WHY/rbz\nDWD3R1Bb4xx4HXWpcxxg2BmQ/6XTvtmw0BmjPnAsZP6XE/hRCR3+aE+t4vbUUlzuPhbg3rAuKKum\nsNQ77Q32wrJqSqtqmn2vCJfQPy6SpLgokuIjSYqLpH9cFH1iwjl0pIq9hWVk55dzoKSC2gbxEhfp\nqt8gDEuKJT0pjhO8G4fBfaIJC7MNQmf4Gvq+7M5MAXaq6i7vGy8EZgNbW32Vl6q+LyLTfVnXmB6x\n9zN458fOqfzDznBaOYPHd//nxg9wNi6ZN0FFEVVbl+De9AYxa57D9flTVLriiPaUUSMRrO/zNT4e\nOIudkWNwb1NqtmzH7amlxqPU1Nbi9j4600qNp/E8t6fWO19x19bS2r5deJgT4v3jIkmOjyItLbY+\nzJPio7zznWDvHxdJn+hwn/bYq2o85BZVsLegnOyCMvYUlLOnoIwvDh3lvW2HcHuOFRUZHkZaYgzp\nSXH1G4S6x9TEmE63jeo2ei39rTy1igL9YiPoHxtJeJC0qdyeWgpKnW9ivvIl9IcCOQ2mc4HTm1lv\njohMw/lWcKeq5jSzTrNE5BbgFoBhw4b5+jJj2ufIAXjvAdj4D0gYAnP+BmPndNsY9kq3h9yicnKK\nKsgtqiC3qNx5LHQeC8r6Ad8mlrmcG7aB88I3kOtK5W3X+ZRX9iXcHUa46ygRYWGEu4RwVxgRYUK4\nS4iOcBEe5p3nEsK969StG+EKa3Z5v9iIxmHu3UPvjrZLVLiL4SnxDE85/kQ2T61yoKTCuyFwNgZ7\nvBuHlbsKKK/21K8bJjA0MYah/WIQpMs3ek2JQGJs3UbP2RAmx0eRFBdJckJU/d8vJd75phMX1bWj\npapraskvrTr2c7SavPrpavKOVpLvDfricne737+rqn0TeFlVq0Tku8DzwHm+vlhV5wPzwWnvdFFN\nxjhqqmDVn+CjX0GtG865G86+s9Nn1Va6PewrbhzoOd5Azy2qOG7vK9IVxtDEGFITY7hgSB9SE2NJ\nTYwhNTGWtMRLSI6PIixMuLNTVQUHV5h4f/9YzmoysElVySut8n5DKGdvQRnZBeXsL65ARAkPCyM6\n4tiGLcLlbNBcYW1v9OqeR3g3og1frwrF5dXklTrHLOr2oLfsP0J+aRVHK5tvd8VEuJxvRvFRpMQf\na3slx0c12mjERrrqj48cC/AqJ9CPHptXUtF8kCdEhZOcEEVyfCQjBsRzxolJznsnOJ8x8zHf/va+\nhP4+oOGYtVSOHbCt+49U0GDyaeBx3z7emG725TJYOs8ZRz/yErjwkQ4NbyworWLRmly27D9SH/CH\njzYO9fAwqQ/180cNIDUxhrT+x4J9QEKU9a19ICIMSIhmQEI0memBc/G0ugPbdRuD/FLnGEj+Ue9j\naRX7iivZmFtCQVk1ntq2918TosNJ8W4URg5K4GzvcyfcnYBPjo8iJSGK6AgfL7HcBl9CfzUwQkQy\ncML+GuC6hiuIyGBVPeCdnAVs65LqjOmo/J2w7B7Y8W/n2jM3vAonfb3db7PtwBGe/WQ3r6/fT3VN\nrRPkibGce3JKo0BPTYxhYJ9oXBbqvVZ0hIsh/WIY0i+mzXVra5WSCjcFZc7ee0FpNWVVNfSPiyQl\nIaq+TdRVQd4ebYa+qtaIyG3AMpwhm8+o6hYReQjIUtXFwA9FZBZQAxQCN9a9XkQ+BkYB8SKSC9ys\nqsu6/lcxAUvVGRpZlu+MM2/2phHRvt8sojWVR2DFr2DVn533vOCXznXVwyN9fgtPrfLu1kM8+8lu\nPttdSHREGHMmpXLTWemcPLDjI2hM6AgLExLjIkmMi+SkHr4yR1vs5CzTMR43lOU5P6Xex7LDTaYb\n/NQ23w9tRFwt3A6ubrqFOwvV/UiYM9Sx9BBMuAHOv79dl94tqXDzyuocnl+ZTW5RBUP6RvOtM9O5\n5rQ0+sX6vtEwxh+6csimCQWqzo00jgvxfGd8ecMALz0MlcXNv48ryhmaGJcCCYNh8DjneZx3XnjU\nsZtDN3dz57ZuDl1Z3PrNolMz4ZqXIXWyz7/6zsOlPPfpbl5ds48Kt4cp6f352cWjmTFmYNAM3TPG\nVxb6vVmtx2mrNBfajaa9jy3d1Si6nxPY8QNgwGjIONc7ndIg0JOd5ZHx/ruMbzvu0Vpbq3y0I49n\nP8lmxZd5RLrCmDVhCDeemc7YoQF6nztjuoCFfrBxVx7fOin17pE3ba+U5x+7rVxDYeHesE52Ajtp\nRIMA94Z43XRscrv64X7lQ+CXVtXw6ppcnv80m135ZaQkRPGjGSdz3enDSI7vgjtDGRPgLPSDySdP\nwLs/b35ZRNyxoE5Md9ocdW2Wup+66eh+zV/vpRfbW1DO8yuzeWV1Dkerahif1o8/XDOBi8YOJjI8\ntP4WJrRZ6AeLWg989hfnxs+Z/9UgxJOd55Fx/q4w4KgqK78q4JlPsnl/+yFcIlx86mBuPCudScMC\n4G5XxviBhX6w2LXcuTn0hb90rvMeZA6WVPKrZV+w/eAR+sZE0Dcmgn6xEfSpex4TWT+vbnnf2Aji\nI8PbfUJTRbWH19fv47lPsvni0FH6x0Xyg+knccPUExjUN3AuRWyMP1joB4v1C5x7sY682N+VtEtV\njYe//Wc3f/xgJzW1yhknJlFWVcOOw6WUVLgpKXdT7WnmuINXmECfmAj6eTcEfWIi6BcbSd+Y8EYb\ni76xESREh/Pxjnxe/nwvxeVuRg/uw+PfGMes8UP8chKMMYHIQj8YVBQ512Sf/G1nyGOQ+PCLwzz0\n5lZ255dxwZiB/PzSMaT1j220jqpS6a51NgAVborLnWuPFFe4OVI/z31seYWb3KKK+ummp7qHCcwY\nM5Cbzsrg9Iz+dv12Y5qw0A8GmxY549EnXO/vSnyyp6CMh9/aynvbDnNichzP/9cUzj05pdl1RYSY\nSBcxka52t15UldKqmvoNw5EKNyckxzHUh9PkjQlVFvrBYP0CGHhqz1zzvRMqqj38aflOnlqxi4gw\n4Z6LRnHTWRndNjpGREiIjiAhOoJUOy5rjE8s9APdoa2wfx3MfNR/Jz21QVVZsukgv3x7K/tLKrl8\nwhDuuXg0A/vYQVNjAo2FfqBbvwDCIuDUq/1dSbO+PHSUB97YwspdBYwZ3Ic/XDuR0wLocrjGmMYs\n9AOZx+3c5WnkzO69d2sHHKl08/t3d/D8ymzio8J5+PKxXDdlmF1a2JgAZ6EfyHb827mcwoQb/F1J\nvdpaZdHaXB5fup2CsmqunTKMuy8YSf+4ILlUgzEhzkI/kK17EeIHdujmH91hQ04xDyzewvqcYiaf\nkMhzN02xi5MZE2Qs9ANV6WHnVn9n/ABc/v3PVFBaxeNLv+CVNTkkxUXx26vHc8XEoTYG3pgg5NNY\nOhGZKSJfiMhOEZnXzPIbRSRPRNZ7f/67wbJvi8gO78+3u7L4Xm3jP0A9MNF/rZ0aTy3PfbKbr/16\nOa+uzeW/z87gw7vP5cpJqRb4xgSpNnchRcQFPAnMAHKB1SKyWFW3Nln1H6p6W5PX9gceADIBBdZ4\nX1vUJdX3VqqwbgGkngYpI/1SwqpdBTy4eAvbDx7l7JOSeXDWGE4aYLcKNCbY+dI3mALsVNVdACKy\nEJgNNA395lwIvKuqhd7XvgvMBF7uWLkhYv9ayNsGl/6+xz/6QEkFv3x7G29tPMDQfjH85YZJXHjK\nINuzN6aX8CX0hwI5DaZzgdObWW+OiEwDvgTuVNWcFl47tOkLReQW4BaAYcOG+VZ5b7ZuAYTHwNgr\nu/VjSqtqyM4vI7ugjN15ZezOL+OdzQepVeWO80dw67nDiYm0C5UZ05t01RHCN4GXVbVKRL4LPA+c\n5+uLVXU+MB+cG6N3UU3ByV0JmxfB6MsguvMjYyrdHrILysjOL2N3fjm780vJzi9nd0EZeUerGq07\nqE80Xx8zkJ9cOPK4C6MZY3oHX0J/H5DWYDrVO6+eqhY0mHwaeLzBa6c3ee3y9hYZUra/BZUlMNH3\ni6tV1XjIKSxnd365E+71IV/GgZLKRusmx0eSkRzH9JNTSE+OIyM5jvSkONKTY4mNtMFcxvR2vvwr\nXw2MEJEMnBC/Briu4QoiMlhVD3gnZwHbvM+XAf8rInWXw7oAuKfTVfdm616EvsMgfdpxi6pravnk\nq3x253lbMt7WzL6iChpeYbhfbAQZyXGccWIS6clxTrh7gz0hOqIHfxljTKBpM/RVtUZEbsMJcBfw\njKpuEZGHgCxVXQz8UERmATVAIXCj97WFIvIwzoYD4KG6g7qmGcU5zh2yzv1Js/ew/fGiDbyxfj8A\nCVHhpCfHMTEtkSsmppKRHEt6krPn3i/Wzo41xjTPp+/zqroEWNJk3v0Nnt9DC3vwqvoM8Ewnagwd\nGxYCChOuO27R2r1FvLF+PzefncH3pg8nKS7SRtQYY9rNmriBQtW5omb6OZCY3mSR8r9vbyMlIYof\nzTiZuCj7z2aM6ZjuubuFab89n0LR7mbPwF26+SBZe4q4ywLfGNNJFvqBYv0CiEyA0bMaza6uqeXR\npdsZOTCBqzLTWnixMcb4xkI/EFQdhS2vw9grILLx+PgXVu1hT0E5914y2q5Vb4zpNAv9QLDldXCX\nHXfd/JJyN0+8v4NzRiS3eGNxY4xpDwv9QLB+ASSNgLQpjWb/8cMdHKl0c+/Fo/1UmDGmt7HQ97eC\nr2DvSmeYZoMhmHsLynn+0z1cPTmN0YP7+LFAY0xvYqHvb+sXgITB+GsbzX5s2XZcYcKPLjjZT4UZ\nY3ojC31/qvXA+ped2yH2GVw/e82eIt7eeIBbpp3IwD7RfizQGNPbWOj7064P4eh+mHDs4mqqyi/f\n3sqAhCi+e+6JfizOGNMbWej707oFEJMIIy+qn/XO5oOs3VvMXRecbFe9NMZ0OQt9fykvhO1vw6lX\nQ3gU4Fwi+dF3tjNqUALfmGwnYhljup6Fvr9sfhU8VY2um//Cyj3sLSzn3ovtRCxjTPew0PeXdS/C\nwFNh8HgAisur+b8PdjLt5BSm2YlYxphuYqHvD4e2wIH1jfby/++DnRytdPMzOxHLGNONLPT9Yd0C\nCItw+vnAnoIy/r4ym6sz0xg5KMG/tRljejWfQl9EZorIFyKyU0TmtbLeHBFREcn0TkeKyLMisklE\nNojI9C6qO3h53LDxH86InbgkAB5bup0IVxg/mmEnYhljuleboS8iLuBJ4CJgDHCtiIxpZr0E4A7g\nswazvwOgqqcCM4DfiEhof7v4chmU59dfN3/NnkKWbDrId6cNZ4CdiGWM6Wa+BPAUYKeq7lLVamAh\nMLuZ9R4GHgMqG8wbA3wAoKqHgWIgs1MVB7v1CyB+EAw/H1Xlkbe3MbBPFN+ZluHvyowxIcCX0B8K\n5DSYzvXOqycik4A0VX27yWs3ALNEJFxEMoDJwHED0EXkFhHJEpGsvLy8dv0CQeXoIWdPf/xccIXz\n9qYDrNtbzF0XjLQTsYwxPaLTSeNt1/wWuLGZxc8Ao4EsYA/wKeBpupKqzgfmA2RmZmpnawpYG/8B\n6oEJN1BV4+Gxpc6JWHMmpfq7MmNMiPAl9PfReO881TuvTgIwFlguzqWBBwGLRWSWqmYBd9atKCKf\nAl+2+mla61PhQafuxuepp0HKybzw8S5yCit44eYpdiKWMabH+NLeWQ2MEJEMEYkErgEW1y1U1RJV\nTVbVdFVNB1YBs1Q1S0RiRSQOQERmADWqurXVTzu8Fb5Y2sFfJ4DtWwt522HC9RSVVfPE+zuYPjKF\nc0bYiVjGmJ7TZuirag1wG7AM2Aa8oqpbROQhEZnV+qsZAKwVkW3AT4Fvtl1ROLw8F5beAzVVba4e\nNNa/COExMPZK/u+DnZRW1XDPRXYiljGmZ/nU01fVJcCSJvPub2Hd6Q2eZwMj21VR8kiYcj6s+hPs\n+QS+8SwkDW/XWwQcdwVsehXGzCK7NJwXVmUz9zQ7EcsY0/MCb8y8CFz8OFzzEhTvhaemwYaF/q6q\nc7a/DVUlMOH6+hOx7rQTsYwxfhB4oV9n1CVw639g0Dh47bvw2q1QVervqjpm3YvQbxhZcgrvbD7I\nrecOZ0CCnYhljOl5gRv6AH1T4dtvwrnznOGOT02D/ev9XVX7FOfAruXo+Gt5ZMkXzolY59gdsYwx\n/hHYoQ/gCoev3eOEv7sC/jYDVv3ZGQIZDDa8DCjvR32d9TnF3H3BSGIiXf6uyhgTogI/9Oukn+20\ne4afD0vnwcvXQFmBv6tqXW0trF+A54RzePDjUkYP7sOVdiKWMcaPgif0wbkq5bUvw8zH4KsP4C9n\nwe6P/V1Vy/Z+CkXZfBR3AblFFdx3id0RyxjjX8EV+uCM7pl6K/z3exAZB89fBh/8Ejw1/q7seOsW\noJEJ/HRrOl8bmcJZJyX7uyJjTIgLvtCvM3g83PIRjL8WVjwOz18KJbn+ruqYqqOw9XXWJnyNgioX\n99gdsYwxASB4Qx8gKh6u+DNcMR8OboI/n+WMiQ8EW14HdzmPHpzMNVOGcfJAOxHLGON/wR36dcbP\nhe+ugMR0WHgdvH03uCvbfFm3WvciByPS2OoayZ1ftxOxjDGBoXeEPjiXarj5XTjjNlj9V3j6fMhr\n/YKe3SZ/J+Ss4rnys/je9JNISYjyTx3GGNNE7wl9gPBIuPCXcN0/4egBmH+uczZsD4/p13UL8BDG\nf2K/zs1n24lYxpjA0btCv87JF8Ctn8DQyfDGD+DV/4bKIz3z2bUeKtcs4CPPOG6ceYadiGWMCSi9\nM/QB+gyGb70B590HW15zLuGwb023f2z1l+8RU3mIlX0u4sqJQ9t+gTHG9KDefWPWMBdM+zGkn+Ps\n7f/tAjjnbhg8DqL6QHQf72Nf59HV+T9Hzgd/JVHjOW/WtwizE7GMMQGmd4d+nWFT4daPYfHt8NGj\nLa8XEdtkY9D0sW8ry/tSVFZB2uEP+ajPZcwYOaTnfj9jjPGRT6EvIjOBPwAu4GlVbTY5RWQOsAg4\nzXu7xAjgaWCS97P+rqr/r0sqb6+YRLj6Beca/RWFTo+/6sjxj03nleQem3aXt/oRid7Hk2fe2v2/\njzHGdECboS8iLuBJYAaQC6wWkcVN73UrIgnAHcBnDWZfBUSp6qkiEgtsFZGXvXfU6nkikHiC89MR\nHrdzpm1lSf1GoaS4gDc/386OvfsZFlfD9AmjGH7K1K6t2xhjuogve/pTgJ2qugtARBYCs4GmNzh/\nGHgM+HGDeQrEiUg4EANUAz00jKYbuCIgtj/E9qe2Vnnp8708trScKvd4vjf9Sq6fPpzoCButY4wJ\nXL6E/lAgp8F0LnB6wxVEZBKQpqpvi0jD0F+Es4E4AMQCd6pqYdMPEJFbgFsAhg0b1q5fwB+27j/C\nz17fxLq9xZw5PImHLx/L8JR4f5dljDFt6vSBXBEJA34L3NjM4imABxiC0/L+WETeq/vWUEdV5wPz\nATIzMwP27ihlVTX8/r0veeaTbPrFRPC7ueO5fMJQRGyUjjEmOPgS+vuAtAbTqd55dRKAscByb/gN\nAhaLyCzgOmCpqrqBwyLyCZAJNAr9YPDu1kM88MZm9pdUcu2UNH46cxT9YiP9XZYxxrSLL6G/Ghgh\nIhk4YX8NTpgDoKolQP2F4kVkOXC3d/TO+cB5wAsiEgdMBX7fdeV3v33FFTy4eAvvbj3EyIEJLLp2\nIpnp/f1dljHGdEiboa+qNSJyG7AMZ8jmM6q6RUQeArJUdXErL38SeFZEtgACPKuqG7ui8O5W46nl\n2U+y+d17X1KryryLRnHz2RlEuHrvSczGmN5PNMBuMJ6ZmalZWVl+rWHt3iJ+9tpmth04wnmjBvCL\nWaeQ1j/WrzUZY0xrRGSNqma2tV5onJHro5IKN48v3c5Ln+9lYEI0f7lhEheeMsgO1Bpjeg0LfUBV\nWbxhPw+/tY3CsipuPDOduy4YSXyU/XmMMb1LyKdadn4ZP39jMx/vyGdcal+eu+k0xg7t6++yjDGm\nW4Rs6FfVeHjqo1388cOdRLrC+MWsU7hh6gm47MqYxpheLCRD/9Ov8rnv9c3syivjknGDuf/SMQzs\nE+3vsowxptuFVOiXV9dw3+ub+dfafaT1j+G5m05j+sgB/i7LGGN6TEiF/kuf7eVfa/fx/enDuf28\nEXYrQ2NMyAmp0F/5VQEnJsfxk5mj/F2KMcb4RcicXuqpVT7fXcjpJyb5uxRjjPGbkAn9rfuPcLSq\nhqkn2nVzjDGhK2RCf+WufACm2p6+MSaEhUzor9pVyInJcTY00xgT0kIi9Gs8tay2fr4xxoRG6G89\nYP18Y4yBEAn9VbsKAOvnG2NMiIS+9fONMQZ8DH0RmSkiX4jIThGZ18p6c0RERSTTO329iKxv8FMr\nIhO6qnhf1PXzpw63vXxjjGkz9EXEhXPbw4uAMcC1IjKmmfUSgDuAz+rmqeoCVZ2gqhOAbwK7VXV9\nVxXvi2P9fAt9Y4zxZU9/CrBTVXepajWwEJjdzHoPA48BlS28z7Xe1/ao+n5+hh3ENcYYX0J/KJDT\nYDrXO6+eiEwC0lT17VbeZy7wcnMLROQWEckSkay8vDwfSvLdql2FnJgSxwDr5xtjTOcP5IpIGPBb\n4K5W1jkdKFfVzc0tV9X5qpqpqpkpKSmdLalefT/fWjvGGAP4Fvr7gLQG06neeXUSgLHAchHJBqYC\ni+sO5npdQwt7+d3J+vnGGNNtnHaXAAARqElEQVSYL5dWXg2MEJEMnLC/BriubqGqlgDJddMishy4\nW1WzvNNhwNXAOV1Xtm+sn2+MMY21uaevqjXAbcAyYBvwiqpuEZGHRGSWD58xDchR1V2dK7X9rJ9v\njDGN+XQTFVVdAixpMu/+Ftad3mR6OU7Lp0fV9fMvmzCkpz/aGGMCVq89I9f6+cYYc7xeG/rWzzfG\nmOP14tC3fr4xxjTVK0O/xlPL5zY+3xhjjtMrQ3/L/iOUWj/fGGOO0ytD3/r5xhjTvF4b+tbPN8aY\n4/W60K/x1LI6u4gzrLVjjDHH6XWhb/18Y4xpWa8L/bp+/ul2E3RjjDlOrwz94SlxDEiwfr4xxjTV\nq0K/rp9vrR1jjGlerwp96+cbY0zrelXoWz/fGGNa1+tC3/r5xhjTsl4T+tbPN8aYtvkU+iIyU0S+\nEJGdIjKvlfXmiIg2vD+uiIwTkZUiskVENolIt+yGWz/fGGPa1uads0TEBTwJzABygdUislhVtzZZ\nLwG4A/iswbxw4EXgm6q6QUSSAHcX1l/P+vnGGNM2X/b0pwA7VXWXqlYDC4HZzaz3MPAYUNlg3gXA\nRlXdAKCqBarq6WTNzbJ+vjHGtM2X0B8K5DSYzvXOqycik4A0VX27yWtPBlRElonIWhH5SXMfICK3\niEiWiGTl5eW1o3yH9fONMcY3nT6QKyJhwG+Bu5pZHA6cDVzvfbxCRM5vupKqzlfVTFXNTElJaXcN\n1s83xhjf+BL6+4C0BtOp3nl1EoCxwHIRyQamAou9B3NzgRWqmq+q5cASYFJXFN7QSuvnG2OMT3wJ\n/dXACBHJEJFI4Bpgcd1CVS1R1WRVTVfVdGAVMEtVs4BlwKkiEus9qHsusPX4j+gc6+cbY4xv2gx9\nVa0BbsMJ8G3AK6q6RUQeEpFZbby2CKf1sxpYD6xtpu/fKTWeWlbb/XCNMcYnbQ7ZBFDVJTitmYbz\n7m9h3elNpl/EGbbZLTbvP0JZtYczhlvoG2NMW4L+jNz68fkZFvrGGNOWXhH6Jw2IJyUhyt+lGGNM\nwAvq0D/Wz7dRO8YY44ugDv26fr4dxDXGGN8EdehbP98YY9on6EPf+vnGGOO7oA196+cbY0z7BW3o\nWz/fGGPaL2hD3/r5xhjTfkEd+tbPN8aY9gnK0Ld+vjHGdExQhr71840xpmOCMvStn2+MMR0TtKFv\n/XxjjGm/oAt9t/XzjTGmw4Iu9DfvK7F+vjHGdJBPoS8iM0XkCxHZKSLzWllvjoio9/64iEi6iFSI\nyHrvz186W/CqXYUAFvrGGNMBbd45S0RcwJPADJwbna8WkcWqurXJegnAHcBnTd7iK1Wd0EX1smpX\nASMGxJMcb/18Y4xpL1/29KcAO1V1l6pWAwuB2c2s9zDwGFDZhfU14vbUkpVt98M1xpiO8iX0hwI5\nDaZzvfPqicgkIK2Fm55niMg6EflIRM5p7gNE5BYRyRKRrLy8vBYLsX6+McZ0TqcP5IpIGPBb4K5m\nFh8AhqnqROBHwEsi0qfpSqo6X1UzVTUzJSWlxc+q6+efbiN3jDGmQ3wJ/X1AWoPpVO+8OgnAWGC5\niGQDU4HFIpKpqlWqWgCgqmuAr4CTO1qs9fONMaZzfAn91cAIEckQkUjgGmBx3UJVLVHVZFVNV9V0\nYBUwS1WzRCTFeyAYETkRGAHs6kih1s83xpjOa3P0jqrWiMhtwDLABTyjqltE5CEgS1UXt/LyacBD\nIuIGaoFbVbWwI4VaP98YYzqvzdAHUNUlwJIm8+5vYd3pDZ6/CrzaifrqWT/fmN7D7XaTm5tLZWW3\nDfbrtaKjo0lNTSUiIqJDr/cp9AOB9fON6T1yc3NJSEggPT0dEfF3OUFDVSkoKCA3N5eMjIwOvUdQ\nXIbB+vnG9C6VlZUkJSVZ4LeTiJCUlNSpb0hBEfrWzzem97HA75jO/t2CIvStn2+MMV0jSELf+vnG\nmK5TXFzMn/70pw699uKLL6a4uLiLK+o5AR/61s83xnS11kK/pqam1dcuWbKEfv36dUdZPSLgR+9Y\nP9+Y3u0Xb25h6/4jXfqeY4b04YHLTmlx+bx58/jqq6+YMGECM2bM4JJLLuHnP/85iYmJbN++nS+/\n/JLLL7+cnJwcKisrueOOO7jlllsASE9PJysri9LSUi666CLOPvtsPv30U4YOHcobb7xBTExMo896\n8803eeSRR6iuriYpKYkFCxYwcOBASktLuf3228nKykJEeOCBB5gzZw5Lly7l3nvvxePxkJyczPvv\nv9+lf5uAD/2VdffDtX6+MaaLPProo2zevJn169cDsHz5ctauXcvmzZvrh0I+88wz9O/fn4qKCk47\n7TTmzJlDUlLjnc8dO3bw8ssv89e//pWrr76aV199lRtuuKHROmeffTarVq1CRHj66ad5/PHH+c1v\nfsPDDz9M37592bRpEwBFRUXk5eXxne98hxUrVpCRkUFhYYfOZW1VwIf+ql2FnDzQ+vnG9Fat7ZH3\npClTpjQa+/7EE0/w2muvAZCTk8OOHTuOC/2MjAwmTHBuFzJ58mSys7OPe9/c3Fzmzp3LgQMHqK6u\nrv+M9957j4ULF9avl5iYyJtvvsm0adPq1+nfv+t3dgO6p2/9fGNMT4mLi6t/vnz5ct577z1WrlzJ\nhg0bmDhxYrNj46Oiju2MulyuZo8H3H777dx2221s2rSJp556yu9nIQd06G/aV0K59fONMV0sISGB\no0ePtri8pKSExMREYmNj2b59O6tWrerwZ5WUlDB0qHMLkueff75+/owZM3jyySfrp4uKipg6dSor\nVqxg9+7dAN3S3gno0F/l7edPybB+vjGm6yQlJXHWWWcxduxYfvzjHx+3fObMmdTU1DB69GjmzZvH\n1KlTO/xZDz74IFdddRWTJ08mOTm5fv59991HUVERY8eOZfz48Xz44YekpKQwf/58rrzySsaPH8/c\nuXM7/LktEVXt8jftjMzMTM3KygLgW898zsGSCv5957l+rsoY05W2bdvG6NGj/V1G0Gru7ycia1Q1\ns63XBuyevvXzjTGm6wVs6Fs/3xhjul7Ahr71840xpuv5FPoiMlNEvhCRnSIyr5X15oiIikhmk/nD\nRKRURO72tTAbn2+MMV2vzdD33uP2SeAiYAxwrYiMaWa9BOAO4LNm3ua3wDu+FmX9fGOM6R6+7OlP\nAXaq6i5VrQYWArObWe9h4DGg0ZkHInI5sBvY4mtR1s83xpju4UvoDwVyGkzneufVE5FJQJqqvt1k\nfjzwU+AX7SnK+vnGmEATHx8PwP79+/nGN77R7DrTp0+nbsh5oOr0gVwRCcNp39zVzOIHgd+pamkb\n73GLiGSJSFZeXp71840xAWvIkCEsWrTI32V0mC8XXNsHpDWYTvXOq5MAjAWWe2/jNQhYLCKzgNOB\nb4jI40A/oFZEKlX1jw0/QFXnA/MBJmdmalZ2Id+YnNrBX8kYE1TemQcHN3Xtew46FS56tMXF8+bN\nIy0tjR/84AeAc9ZsfHw8t956K7Nnz6aoqAi3280jjzzC7NmNu9nZ2dlceumlbN68mYqKCm666SY2\nbNjAqFGjqKioaPbzHnroId58800qKio488wzeeqppxARdu7cya233kpeXh4ul4t//vOfDB8+nMce\ne4wXX3yRsLAwLrroIh59tOXfpb18Cf3VwAgRycAJ+2uA6+oWqmoJUH9usYgsB+5W1SzgnAbzHwRK\nmwZ+UxXVHuvnG2O61dy5c/mf//mf+tB/5ZVXWLZsGdHR0bz22mv06dOH/Px8pk6dyqxZs1q8L+2f\n//xnYmNj2bZtGxs3bmTSpEnNrnfbbbdx//33A/DNb36Tt956i8suu4zrr7+eefPmccUVV1BZWUlt\nbS3vvPMOb7zxBp999hmxsbFdfv2dNkNfVWtE5DZgGeACnlHVLSLyEJClqou7sqCyqhoEON36+caE\nhlb2yLvLxIkTOXz4MPv37ycvL4/ExETS0tJwu93ce++9rFixgrCwMPbt28ehQ4cYNGhQs++zYsUK\nfvjDHwIwbtw4xo0b1+x6H374IY8//jjl5eUUFhZyyimnMH36dPbt28cVV1wBQHR0NOBccvmmm24i\nNjYW6PrLK/t0PX1VXQIsaTLv/hbWnd7C/Ad9+azSqhoyByaQZP18Y0w3uuqqq1i0aBEHDx6sv7DZ\nggULyMvLY82aNURERJCent7pSyFXVlby/e9/n6ysLNLS0njwwQf9ennlgDsj12nt2F6+MaZ7zZ07\nl4ULF7Jo0SKuuuoqwLkM8oABA4iIiODDDz9kz549rb7HtGnTeOmllwDYvHkzGzduPG6duoBPTk6m\ntLS0/iBwQkICqampvP766wBUVVVRXl7OjBkzePbZZykvLwe6/vLKARf6tarWzzfGdLtTTjmFo0eP\nMnToUAYPHgzA9ddfT1ZWFqeeeip///vfGTVqVKvv8b3vfY/S0lJGjx7N/fffz+TJk49bp1+/fnzn\nO99h7NixXHjhhZx22mn1y1544QWeeOIJxo0bx5lnnsnBgweZOXMms2bNIjMzkwkTJvDrX/+6S3/v\ngLu0cnLGaP1i03pr7xjTi9mllTunV11aOT0pzgLfGGO6ScCFvjHGmO5joW+M8YtAay0Hi87+3Sz0\njTE9Ljo6moKCAgv+dlJVCgoK6sf0d4RP4/SNMaYrpaamkpubS15enr9LCTrR0dGkpnb8MjUW+saY\nHhcREUFGRoa/ywhJ1t4xxpgQYqFvjDEhxELfGGNCSMCdkSsieUDrF7zonGQgvxvfv7tZ/f5l9ftX\nMNff3bWfoKopba0UcKHf3UQky5dTlQOV1e9fVr9/BXP9gVK7tXeMMSaEWOgbY0wICcXQn+/vAjrJ\n6vcvq9+/grn+gKg95Hr6xhgTykJxT98YY0KWhb4xxoSQkAl9EUkTkQ9FZKuIbBGRO/xdU0eIiEtE\n1onIW/6upb1EpJ+ILBKR7SKyTUTO8HdNvhKRO73/32wWkZdFpOOXOewBIvKMiBwWkc0N5vUXkXdF\nZIf3MdGfNbamhfp/5f1/Z6OIvCYi/fxZY2uaq7/BsrtEREUk2R+1hUzoAzXAXao6BpgK/EBExvi5\npo64A9jm7yI66A/AUlUdBYwnSH4PERkK/BDIVNWxgAu4xr9Vtek5YGaTefOA91V1BPC+dzpQPcfx\n9b8LjFXVccCXwD09XVQ7PMfx9SMiacAFwN6eLqhOyIS+qh5Q1bXe50dxAmeof6tqHxFJBS4BnvZ3\nLe0lIn2BacDfAFS1WlWL/VtVu4QDMSISDsQC+/1cT6tUdQVQ2GT2bOB57/Pngct7tKh2aK5+Vf23\nqtZ4J1cBHb++cDdr4e8P8DvgJ4DfRtCETOg3JCLpwETgM/9W0m6/x/kfptbfhXRABpAHPOttTz0t\nInH+LsoXqroP+DXO3tkBoERV/+3fqjpkoKoe8D4/CAz0ZzGd9F/AO/4uoj1EZDawT1U3+LOOkAt9\nEYkHXgX+R1WP+LseX4nIpcBhVV3j71o6KByYBPxZVScCZQR2e6Get/c9G2fDNQSIE5Eb/FtV56gz\nVjsox2uLyM9w2rUL/F2Lr0QkFrgXuN/ftYRU6ItIBE7gL1DVf/m7nnY6C5glItnAQuA8EXnRvyW1\nSy6Qq6p1364W4WwEgsHXgd2qmqeqbuBfwJl+rqkjDonIYADv42E/19NuInIjcClwvQbXSUbDcXYa\nNnj/DacCa0VkUE8XEjKhLyKC00/epqq/9Xc97aWq96hqqqqm4xxE/EBVg2ZvU1UPAjkiMtI763xg\nqx9Lao+9wFQRifX+f3Q+QXIQuonFwLe9z78NvOHHWtpNRGbitDdnqWq5v+tpD1XdpKoDVDXd+284\nF5jk/XfRo0Im9HH2lL+Js4e83vtzsb+LCjG3AwtEZCMwAfhfP9fjE++3k0XAWmATzr+bgDilviUi\n8jKwEhgpIrkicjPwKDBDRHbgfHt51J81tqaF+v8IJADvev/9/sWvRbaihfoDgl2GwRhjQkgo7ekb\nY0zIs9A3xpgQYqFvjDEhxELfGGNCiIW+McaEEAt9Y4wJIRb6xhgTQv4/GCECcm8M9MEAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3leC5524UWz",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning, unfreeze layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0xb61JkZ0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1Y_b7XtXJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "#modelname = base_path +'resnext50-Adam-lr0.03-StepLR_4-epo15.pth'\n",
        "\n",
        "modely = models.resnext50_32x4d(pretrained=True)\n",
        "\n",
        "#modely.load_state_dict(torch.load(modelname),strict=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au_JXIwPuBe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(modely)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0wD2OUVkcwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in modely.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "fc_in = modely.fc.in_features\n",
        "\n",
        "transferclassifier = nn.Sequential(\n",
        "                        nn.BatchNorm1d(fc_in),\n",
        "                        nn.Linear(fc_in, 7),\n",
        "                        #nn.ReLU(),\n",
        "                        #nn.Linear(1024, 133)\n",
        "                        )\n",
        "\n",
        "#transfermodel.fc = transferclassifier # resnet\n",
        "modely.fc = transferclassifier\n",
        "modely.apply(weights_init_normal)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modely.to(device);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhOfpBFuEfh",
        "colab_type": "code",
        "outputId": "3a77a539-7138-458a-d52f-1ed0d7d3ace1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "\n",
        "criterion_tf = nn.CrossEntropyLoss()  \n",
        "\n",
        "lr_tf = 1e-3\n",
        "optimizer_tf = optim.Adam(modely.parameters(), lr=lr_tf)\n",
        "\n",
        "stepsize_tf = 7\n",
        "scheduler_tf = lr_scheduler.StepLR(optimizer_tf, step_size=stepsize_tf, gamma=0.1)\n",
        "\n",
        "epochs_ft = 20\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname_xy = '{}tf_resnext50-{}-lr{}-{}{}-epo{}.pth'.format(\n",
        "    save_path, \n",
        "    'Adam', \n",
        "    lr_tf, \n",
        "    'StepLR_', \n",
        "    stepsize_tf, \n",
        "    epochs_ft\n",
        ")\n",
        "\n",
        "print(modelname_xy)\n",
        "\n",
        "modelxy = train_model(\n",
        "    modely, \n",
        "    modelname_xy, \n",
        "    criterion_tf, \n",
        "    optimizer_tf, \n",
        "    scheduler_tf, \n",
        "    epochs_ft, \n",
        "    device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/tf_resnext50-Adam-lr0.001-StepLR_7-epo20.pth\n",
            "starting the training at 19:27:37\n",
            "Epoch: 1 at 19:42:33 \tTrain. Loss: 1.577323 \tValid. Loss: 1.562634 \t Accur.: 0.4001114517\n",
            "*** Validation loss decreased (inf --> 1.562634).  Saving model ...\n",
            "Epoch: 2 at 19:47:58 \tTrain. Loss: 1.507071 \tValid. Loss: 1.544317 \t Accur.: 0.4104207300\n",
            "*** Validation loss decreased (1.562634 --> 1.544317).  Saving model ...\n",
            "Epoch: 3 at 19:53:23 \tTrain. Loss: 1.481276 \tValid. Loss: 1.518490 \t Accur.: 0.4271384787\n",
            "*** Validation loss decreased (1.544317 --> 1.518490).  Saving model ...\n",
            "Epoch: 4 at 19:58:49 \tTrain. Loss: 1.468990 \tValid. Loss: 1.524944 \t Accur.: 0.4240735581\n",
            "Epoch: 5 at 20:4:14 \tTrain. Loss: 1.456688 \tValid. Loss: 1.507987 \t Accur.: 0.4329896907\n",
            "*** Validation loss decreased (1.518490 --> 1.507987).  Saving model ...\n",
            "Epoch: 6 at 20:9:40 \tTrain. Loss: 1.448987 \tValid. Loss: 1.507886 \t Accur.: 0.4335469490\n",
            "*** Validation loss decreased (1.507987 --> 1.507886).  Saving model ...\n",
            "Epoch: 7 at 20:15:6 \tTrain. Loss: 1.392051 \tValid. Loss: 1.465108 \t Accur.: 0.4458066314\n",
            "*** Validation loss decreased (1.507886 --> 1.465108).  Saving model ...\n",
            "Epoch: 8 at 20:20:31 \tTrain. Loss: 1.378714 \tValid. Loss: 1.458564 \t Accur.: 0.4474784062\n",
            "*** Validation loss decreased (1.465108 --> 1.458564).  Saving model ...\n",
            "Epoch: 9 at 20:25:57 \tTrain. Loss: 1.373702 \tValid. Loss: 1.451046 \t Accur.: 0.4471997771\n",
            "*** Validation loss decreased (1.458564 --> 1.451046).  Saving model ...\n",
            "Epoch: 10 at 20:31:22 \tTrain. Loss: 1.369122 \tValid. Loss: 1.453182 \t Accur.: 0.4494288103\n",
            "Epoch: 11 at 20:36:47 \tTrain. Loss: 1.369987 \tValid. Loss: 1.451697 \t Accur.: 0.4513792143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-666ce5f12355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mscheduler_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-7-9d0348e5d8ec>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, name, criteria, optimizer, scheduler, epochs, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0csjXEyJbjK",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcUMyEhJasV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loader, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    print('test started at ', get_time())\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('test finished at ', get_time())\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh5CaGYNLErC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c44443f9-7c50-4e41-b27d-9d3ad8328c6a"
      },
      "source": [
        "\n",
        "# call test function    \n",
        "test(dataloaders['test'], model_ft, criteria, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test started at  (25, 11, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUS0Xhf4pLc",
        "colab_type": "text"
      },
      "source": [
        "### Unused stuff ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY9tuHQsubgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-WTxtUsKc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model as a checkpoint file after every 5 epochs\n",
        "def save_model_checkpoint(model, optimizer, criteria, epochs):\n",
        "  model.to('cpu')\n",
        "  model.class_to_idx = datasets['train'].class_to_idx\n",
        "  checkpoint = {'input_size': 48*48*1,\n",
        "                'output_size': 7,\n",
        "                'model': model,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'criterion': criteria,\n",
        "                'epochs': epochs,\n",
        "                'class_to_idx': model.class_to_idx}\n",
        "\n",
        "  path = \"/content/gdrive/My Drive/facial_expressions.pth\"\n",
        "  torch.save(checkpoint,path)\n",
        "\n",
        "\n",
        "# load model function \n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath, map_location='cpu')\n",
        "    model = checkpoint[\"model\"]\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_4i2xcK_Lfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}