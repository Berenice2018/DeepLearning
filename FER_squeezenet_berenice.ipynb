{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER-squeezenet-berenice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "GcA_vwhUrURY",
        "rj5m7HOg3gHn",
        "I3leC5524UWz",
        "ajUS0Xhf4pLc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/FER_squeezenet_berenice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh9XQ8vR84zw",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xdgcVYCJpkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f4c5af99-6ead-4915-9425-30116fdf4133"
      },
      "source": [
        "# Imports here\n",
        "#!pip install git+https://github.com/pytorch/vision\n",
        "\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torchvision.models as models\n",
        "from torchvision.models.squeezenet import  model_urls\n",
        "squeezenet1_0_state_dict = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "import os,cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#from pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20, 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /root/.cache/torch/checkpoints/squeezenet1_0-a815701f.pth\n",
            "100%|██████████| 5017600/5017600 [00:00<00:00, 16207423.76it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCJINZX0Kcpk",
        "colab_type": "code",
        "outputId": "be634c19-05d9-4368-b4d8-d708941e6e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8ynY8-MVOg",
        "colab_type": "code",
        "outputId": "91cc73d3-c488-49d9-c678-1363a0b40c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fer= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/fer2013.csv\"\n",
        "ferr= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset\"\n",
        "\n",
        "#!ls   '/content/gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.bib  fer2013.csv  PrivateTest  PublicTest  README  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lVhUAPOZa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcA_vwhUrURY",
        "colab_type": "text"
      },
      "source": [
        "### Convert and save images to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5WuBM0VOJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yAg9oU_radg",
        "colab_type": "text"
      },
      "source": [
        "### Load data , image transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvDN0ydqjQ-",
        "colab_type": "code",
        "outputId": "bb1fc400-7353-4282-c424-16efa42b3a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "data_dir = \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013\"\n",
        "train_dir = data_dir + '/Training'\n",
        "valid_dir = data_dir + '/PublicTest'\n",
        "test_dir = data_dir + '/PrivateTest'\n",
        "\n",
        "# original img size = 48 x48 px\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        #transforms.CenterCrop(256),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    }\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir,\n",
        "        'test': test_dir}\n",
        "\n",
        "datasets = {x: torchvision.datasets.ImageFolder(dirs[x], transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=7) for x in ['train', 'valid','test']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) \n",
        "                              for x in ['train', 'valid','test']}\n",
        "print(dataset_sizes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 32556, 'valid': 3589, 'test': 3589}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9fxwj-f-wG",
        "colab_type": "code",
        "outputId": "86ebc428-337c-4192-b606-26a9055cbf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names = datasets['train'].classes\n",
        "print(class_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj5m7HOg3gHn",
        "colab_type": "text"
      },
      "source": [
        "### Show some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9_rLvF03kGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a batch of training images\n",
        "dataiter = iter(dataloaders['train'])\n",
        "images, _ = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy\n",
        "\n",
        "# plot the images of the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 16/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gi4Auz4D_l",
        "colab_type": "text"
      },
      "source": [
        "### Model train helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMm_P_CERmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "    \n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwzo4GzQsAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, name, criteria, optimizer, scheduler = None, epochs=50, device='cuda'):\n",
        "    h, m, s = get_time()\n",
        "    print('starting the training at {}:{}:{}'.format(h, m, s))\n",
        "    since = time.time()\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    # initialize tracker for accuracy \n",
        "    min_loss = np.Inf\n",
        "    TS_loss = pd.DataFrame(np.nan, index = range(1,epochs+1), columns = ['train loss','valid loss'])\n",
        "    TS_acc = pd.DataFrame(np.nan,index = range(1,epochs+1), columns = ['train acc','valid acc'])\n",
        "    \n",
        "    for epoch in range(1, epochs+1):        \n",
        "        # monitor loss/accuracy\n",
        "        train_loss_running = 0.0\n",
        "        valid_loss_running = 0.0\n",
        "        train_acc_running = 0.0\n",
        "        valid_acc_running = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        model.train() # prep model for training\n",
        "        \n",
        "        for data, target in dataloaders['train']:\n",
        "    \n",
        "            # Move input and data tensors to the default device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criteria(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss \n",
        "            train_loss_running += loss.item()*data.size(0)\n",
        "            # accuracy\n",
        "            _, preds = torch.max(output, 1)\n",
        "            train_acc_running  += torch.sum(preds == target.data)\n",
        "    \n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloaders['valid']:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criteria(output, target)\n",
        "                valid_loss_running += loss.item()*data.size(0)\n",
        "                \n",
        "                _, preds = torch.max(output, 1)\n",
        "                valid_acc_running  += torch.sum(preds == target.data)\n",
        "                #print('valid_acc_running {:.6f}'.format(valid_acc_running))\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                #ps = torch.exp(logps)\n",
        "                #top_p, top_class = ps.topk(1, dim=1)\n",
        "                #equals = top_class == labels.view(*top_class.shape)\n",
        "                #valid_loss_running += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        # statistics\n",
        "        train_loss = train_loss_running/ dataset_sizes['train']\n",
        "        valid_loss = valid_loss_running/ dataset_sizes['valid']\n",
        "        train_acc = train_acc_running.double()/ dataset_sizes['train']\n",
        "        valid_acc = valid_acc_running.double()/ dataset_sizes['valid']\n",
        "        \n",
        "        TS_loss.loc[epoch] = [train_loss, valid_loss]\n",
        "        TS_acc.loc[epoch] = [(train_acc.cpu().numpy()), (valid_acc.cpu().numpy())]                                         \n",
        "\n",
        "        # print training/validation statistics \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  train_loss,\n",
        "                  valid_loss,\n",
        "                  valid_acc \n",
        "        ))\n",
        "                                                             \n",
        "        # save model if validation acc has increased\n",
        "        # BC: using the lower validation loss as criterium, when saving a model\n",
        "        if valid_loss <= min_loss:\n",
        "            old_loss_min = min_loss\n",
        "            min_loss = valid_loss\n",
        "            save = True\n",
        "            \n",
        "            print('*** Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            old_loss_min, min_loss))        \n",
        "    \n",
        "    #End\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    #print('Best Valid Acc: {:4f}'.format(best_acc))\n",
        "                                                   \n",
        "    TS_loss.plot(title = 'loss')\n",
        "    TS_acc.plot(title = 'acc')\n",
        "                                                   \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model)\n",
        "    torch.save(model.state_dict(), name)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AGfumpM4Lik",
        "colab_type": "text"
      },
      "source": [
        "### Hyper params, start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeUCHPa_40ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a892f468-faab-4cf1-ee27-8fbce70f926e"
      },
      "source": [
        "#model = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "#model = torch.hub.load('pytorch/vision', 'squeezenet1_0', pretrained=True)\n",
        "\n",
        "no_of_classes = 7\n",
        "transfermodel = models.squeezenet1_0(pretrained =True)\n",
        "\n",
        "for param in transfermodel.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "transfermodel.classifier[1] = nn.Conv2d(512, no_of_classes, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "#transfermodel.apply(weights_init_normal)\n",
        "\n",
        "#transfermodel.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfermodel.to(device);\n",
        "\n",
        "transfermodel"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SqueezeNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (3): Fire(\n",
              "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (4): Fire(\n",
              "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (5): Fire(\n",
              "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (7): Fire(\n",
              "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (8): Fire(\n",
              "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (9): Fire(\n",
              "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (10): Fire(\n",
              "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (12): Fire(\n",
              "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Conv2d(512, 7, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU(inplace)\n",
              "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hrVk_TkscuM",
        "colab_type": "code",
        "outputId": "0cf2924d-098c-423b-d66d-00c1f5de7ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()    \n",
        "lr = 5e-3 #1e-2 #1e-3\n",
        "optimizer = optim.Adam(transfermodel.parameters(), lr=lr)\n",
        "\n",
        "stepsize = 4\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=stepsize, gamma=0.1)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [4, 7, 10, 12], 0.2)\n",
        "\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname = '{}squeeze1_0-{}-lr{}-{}{}-epo{}.pth'.format(save_path, 'Adam', lr, 'MultiStep4_7_10_12', stepsize, epochs)\n",
        "\n",
        "print(modelname)\n",
        "\n",
        "model_ft = train_model(transfermodel, modelname, criteria, optimizer, scheduler, epochs, device)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/squeeze1_0-Adam-lr0.005-MultiStep4_7_10_124-epo15.pth\n",
            "starting the training at 10:12:30\n",
            "Epoch: 1 at 10:42:16 \tTrain. Loss: 1.513116 \tValid. Loss: 1.511674 \t Accur.: 0.4541655057\n",
            "*** Validation loss decreased (inf --> 1.511674).  Saving model ...\n",
            "Epoch: 2 at 10:44:53 \tTrain. Loss: 1.448081 \tValid. Loss: 1.468687 \t Accur.: 0.4745054333\n",
            "*** Validation loss decreased (1.511674 --> 1.468687).  Saving model ...\n",
            "Epoch: 3 at 10:47:29 \tTrain. Loss: 1.431797 \tValid. Loss: 1.503380 \t Accur.: 0.4714405127\n",
            "Epoch: 4 at 10:50:7 \tTrain. Loss: 1.387956 \tValid. Loss: 1.445675 \t Accur.: 0.4842574533\n",
            "*** Validation loss decreased (1.468687 --> 1.445675).  Saving model ...\n",
            "Epoch: 5 at 10:52:44 \tTrain. Loss: 1.382197 \tValid. Loss: 1.435690 \t Accur.: 0.4831429368\n",
            "*** Validation loss decreased (1.445675 --> 1.435690).  Saving model ...\n",
            "Epoch: 6 at 10:55:21 \tTrain. Loss: 1.372908 \tValid. Loss: 1.423354 \t Accur.: 0.4878796322\n",
            "*** Validation loss decreased (1.435690 --> 1.423354).  Saving model ...\n",
            "Epoch: 7 at 10:57:59 \tTrain. Loss: 1.349729 \tValid. Loss: 1.418597 \t Accur.: 0.4937308442\n",
            "*** Validation loss decreased (1.423354 --> 1.418597).  Saving model ...\n",
            "Epoch: 8 at 11:0:36 \tTrain. Loss: 1.352900 \tValid. Loss: 1.418894 \t Accur.: 0.4931735860\n",
            "Epoch: 9 at 11:3:14 \tTrain. Loss: 1.350776 \tValid. Loss: 1.416217 \t Accur.: 0.4923376985\n",
            "*** Validation loss decreased (1.418597 --> 1.416217).  Saving model ...\n",
            "Epoch: 10 at 11:5:52 \tTrain. Loss: 1.349158 \tValid. Loss: 1.412083 \t Accur.: 0.4931735860\n",
            "*** Validation loss decreased (1.416217 --> 1.412083).  Saving model ...\n",
            "Epoch: 11 at 11:8:30 \tTrain. Loss: 1.352658 \tValid. Loss: 1.412527 \t Accur.: 0.4942881025\n",
            "Epoch: 12 at 11:11:7 \tTrain. Loss: 1.351924 \tValid. Loss: 1.412019 \t Accur.: 0.4942881025\n",
            "*** Validation loss decreased (1.412083 --> 1.412019).  Saving model ...\n",
            "Epoch: 13 at 11:13:45 \tTrain. Loss: 1.349185 \tValid. Loss: 1.410998 \t Accur.: 0.4940094734\n",
            "*** Validation loss decreased (1.412019 --> 1.410998).  Saving model ...\n",
            "Epoch: 14 at 11:16:23 \tTrain. Loss: 1.352488 \tValid. Loss: 1.411180 \t Accur.: 0.4945667317\n",
            "Epoch: 15 at 11:19:3 \tTrain. Loss: 1.347630 \tValid. Loss: 1.410650 \t Accur.: 0.4940094734\n",
            "*** Validation loss decreased (1.410998 --> 1.410650).  Saving model ...\n",
            "Training complete in 66m 33s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8leX9//HXJyc7ZC8gAZIAshII\nEBAEGYqrWkehigVHtVpHtXZil23tUFt/X6kLSxV3sRbrqJsqCCioYSN7BEgQkhASMsi+fn/cd0KA\n7Jzkzjn5PB+P88g59zqf5AHnfa7rvu7rFmMMSimllI/TBSillOoeNBCUUkoBGghKKaVsGghKKaUA\nDQSllFI2DQSllFKABoJSzRKRLBGZ4XQdSnUFDQSllFKABoJSSimbBoJSrSAiASIyX0QO2Y/5IhJg\nr4sRkbdFpFBECkRkpYj42OvmiUiOiBSLyA4ROd/Z30Sppvk6XYBSHuJXwAQgHTDAm8Cvgd8APwGy\ngVh72wmAEZEhwA+AccaYQyKSBLi6tmylWk9bCEq1zhzgfmNMrjEmD/g9cJ29rgroAwwwxlQZY1Ya\na5KwGiAAGC4ifsaYLGPMHkeqV6oVNBCUap2+wP4Gr/fbywD+CuwGPhSRvSJyL4AxZjdwD/A7IFdE\nXhGRvijVTWkgKNU6h4ABDV73t5dhjCk2xvzEGJMCXA78uO5cgTHmn8aYyfa+Bnioa8tWqvU0EJRq\nncXAr0UkVkRigPuAlwBE5DIRGSQiAhRhdRXVisgQETnPPvlcDpwAah2qX6kWaSAo1Tp/BDKBTcBm\nYJ29DGAw8D+gBFgNPGmMWYZ1/uBBIB84DMQBv+jaspVqPdEb5CillAJtISillLJpICillAI0EJRS\nStk0EJRSSgEeNnVFTEyMSUpKcroMpZTyKGvXrs03xsS2tJ1HBUJSUhKZmZlOl6GUUh5FRPa3vJV2\nGSmllLJpICillAI0EJRSStk86hyCUso7VVVVkZ2dTXl5udOleLTAwEASExPx8/Nr1/4aCEopx2Vn\nZxMaGkpSUhLWHIGqrYwxHD16lOzsbJKTk9t1DO0yUko5rry8nOjoaA2DDhARoqOjO9TK0kBQSnUL\nGgYd19G/oUcFQnF5tdMlKKWU1/KoQCgorXC6BKWUFyosLOTJJ59s177f+MY3KCwsbPX2v/vd73j4\n4Yfb9V6dzaMCwb+igBOVNU6XoZTyMs0FQnV18z0T7777LhEREZ1RVpfzqECIoZBPd37tdBlKKS9z\n7733smfPHtLT0/nZz37G8uXLOffcc7n88ssZPnw4AFdeeSVjx45lxIgRLFy4sH7fpKQk8vPzycrK\nYtiwYdxyyy2MGDGCCy+8kBMnTjT7vhs2bGDChAmMHDmSq666imPHjgHw6KOPMnz4cEaOHMns2bMB\n+OSTT0hPTyc9PZ3Ro0dTXFzs9r+DRw079aOa/NUvQ+o8p0tRSnWS3//3K7YeOu7WYw7vG8Zvvzmi\nyfUPPvggW7ZsYcOGDQAsX76cdevWsWXLlvohnIsWLSIqKooTJ04wbtw4Zs6cSXR09CnH2bVrF4sX\nL+Yf//gHV199Na+99hpz585t8n2vv/56HnvsMaZOncp9993H73//e+bPn8+DDz7Ivn37CAgIqO+O\nevjhh3niiSeYNGkSJSUlBAYGdvTPcgaPaiFUSQAZOS9SU6PdRkqpzjV+/PhTxvM/+uijjBo1igkT\nJnDw4EF27dp1xj7Jycmkp6cDMHbsWLKyspo8flFREYWFhUydOhWAG264gRUrVgAwcuRI5syZw0sv\nvYSvr/W9fdKkSfz4xz/m0UcfpbCwsH65O3lUC6EqOJZBHGT36v8waPK3nS5HKdUJmvsm35VCQkLq\nny9fvpz//e9/rF69muDgYKZNm9boeP+AgID65y6Xq8Uuo6a88847rFixgv/+97/86U9/YvPmzdx7\n771ceumlvPvuu0yaNIkPPviAoUOHtuv4TfGoFkJAaDQ5JoaAzx9zuhSllBcJDQ1ttk++qKiIyMhI\ngoOD2b59O2vWrOnwe4aHhxMZGcnKlSsBePHFF5k6dSq1tbUcPHiQ6dOn89BDD1FUVERJSQl79uwh\nLS2NefPmMW7cOLZv397hGk7nUS0El48PH0V8m+uLFsCBNdB/gtMlKaW8QHR0NJMmTSI1NZVLLrmE\nSy+99JT1F198MU899RTDhg1jyJAhTJjgns+e559/nttuu42ysjJSUlJ49tlnqampYe7cuRQVFWGM\n4e677yYiIoLf/OY3LFu2DB8fH0aMGMEll1zilhoaEmOM2w/aWTIyMsyP/u8FLvnoAgKSJxJy4xKn\nS1JKucG2bdsYNmyY02V4hcb+liKy1hiT0dK+HtVlBDBtZDLPV19ESNZSyN3mdDlKKeU1PC4QEiKC\n+Dx2JuUEwKePOl2OUkp5DY8LBIAJqYNZXD0Ns/lVKMp2upyWlRXAoktg/2qnK1FKqSZ5ZCDMGBbP\n09XfwBgDq59wupyWLX8ADnwGnz/ldCVKKdWkFgNBRBaJSK6IbGli/TQRKRKRDfbjvgbrLhaRHSKy\nW0TubbA8WUQ+t5f/S0T821L0iL5hENGfNSHnwdrnrW/g3dWRrfDlM+DfC3a+DxXuv9xcKaXcoTUt\nhOeAi1vYZqUxJt1+3A8gIi7gCeASYDhwrYgMt7d/CHjEGDMIOAbc3JaiRYQZw+J4oOhCqCqFL59u\ny+5dxxh4/14ICIWZT0N1OWx/1+mqlFKqUS0GgjFmBdCer+Djgd3GmL3GmErgFeAKse7gcB5QN2b0\neeDKth78guG92VyVQF6faVZXTGVZO0rsZDvehX2fwPRfwuCLILwfbNGhskp5g169egFw6NAhZs2a\n1eg206ZNIzMzs9XLneaucwgTRWSjiLwnInXXnScABxtsk20viwYKjTHVpy1vlIjcKiKZIpKZl5dX\nv/zslChCA335d+BMKDsKG15206/iJtUV8MGvIHYoZNwEPj6Q+i3Y83H37uJSSrVJ3759WbLEO77o\nuSMQ1gEDjDGjgMeAN9xwzHrGmIXGmAxjTEZsbGz9cj+XD9OGxPHM/t6YxLPhs0ehphvdUW3NAji2\nDy76M7j8rGWpM6G2Gra+6WxtSqlT3HvvvTzxxMkBKnU3sSkpKeH8889nzJgxpKWl8eabZ/7fzcrK\nIjU1FYATJ04we/Zshg0bxlVXXdWquYwWL15MWloaqampzJtnzeRcU1PDjTfeSGpqKmlpaTzyyCNA\n49Niu1OHp64wxhxv8PxdEXlSRGKAHKBfg00T7WVHgQgR8bVbCXXL2+yC4fH8d+Mhdp91M4M/vhW+\neh1GdoNJ74qPwIq/wlmXwKDzTy7vPRKiB8OW1yDju87Vp1R39t69cHize4/ZOw0uebDJ1ddccw33\n3HMPd955JwCvvvoqH3zwAYGBgbz++uuEhYWRn5/PhAkTuPzyy5u8d/GCBQsIDg5m27ZtbNq0iTFj\nxjRb1qFDh5g3bx5r164lMjKSCy+8kDfeeIN+/fqRk5PDli3WWJ66KbAbmxbbnTrcQhCR3vZ5AURk\nvH3Mo8CXwGB7RJE/MBt4y1hzZSwD6jrdbgDa9ZV52pBY/FzCkuJUq2vm079ZJ3Kd9tH9VpfRRX86\ndbkIpM2CrFVw/JAztSmlzjB69Ghyc3M5dOgQGzduJDIykn79+mGM4Ze//CUjR45kxowZ5OTkcOTI\nkSaPs2LFivr7H4wcOZKRI0c2+75ffvkl06ZNIzY2Fl9fX+bMmcOKFStISUlh79693HXXXbz//vuE\nhYXVH/P0abHdqcUjishiYBoQIyLZwG8BPwBjzFNYH+y3i0g1cAKYbX/oV4vID4APABewyBjzlX3Y\necArIvJHYD3wTHuKDwv0Y0JKNEu35/GL8+6GN++A3R/B4BntOZx75KyzzmeccxdEDzxzfeos67qE\nr16HiXd2fX1KdXfNfJPvTN/+9rdZsmQJhw8f5pprrgHg5ZdfJi8vj7Vr1+Ln50dSUlKj0167W2Rk\nJBs3buSDDz7gqaee4tVXX2XRokWNTovtzmBo8UjGmGtbWP848HgT694FzhhnaYzZizUKqcMuGB7P\nfW9+xZ4+lzAwLAFWPeJcINQNMw2JgSk/a3ybmEHQZxRsXqKBoFQ3cs0113DLLbeQn5/PJ598AljT\nXsfFxeHn58eyZcvYv39/s8eYMmUK//znPznvvPPYsmULmzZtanb78ePHc/fdd5Ofn09kZCSLFy/m\nrrvuIj8/H39/f2bOnMmQIUOYO3fuKdNiT548mVdeeYWSkhK33s/ZI69UbmjGsHgAlu44Zn3A7l8F\n2Q4N59ryGhz8HM6/DwLDmt4udSYcWgcFe7uuNqVUs0aMGEFxcTEJCQn06dMHgDlz5pCZmUlaWhov\nvPBCizekuf322ykpKWHYsGHcd999jB07ttnt+/Tpw4MPPsj06dMZNWoUY8eO5YorriAnJ4dp06aR\nnp7O3LlzeeCBB+qnxU5LS2P06NH102K7k8dNf93Y2N1LH11JoJ+L124aCY+MgKTJMLuLh6FWlsLj\n46zWwS3LwMfV9LaFB2F+Kpz366ZbEkr1IDr9tfv0qOmvG3PB8HjWHThGXqUfjL8Ftr8D+Wfe77RT\nffooHM+Bix9qPgwAIvpB/4mw+bWuqU0ppVrBawLBGFi2PRfGfx98A6wRR12l8CB8Oh9GfAsGTGzd\nPqkzIW8bHPmq5W2VUqoLeEUgDO8TRkJEEB9uPQK9YmH0XNj4StcN7Vxqz+d3wf2t32fEVSAu6+Sy\nUgpP6r7urjr6N/SKQBARLhgez6rdeZyorLGGfJpaWPNk57/5/s/gq//ApHusrqDWComBlGnWiWj9\nj6B6uMDAQI4ePaqh0AHGGI4ePUpgYGC7j+H+KxscMmNYPM99lsXKXXlcOCLJ+gae+Ryc+1MIcu+Z\n+Hq1NfDePAhLgEk/bPv+qTOtaydy1kJii+d7lPJaiYmJZGdn03C+MtV2gYGBJCYmtnt/rwmEusnu\nlm49woUjelsf0FuWQOYzcO5POudNN7wMhzfBzGfAP7jt+w+7DN7+kdVtpIGgejA/Pz+Sk5OdLqPH\n84ouI7Amu5s+JI6Pt+dSU2ugz0gYeL41yVxVyxNMtVn5cWuKin4TrG/67REYDoMvsLqcamvcW59S\nSrWR1wQCWKONjpZWsv7AMWvB5B9BaR5s+Kf732zFX6E037rMvomJrlolbRaUHLHmN1JKKQd5VSBM\ntSe7W7rVnnwqaTIkjIXPHnPvN/Cje6yWR/oc6Du6Y8cafJF1e029cY5SymFeFQj1k93VBYKINfrn\n2D733oPgg19Z1zqcf1/L27bEPxiGfAO2vgXVlR0/nlJKtZNXBQJY3UZ780vZnVtiLRh6KUQPsi4c\nc8eQtt0fwc73rCknQuM7fjywuo3KC627qSmllEO8LhDqJ7urayX4uOCcu+HrjbB3WccOXlMFH/wS\nIpNhwu0drLSBlOkQFKndRkopR3ldIPSNCCI1IYz/bWtwE4tRs6FXb1g1v2MHz1wEedutG9/4BnTs\nWA35+sPwK2D7u1BZ5r7jKqVUG3hdIABcMKy3NdldcYW1wDcAJt4B+z6BQ+vbd9DSo7DsT9bVxUO+\n4a5ST0qdBVWlVneUUko5wCsDYcbwOIyBj7c3aCWM/S4EhLe/lbD8z1BRAhc90LFhpk0ZcI7Vitny\nH/cfWymlWsErA6Fusrv68whg3bBm3E2w7S1r2GhbHPnK6i7KuAnih7u32Do+Lkj9Fuz6EE64/+bZ\nSinVEq8MhLrJ7lbuyqessvrkirNvBx8/+OzR1h+s7raYAWEw/ZfuL7ah1FlQUwnb3+7c91FKqUZ4\nZSCANfy0orqWlbvyTy4MjYf078CGxVB8pOmdG9r+DuxbAdN/BcFRnVNsnYQx1ggmnRJbKeUArw2E\n8clRhAX68r+tp33wn3MX1FbB5wtaPkh1BXz4K4gdZnUXdTYRa16kfZ9ASW7nv59SSjXQYiCIyCIR\nyRWRLS1sN05EqkVklv16uohsaPAoF5Er7XXPici+BuvS3fPrnOTn8mH60AaT3dWJHgjDLocvn4Hy\nouYPsuZJOJYFF/8ZXF00MWzaLOteDl+90TXvp5RStta0EJ4DLm5uAxFxAQ8BH9YtM8YsM8akG2PS\ngfOAsobrgZ/VrTfGbGhz5a0wY5g12d26usnu6ky+ByqOQ+azTe9cfBhWPGwNMR14XmeU17i4YRA3\n3LpxjlJKdaEWA8EYswIoaGGzu4DXgKb6OWYB7xljuvSqq2mnT3ZXp+9o63qCNQusbqHGfHS/te7C\nP3Z2mWdKnQkH11j3alZKqS7S4XMIIpIAXAU01yk/G1h82rI/icgmEXlERJq87FdEbhWRTBHJbOvd\nlEIbTHZ3xq35Jt0DJYetey+fLmetdfObiXdYXUxdre7+CtpKUEp1IXecVJ4PzDPG1Da2UkT6AGnA\nBw0W/wIYCowDooB5TR3cGLPQGJNhjMmIjY1tc3EXDo9nX34pe/JKT12RMg36jLKGoDacGtsYeO9e\nCImzbr/phKhkSMjQuY2UUl3KHYGQAbwiIllYXUNP1p08tl0NvG6MqapbYIz52lgqgGeB8W6oo1Ez\nhp822V2duqmxj+62hpbW2bwEsr+wprYODOusslqWNgsOb4a8nc7VoJTqUTocCMaYZGNMkjEmCVgC\n3GGMaThE5lpO6y6yWw2IiABXAs2OYOqIPuHWZHdLtx4+c+XwK6xx/6sesVoGlaWw9D7ok27d/MZJ\nw68ERLuNlFJdpjXDThcDq4EhIpItIjeLyG0iclsr9k0C+gGfnLbqZRHZDGwGYoBOPXN7wbDerD9Y\neHKyuzo+Lph0NxxaB1krrXmOig/BxQ+Cj8OXaIT1se74tmWJe+7joJRSLWhxcL0x5trWHswYc+Np\nr7OAhEa268JxnNZVy4/8bycfbTvC7PH9T1056juw7AFY+lvI3Wqd0B0wsSvLa1raLPjvD617OfR1\n+6UaSil1Cq+9UrmhYX1CSYgIOvUeCXX8AmHCbVYrAYEZv+/y+po07HJr7iU9uayU6gI9IhCanOyu\nTsbN1qiiqT+HiH5dX2BTgqNg0PnWlNi1jQ7iUkopt+kRgQBNTHZXJygCfrIdJv+o6wtrSepMOJ5j\nXaimlFKdqMcEQt1kd2cMP63j4+qcG9901JBvgG+QjjZSSnW6HhMITU52190F9IIhF1uT3dU00t2l\nlFJu0mMCAaxuo4LSStbuP9byxt1J6iwoy4d9y52uRCnlxXpUIEw9y5rsrtHRRt3Z4Aus+0Fv1m4j\npVTn6VGB0Oxkd92ZbwAMu8y6tWZVudPVKKW8VI8KBGg42V2J06W0TepM6x4Ou5c6XYlSykv1uECo\nm+zuw6ZGG3VXyVMhJFbvt6yU6jQ9LhD6hAeRlhDe9PDT7srla014t/N9qCh2uhqllBfqcYEA1mij\nDQcLyS32sP74tFlQXQ7b33W6EqWUF+qRgTBjWDzGwMfbmrrjZzeVOB7C++ncRkqpTtEjA6FusjuP\n6zby8YERV8Gej6GspdtcK6VU2/TIQKib7G7V7iYmu+vO0mZBbTVsfdPpSpRSXqZHBgJYw08rqmtZ\nsbORye66s94jIXqwzm2klHK7HhsI41qa7K67ErFaCVmr4Pghp6tRSnmRHhsIfi4fzhsax8fbj3jW\nZHdgXaSGga9ed7oSpZQX6bGBANZFasfKqjxvsruYwVbXkV6kppRyox4dCHWT3S3detjpUtoubZZ1\n28+CvU5XopTyEi0GgogsEpFcEdnSwnbjRKRaRGY1WFYjIhvsx1sNlieLyOcisltE/iUi/h37Ndon\nNNCPiQNjPG+yO4AR37J+6sllpZSbtKaF8BxwcXMbiIgLeAj48LRVJ4wx6fbj8gbLHwIeMcYMAo4B\nN7e+ZPe6YHg8WUfL2J3rYZPdRfSD/hN1SmyllNu0GAjGmBVAS1dB3QW8BrR46a+ICHAeUNcB/jxw\nZUv7dZYZw+IAWOpp90gA6+Ry3jY48pXTlSilvECHzyGISAJwFbCgkdWBIpIpImtEpO5DPxooNMbU\nXRGWDSR0tI728tjJ7sCa7E5cenJZKeUW7jipPB+YZ4ypbWTdAGNMBvAdYL6IDGzrwUXkVjtUMvPy\n8jpaa6M8drK7XrGQMtU6j+Bp50CUUt2OOwIhA3hFRLKAWcCTda0BY0yO/XMvsBwYDRwFIkTE194/\nEchp6uDGmIXGmAxjTEZsbKwbyj3TBcOtye5e+Gy/551cTp0FhfshZ63TlSilPFyHA8EYk2yMSTLG\nJGGdF7jDGPOGiESKSACAiMQAk4CtxvrEXYYVHgA3AI5OzDO0dyiXpPbm8WW7ufe1zVRU1zhZTtsM\nuwxcAdptpJTqsNYMO10MrAaGiEi2iNwsIreJyG0t7DoMyBSRjVgB8KAxZqu9bh7wYxHZjXVO4Zn2\n/wodJyI88Z0x3HXeIP6VeZBrF67xnO6jwHAYfAF89R+o9aAgU0p1O+JJXSQZGRkmMzOzU9/jnU1f\n89N/byQ8yI+/XzeWUf0iOvX93OKr1+HfN8KYG2DavRDW1+mKlFLdiIistc/nNqtHX6ncmEtH9mHJ\n7RNx+Qjf/vtqXl+f7XRJLRt6GWTcBBtehr+Ngnd+CkVNnpZRSqlGaSA0YkTfcN76wSRG94vgR//a\nyJ/f3da9J8Bz+cFlj8Bd62DUtbD2WXg0XYNBKdUm2mXUjKqaWv7w9lZeWL2fKWfF8tjs0YQH+3XZ\n+7fbsf2w8v9ZLQbxgTHXw+QfQXii05UppRzQ2i4jDYRWWPzFAe57cwuJkcH84/qxDIoL7fIa2uXY\nflj1f7D+JQ0GpXowDQQ3+zKrgNtfWkt5VS1/m53O+cPiHamjXQoPwMq6YBAYfR2c+2MNBqV6CD2p\n7GbjkqJ46weTSYoJ5nsvZPLEst2ecxFbRH/45ny4ex2kz4F1L8Df0uHtH0ORB5w0V0p1CW0htNGJ\nyhrmvbaJtzYe4tKRffjrrJEE+/u2vGN3UnjQ6kpa96L1esx1MPnH1gyqSimvo11GncgYw99X7OWh\n97czrHcYC68fS2JksNNltd3pwTB6rtWVFNHf2bqUUm6lgdAFlm3P5e5X1uPn8mHBnDGcnRLtdEnt\nU3gQVj1idSWBBoNSXkbPIXSB6UPjeOPOSUQE+THn6c95ac1+p0tqn4h+cNn/wQ83wNgbrOGqj46B\n//7QOiGtlOoRtIXgBkUnqrjnlfUs25HHd87uz+++OQJ/Xw/O2qLsky0GY2D0HDj3J9piUMpDaZdR\nF6upNTz84Q4WLN/DuKRIFswdS0yvAKfL6piiHDsYnreC4ZwfwJSfg78Hni9RqgfTLqMu5vIR5l08\nlL/NTmdzThGXP7aKLTlFTpfVMeEJcOnDcPcGSPu2FQ5Png07P3C6MqVUJ9BAcLMr0hNYcts5GGDW\nU5/x1sZDTpfUceEJcNUCuPEd8A2Cf14Nr8zRaxiU8jIaCJ0gNSGct34wmbSEcO5evJ6H3t/evSfH\na62kyXDbKjj/t7D7I3h8PHz2ONRUt7yvUqrb00DoJLGhAbz8vQlcO74/C5bv4XvPf0lJhRd8cPr6\nW0NS71wDSZPgw1/Bwmlw8AunK1NKdZAGQify9/XhgW+l8YcrU/lkZx6PfbzL6ZLcJzIJvvMqXP0i\nnCiAZy6whqmWFThdmVKqnTQQusB1EwZwSWof/rnmAMXlVU6X4z4iMPxyuPNzmPgD64rnx8fBhsXW\nqCSllEfRQOgit05Jobiimn99edDpUtwvIBQu+hN8/xOISoY3boPnvwl5O5yuTCnVBhoIXWRUvwjO\nTo5i0ap9VNXUOl1O5+idBjd9CJfNh8ObYMEk+OgPUHXC6cqUUq2ggdCFvj81hUNF5by9yQuGojbF\nxwcyvgs/WAupM2Hlw/DE2bBrqdOVKaVa0GIgiMgiEckVkS0tbDdORKpFZJb9Ol1EVovIVyKySUSu\nabDtcyKyT0Q22I/0jv8q3d+0s+IYHNeLv3+y13PupdBevWLhW3+HG/4LLn94eRa8ej0c9+IwVMrD\ntaaF8BxwcXMbiIgLeAj4sMHiMuB6Y8wIe//5IhLRYP3PjDHp9mND28r2TD4+wi3nprD9cDErd+U7\nXU7XSJ4Ct38K5/3ausL58XGw+km9dkGpbqjFQDDGrABaGkt4F/AakNtgv53GmF3280P2utj2l+od\nrhjdl7jQABau2Ot0KV3HNwCm/AzuWAP9J8IHv4B/TIPs7jkvlVI9VYfPIYhIAnAVsKCZbcYD/sCe\nBov/ZHclPSIiTc4CJyK3ikimiGTm5eV1tFzHBfi6uHFSEqt253v+XEdtFZUMc/4NV78Apfnw9Azr\nNp4nCp2uTCmFe04qzwfmGWMaHTojIn2AF4HvNtjmF8BQYBwQBcxr6uDGmIXGmAxjTEZsrHc0MOac\nPYAQfxf/WNmDWgl1RGD4FXDnFzDhdlj7LDyeAetfhvIeFpBKdTPuCIQM4BURyQJmAU+KyJUAIhIG\nvAP8yhizpm4HY8zXxlIBPAuMd0MdHiM8yI/Z4/vz9qavyT5W5nQ5zggMg4sfgFuXW/dZePMOeHAA\nLJgM7/4MtvwHig87XaVSPUqH7w5vjEmuey4izwFvG2PeEBF/4HXgBWPMkob7iEgfY8zXIiLAlUCz\nI5i80U2Tk3nusyye/TSL31w23OlynNNnFNy8FLJWwf7P4MBqWP8SfLHQWh+ZDAPOgf4ToP85ED3Q\namUopdyuxUAQkcXANCBGRLKB3wJ+AMaYp5rZ9WpgChAtIjfay260RxS9LCKxgAAbgNva+wt4qoSI\nIL45sg+vfHGAu88fTHiQn9MlOcfHBSlTrQdATRV8vQkOfAb7V8OO96zbegKExFnhUBcS8Wng6vD3\nGqUUesc0R209dJxvPLqSn188hDumDXK6nO7LGMjfebIFsX81FNn3evYPhX7jrNbDgImQMBb8gpyt\nV6luprV3TNOvVg4a3jeMcwfH8OynWdw8OZkAX5fTJXVPIhA7xHpkfNdaVpQNB9acDIllf7SW+/hB\n39FWOPQ/B/qfDUGRztWulAfRFoLDVu7K47pnvuAvM0dy9bh+TpfjucoK4ODnJ1sQh9ZDbRUgEDcc\n+oy0ntdWg6mxftae/rPB8yZ02I+YAAAY4UlEQVS3abBtw21cfhAxwJoWvO4RlWz9DEvUbi3lqNa2\nEDQQHGaM4dJHV1FZU8uH90zBx0dPmLpFZRnkrLVaEQc+s2ZeFZd1vsLHBT6+9sNlL2/w+pSfrdym\nqgyO7YdjWVB4wA4jm7ggop91gryxwAgMd+RPpHoO7TLyECLCrVNSuOdfG1i2I5fzh8U7XZJ38A+G\n5HOtR1errYHjOVY41D0K9lk/t75p3VCooaBIOyQaCYywBCt4lOoC2kLoBqpqapn6l2UkRgXz6vcn\nOl2O6mzlRaeGRcPAKDpodUPV8fGzWhfRg61zIwljoO8Ya/JApVpJWwgexM/lw02Tk/njO9vYcLCQ\n9H4RLe+kPFdguHX9RZ9RZ66rqW7Quth3MjByt8GuDwH7C1x4v1MDom+6dj2pDtMWQjdRUlHNxAc+\n4tzBMTw5Z6zT5ajuqKLYuj7j0DrIWWf9PJZ1cn30ICsc6kKid5rVdaZ6PG0heJheAb7MOXsAC1fs\nYf/RUgZEhzhdkupuAkIhaZL1qFNWYAXDofWQsx6yVsLmV6114rJGWPVNPxkS8SOsEVFKNUJbCN3I\nkePlTH7oY64d35/7r0h1uhzlqY5/3aAVsd56fuKYtc4VYLUc6ruaRkPM4JZPXNfWQE2ldRV5TZX1\nvLbB8zOWn7ZMxLpRkivACiTfAPu1/fD1P/W1y9/aRk+ou4W2EDxQfFggV6Yn8GrmQe6ZcRZRIf5O\nl6Q8UVgfCLsUhl5qvTbG6lpqGBLrXz45X5R/L2s0U3Mf8I1PZtz5xMcOkUZCo/51gHV1ekAv68r1\ngF7W71T/M7TB60bWa+jU00DoZm6dksK/12bz4ur9/HDGYKfLUd5AxBrCGpVs3ecarG/8+btOhkRp\nboMPWz9rdFPdc5df88t9fBvs2+B5/XK7i6q6wg6ZCitoqivt8LGXV9vL6x6Nrq9qfJ/yQuvq9coS\n61xLZUnrQ8wv5LSQaCI0amuscDW11kWJptZ61NY9N00sP+1xynL7mD4uK9h87YDztVtSHV5mh2kr\naSB0M4PjQzlvaBwvrM7i+1NTCPTTby+qE/i4IG6o9Uj/jtPVuJ8x1sWCFSWnhkRrXx8/dOprU2u1\nVsRl/xT7gkWf05b7gI9P65f7uACxg+2YHYINw67i5LIuaKVpIHRDt05JYfbCNSxZm83cCQOcLkcp\nzyMC/iHWAy+52LO25syQaCw46ltXDZb9/oZWvYUGQjd0dnIUoxLDeXrlXq4d3x+XTmehlPJx2cOI\n2zOUuHWB4I47pik3s6azGEjW0TKWbtW7himluoYGQjd1cWpv+kcF8/cVe/GkocFKKc+lgdBNuXyE\n752bzPoDhWTuP+Z0OUqpHkADoRubNTaRiGA/Fq7Y63QpSqkeQAOhGwv29+X6CQP437Yj7Mkrcboc\npZSX00Do5q4/Jwl/lw9Pr9RWglKqc2kgdHMxvQKYOTaR19blkFdc4XQ5Sikv1qpAEJFFIpIrIlta\n2G6ciFSLyKwGy24QkV3244YGy8eKyGYR2S0ij4qIDrZvwi3nplBVU8vzn2U5XYpSyou1toXwHHBx\ncxuIiAt4CPiwwbIo4LfA2cB44LciEmmvXgDcAgy2H80evydLjgnhwuHxvLhmP6UV1S3voJRS7dCq\nQDDGrAAKWtjsLuA1ILfBsouApcaYAmPMMWApcLGI9AHCjDFrjDXI/gXgyjZX34PcOmUgRSeqeDXz\noNOlKKW8lFvOIYhIAnAV1rf+hhKAhp9g2fayBPv56csbO/atIpIpIpl5eXnuKNcjjR0QScaASJ5Z\ntY/qGoemIlZKeTV3nVSeD8wzxv3T8RljFhpjMowxGbGxPfvG4rdOSSH72Ane3aLTWSil3M9dgZAB\nvCIiWcAs4EkRuRLIAfo12C7RXpZjPz99uWrGjGHxpMSGsHDFHp3OQinldm4JBGNMsjEmyRiTBCwB\n7jDGvAF8AFwoIpH2yeQLgQ+MMV8Dx0Vkgj266HrgTXfU4s18fIRbzk1hS85xVu896nQ5Sikv09ph\np4uB1cAQEckWkZtF5DYRua25/YwxBcAfgC/tx/32MoA7gKeB3cAe4L12/g49ylWjE4jp5a/TWSil\n3K5V90Mwxlzb2gMaY2487fUiYFEj22UCeif5Ngr0c3HDxCT+39Kd7DhczJDeoU6XpJTyEnqlsgea\nO2EAQX4ubSUopdxKA8EDRYb4c824fry1MYfDReVOl6OU8hIaCB7q5snJ1NQanv10n9OlKKW8hAaC\nh+oXFcw30vrwz88PUFxe5XQ5SikvoIHgwb4/ZSDFFdUs/uKA06UopbyABoIHS0sMZ2JKNItWZVFZ\nrdNZKKU6RgPBw906NYXDx8t5e9Mhp0tRSnk4DQQPN+2sWIbEh7JwxV6dzkIp1SEaCB5ORLhlSgrb\nDxfzrQWf8fjHu9iSU6ThoJRqs1Zdqay6tyvT+3LkeDnvbznMwx/u5OEPdxIbGsC0s2KZPjSOyYNj\nCAv0c7pMpVQ3J570TTIjI8NkZmY6XUa3lltczoqd+SzbkcvKnXkcL6/G5SOMHRDJ9CFxTBsSy9De\noegdS5XqOURkrTEmo8XtNBC8V3VNLesPFrJsey7Ld+Sx9evjAPQOC2T60FimnmW1HnoFaENRKW+m\ngaDOcLionE92WuGwclc+JRXV+LmEcUlRTBsSy/QhcQyK66WtB6W8jAaCalZVTS2ZWcdYvjOX5dvz\n2HGkGICEiKD6cDhnUDTB/tp6UMrTaSCoNjlUeILlO/JYtiOXT3fnU1ZZg7/Lh7NTopg2JI7pQ2JJ\nie3ldJlKqXbQQFDtVlFdQ2bWMevcw848dueWADB5UAzfn5rC5EEx2q2klAfRQFBuc7CgjP9uOsSz\nn2aRV1xBakIY358ykEtSe+Pr0ktZlOruNBCU21VU1/D6uhwWrtjL3vxS+kcFc8uUFL49NpFAP5fT\n5SmlmqCBoDpNTa1h6dYjPPXJHjYcLCQ6xJ8bz0niuokDiAj2d7o8pdRpNBBUpzPG8Pm+Ap76ZA/L\nd+QR7O/i2vH9uXlyMn0jgpwuTyll00BQXWrb18dZuGIvb208hACXp/fltqkDOSs+1OnSlOrxWhsI\nLZ4RFJFFIpIrIluaWH+FiGwSkQ0ikikik+3l0+1ldY9yEbnSXveciOxrsC69rb+g6l6G9QnjkWvS\n+eRn05g7YQDvbT7MhY+s4ObnvuSLfQU62Z5SHqDFFoKITAFKgBeMMamNrO8FlBpjjIiMBF41xgw9\nbZsoYDeQaIwpE5HngLeNMUvaUqy2EDzHsdJKXli9n+dXZ1FQWsmY/hHcNnUgM4bF4+OjQ1aV6kpu\nayEYY1YABc2sLzEnUyUEaCxhZgHvGWPKWno/5R0iQ/z54YzBfDrvPO6/YgS5xRXc+uJaLpy/glcz\nD+od3pTqhtwyiFxErhKR7cA7wE2NbDIbWHzasj/ZXU2PiEhAM8e+1e6KyszLy3NHuaoLBfm7uH5i\nEst/Oo2/zU7Hz+XDz5ds4ty/fMzCFXsoLq9yukSllK1VJ5VFJAmri+eMLqPTtpsC3GeMmdFgWR9g\nE9DXGFPVYNlhwB9YCOwxxtzfUh3aZeT5jDGs2JXPU8v3sHrvUUIDfbluwgBunJREXGig0+Up5ZXc\n1mXUFnb3UoqIxDRYfDXwel0Y2Nt9bSwVwLPAeHfWobovEWHqWbEsvnUCb945iXMHx7Dgkz1M/cty\nMrOa7JlUSnWBDgeCiAwSe2IbERkDBABHG2xyLad1F9ktBOz9rgQaHcGkvNuofhE8OWcsH/9kGr3D\nA7nlhUyy8kudLkupHqs1w04XA6uBISKSLSI3i8htInKbvclMYIuIbACeAK6pO8lsdzX1Az457bAv\ni8hmYDMQA/zRHb+M8kzJMSE8e+M4AL773JccK610uCKleia9ME11G5lZBXzn6c8ZlRjOizefrfMj\nKeUmjpxDUKojMpKi+H/fHsWXWcf4+ZJN1NZ6zpcVpbyB3g5LdSvfHNWXg8fK+Mv7O+gfFcxPLxri\ndElK9RgaCKrbuX3qQA4cLePxZbvpHxXM1eP6OV2SUj2CBoLqdkSEP1yZSk7hCX75+mb6RgQxeXBM\nyzsqpTpEzyGobsnP5cMTc8YwMLYXt7+0lh2Hi50uSSmvp4Gguq2wQD8WfXccgf4ubnruS3KPlztd\nklJeTQNBdWsJEUEsumEcBaWV3Px8JmWV1U6XpJTX0kBQ3V5aYjiPXTuarw4VcffiDdTocFSlOoUG\ngvIIM4bHc99lw/nftiP88Z2tTpejlFfSUUbKY9w4KZn9BWU8+2kWA6KCuXFSstMlKeVVNBCUR/n1\npcPJPnaC+9/eSmJkMDOGxztdklJeQ7uMlEdx+Qh/m51OakI4dy1ez+bsIqdLUspraCAojxPs78vT\nN2QQFeLPTc9/SU7hCadLUsoraCAojxQXGsiz3x1HeVUNNz37Jcf1VpxKdZgGgvJYZ8WH8tTcsezJ\nK+GOl9ZRVVPrdElKeTQNBOXRJg2K4c/fSmPV7nx+/foWPOn+Hkp1NzrKSHm8qzP6nZwdNTqYO6cP\ncrokpTySBoLyCj+58CwOFJTx1w920C8qmMtH9XW6JKU8jgaC8goiwl+/PZKvi07w039vpG94IBlJ\nUU6XpZRH0XMIymsE+LpYeF0GCRFB3PJCJln5pV3yvuVVNRw5Xk61ntRWHk486SRcRkaGyczMdLoM\n1c1l5Zdy1ZOfEhHsz39uP4fIEH+3HPdYaSW780rYk1vC7twS9uSVsDuvhOxjJzAGfARiQwPoHRZI\nfFggvcPtn2GB9AkPJD7ceh4S4N0N82Ollew4UsyOw8VsP1zMziPFlJRXE+jnQ6Cfi0A/F0F+rlNe\nn74syM9FgJ+PvcxFkL+LQN9T97GW+eDr8qzvtcYYDhWVs+tIMbuOlLDvaCn9IoMZnxxFWkI4/r7u\n/31EZK0xJqPF7VoKBBFZBFwG5BpjUhtZfwXwB6AWqAbuMcasstfVAJvtTQ8YYy63lycDrwDRwFrg\nOmNMZUvFaiCo1lq7v4Br//E5oxLDefHmswn0c7Vqv9paQ07hifoP/j15JezJLWV3XgkFpSf/iQb4\n+pAS24tBcb0YGBtCdIg/ucUVHC4q5/Dx8vqfxeVnTtcdGuBbHw697Z/1r8MCiQ8PICYkAB8fcdvf\nozOUV9Ww60gJ2w8fZ+cR68N/x+Ficosr6rcJD/JjSO9QIoL8KK+upbyqhoqqGk5U1VBeVWv/rKGi\nqpbKdrawfH2EmF4B9I8OZkBUMAOig+kfHVL/PCLYPV8I2qru39KuXOuDf+eREnbnFrM7t4TSypr6\n7cKD/Cg6YV1HE+jnw5j+kYxPjmJ8chSj+0US5N+6f7vNcWcgTAFKgBeaCIReQKkxxojISOBVY8xQ\ne12JMaZXI/u8CvzHGPOKiDwFbDTGLGipWA0E1RZvbzrED/65nstH9WX+NemnfMCWV9WQdbTU+qZv\nf+DvyS1hb34J5VUnP5gig/0YFFf3wd+LgXG9GBTbi4SIoFZ9YJdVVteHw5Hj5RwuquBw0QkrNI5X\ncKSonNzick6f0dvXR4gPCyQ+LIDe4YHEhQYSFeJ/yiM6xJ/IEH8ig/1xdWJ41NQa9h8trf/Gv+Nw\nMTuOFLP/aGl93QG+PgyO78VZ8aEM7R3KkN5hDO0dSlxoACKtq62m1lBuB0RdYNS9bhgeDZeVV9VQ\nZnfZHThaxv6CMvIaBBJAWKAvSTEh9LcDYkBUiBUe0cHEhwZ2OHhrag0HC8rYlVvCrtxidh8pYZfd\nijxRdfKDPy40gLPiQxkU14vB8b0YHBfK4LheRIb4c7Skgi+zjvH5vqN8sa+ArV8fxxjwcwkjEyPq\nAyJjQCShgX5trtFtgWAfLAl4u7FAOG27icAiY8ww+/UZgSDWv448oLcxptre53fGmItaqkMDQbXV\nk8t385f3dzBrbCJRIf71XT0HC8rqP8xErBvx1H3oN/wZ5abupubU1BryS6zWxddFdnAcL+dIXWvj\neDl5xysormj85kAiEBHkd1pgBBAV4kdUSADRpwVJVIh/oy0mYwy5xRVWN0/dh/+R4+w6UkJFdW39\neyVFhzAkPpQhva0P/7N6h5IUHdKpodQWZZXVHCgoY//RMjskSq3nBWXkHDtBdYP09ff1sYIiKrhB\nC8MKjMTIIAJ8T/6dqmtqOVBQVv9Nf1duCbuOWP+e6v4+AH3CAxkUZ4XjYPvDf1BsKOHBrf8gP15e\nxdqsY3y+r4Av9h1lU3YR1bUGH4ERfcPrA2JcUlSr/o12aSCIyFXAA0AccKkxZrW9vBrYgNWV9KAx\n5g0RiQHWGGMG2dv0A95r5ti3ArcC9O/ff+z+/ftbrFepOsYYfvXGFv75+QH8fX1IiQlh4Ckf/CGk\nxPRyS7O8s1VU11BYVsXRkkoKSispKKukoKTi5PPSSo6WVHLMfl5QWnlGy6NOsL/rlFbGicoadhwp\nprDs5BQgcaEBDOkd2uDDP4xBcZ7xt2pKdU0thwrLTwmJ/UdPPi9r0JUjAn3Dg0iMDKLoRBV780pP\n6dZKiAiyv+n3YrD94T8orle7vsG3pKyymg0HCvl8XwGf7zvK+gOF9SF0VnwvOyCiOTs5iviwwDP2\nd6qFMAW4zxgzw36dYIzJEZEU4GPgfKCINgRCQ9pCUO2VV1xBVEjndq10N7W1huPlVRwtPTMs6p5b\n6yrwd/nUd/PUhYC7TsZ7CmMM+SWVHLDDoi4kDhaUER7kxyC7m+eseOsLhZODAyqqa9icXWS3IApY\nu/8YJXYLckB0MOOTrBbEhJRoEiOD8PHxaVUguPU3MsasEJEUEYkxxuQbY3Ls5XtFZDkwGngNiBAR\nX2NMNZAI5LizDqVOFxsa4HQJXc7HR4gI9ici2J+BsU5X0/2JCLGhAcSGBjB2QPe+hiXA10VGUhQZ\nSVHcOd1q+Wz7urj+HMTSbUf499pswOrCaq0OB4KIDAL22CeVxwABwFERiQTKjDEVdjfRJOAv9nbL\ngFlYI41uAN7saB1KKdVT+bp8SEsMJy0xnO+dm0JtrWF3XonVxbT3KGtaeZzWjDJaDEwDYoAjwG8B\nPwBjzFMiMg+4HqgCTgA/M8asEpFzgL9jDUf1AeYbY56xj5mCFQZRwHpgrjHm1KEBjdAuI6WUaju3\nnkPoLjQQlFKq7VobCJ51iZ9SSqlOo4GglFIK0EBQSill00BQSikFaCAopZSyaSAopZQCNBCUUkrZ\nPOo6BBHJAzpzdrsYIL8Tj9/ZPLl+T64dtH6naf3NG2CMaXECE48KhM4mIpmtuXiju/Lk+j25dtD6\nnab1u4d2GSmllAI0EJRSStk0EE610OkCOsiT6/fk2kHrd5rW7wZ6DkEppRSgLQSllFI2DQSllFKA\nBgIi0k9ElonIVhH5SkR+6HRN7SEiLhFZLyJvO11LW4lIhIgsEZHtIrJNRCY6XVNbiMiP7H87W0Rk\nsYi0/p6FDhCRRSKSKyJbGiyLEpGlIrLL/hnpZI3NaaL+v9r/fjaJyOsiEuFkjc1prP4G634iIsa+\ny2SX6/GBAFQDPzHGDAcmAHeKyHCHa2qPHwLbnC6inf4GvG+MGQqMwoN+DxFJAO4GMowxqYALmO1s\nVS16Drj4tGX3Ah8ZYwYDH9mvu6vnOLP+pUCqMWYksBP4RVcX1QbPcWb9iEg/4ELgQFcXVKfHB4Ix\n5mtjzDr7eTHWh1GCs1W1jYgkApcCTztdS1uJSDgwBXgGwBhTaYwpdLaqNvMFgkTEFwgGDjlcT7OM\nMSuAgtMWXwE8bz9/HriyS4tqg8bqN8Z8aIyptl+uARK7vLBWauLvD/AI8HPAsZE+PT4QGhKRJGA0\n8LmzlbTZfKx/SLVOF9IOyUAe8Kzd5fW0iIQ4XVRrGWNygIexvtV9DRQZYz50tqp2iTfGfG0/PwzE\nO1lMB90EvOd0EW0hIlcAOcaYjU7WoYFgE5FewGvAPcaY407X01oichmQa4xZ63Qt7eQLjAEWGGNG\nA6V07+6KU9h97VdgBVtfIERE5jpbVccYayy6R45HF5FfYXUDv+x0La0lIsHAL4H7nK5FAwEQET+s\nMHjZGPMfp+tpo0nA5SKSBbwCnCciLzlbUptkA9nGmLpW2RKsgPAUM4B9xpg8Y0wV8B/gHIdrao8j\nItIHwP6Z63A9bSYiNwKXAXOMZ11gNRDrC8VG+/9xIrBORHp3dSE9PhBERLD6r7cZY/7P6Xrayhjz\nC2NMojEmCetk5sfGGI/5hmqMOQwcFJEh9qLzga0OltRWB4AJIhJs/1s6Hw86Kd7AW8AN9vMbgDcd\nrKXNRORirG7Ty40xZU7X0xbGmM3GmDhjTJL9/zgbGGP/3+hSPT4QsL5hX4f1zXqD/fiG00X1MHcB\nL4vIJiAd+LPD9bSa3bJZAqwDNmP9n+oW0xA0RUQWA6uBISKSLSI3Aw8CF4jILqxWz4NO1ticJup/\nHAgFltr/h59ytMhmNFF/t6BTVyillAK0haCUUsqmgaCUUgrQQFBKKWXTQFBKKQVoICillLJpICil\nlAI0EJRSStn+P8SGyjG1maNkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3leC5524UWz",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning, unfreeze layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0xb61JkZ0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1Y_b7XtXJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "#modelname = base_path +'resnext50-Adam-lr0.03-StepLR_4-epo15.pth'\n",
        "\n",
        "modely = models.resnext50_32x4d(pretrained=True)\n",
        "\n",
        "#modely.load_state_dict(torch.load(modelname),strict=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au_JXIwPuBe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(modely)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0wD2OUVkcwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in modely.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "fc_in = modely.fc.in_features\n",
        "\n",
        "transferclassifier = nn.Sequential(\n",
        "                        nn.BatchNorm1d(fc_in),\n",
        "                        nn.Linear(fc_in, 7),\n",
        "                        #nn.ReLU(),\n",
        "                        #nn.Linear(1024, 133)\n",
        "                        )\n",
        "\n",
        "#transfermodel.fc = transferclassifier # resnet\n",
        "modely.fc = transferclassifier\n",
        "modely.apply(weights_init_normal)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modely.to(device);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhOfpBFuEfh",
        "colab_type": "code",
        "outputId": "3a77a539-7138-458a-d52f-1ed0d7d3ace1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "\n",
        "criterion_tf = nn.CrossEntropyLoss()  \n",
        "\n",
        "lr_tf = 1e-3\n",
        "optimizer_tf = optim.Adam(modely.parameters(), lr=lr_tf)\n",
        "\n",
        "stepsize_tf = 7\n",
        "scheduler_tf = lr_scheduler.StepLR(optimizer_tf, step_size=stepsize_tf, gamma=0.1)\n",
        "\n",
        "epochs_ft = 20\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname_xy = '{}tf_resnext50-{}-lr{}-{}{}-epo{}.pth'.format(\n",
        "    save_path, \n",
        "    'Adam', \n",
        "    lr_tf, \n",
        "    'StepLR_', \n",
        "    stepsize_tf, \n",
        "    epochs_ft\n",
        ")\n",
        "\n",
        "print(modelname_xy)\n",
        "\n",
        "modelxy = train_model(\n",
        "    modely, \n",
        "    modelname_xy, \n",
        "    criterion_tf, \n",
        "    optimizer_tf, \n",
        "    scheduler_tf, \n",
        "    epochs_ft, \n",
        "    device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/tf_resnext50-Adam-lr0.001-StepLR_7-epo20.pth\n",
            "starting the training at 19:27:37\n",
            "Epoch: 1 at 19:42:33 \tTrain. Loss: 1.577323 \tValid. Loss: 1.562634 \t Accur.: 0.4001114517\n",
            "*** Validation loss decreased (inf --> 1.562634).  Saving model ...\n",
            "Epoch: 2 at 19:47:58 \tTrain. Loss: 1.507071 \tValid. Loss: 1.544317 \t Accur.: 0.4104207300\n",
            "*** Validation loss decreased (1.562634 --> 1.544317).  Saving model ...\n",
            "Epoch: 3 at 19:53:23 \tTrain. Loss: 1.481276 \tValid. Loss: 1.518490 \t Accur.: 0.4271384787\n",
            "*** Validation loss decreased (1.544317 --> 1.518490).  Saving model ...\n",
            "Epoch: 4 at 19:58:49 \tTrain. Loss: 1.468990 \tValid. Loss: 1.524944 \t Accur.: 0.4240735581\n",
            "Epoch: 5 at 20:4:14 \tTrain. Loss: 1.456688 \tValid. Loss: 1.507987 \t Accur.: 0.4329896907\n",
            "*** Validation loss decreased (1.518490 --> 1.507987).  Saving model ...\n",
            "Epoch: 6 at 20:9:40 \tTrain. Loss: 1.448987 \tValid. Loss: 1.507886 \t Accur.: 0.4335469490\n",
            "*** Validation loss decreased (1.507987 --> 1.507886).  Saving model ...\n",
            "Epoch: 7 at 20:15:6 \tTrain. Loss: 1.392051 \tValid. Loss: 1.465108 \t Accur.: 0.4458066314\n",
            "*** Validation loss decreased (1.507886 --> 1.465108).  Saving model ...\n",
            "Epoch: 8 at 20:20:31 \tTrain. Loss: 1.378714 \tValid. Loss: 1.458564 \t Accur.: 0.4474784062\n",
            "*** Validation loss decreased (1.465108 --> 1.458564).  Saving model ...\n",
            "Epoch: 9 at 20:25:57 \tTrain. Loss: 1.373702 \tValid. Loss: 1.451046 \t Accur.: 0.4471997771\n",
            "*** Validation loss decreased (1.458564 --> 1.451046).  Saving model ...\n",
            "Epoch: 10 at 20:31:22 \tTrain. Loss: 1.369122 \tValid. Loss: 1.453182 \t Accur.: 0.4494288103\n",
            "Epoch: 11 at 20:36:47 \tTrain. Loss: 1.369987 \tValid. Loss: 1.451697 \t Accur.: 0.4513792143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-666ce5f12355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mscheduler_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-7-9d0348e5d8ec>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, name, criteria, optimizer, scheduler, epochs, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0csjXEyJbjK",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcUMyEhJasV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loader, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    print('test started at ', get_time())\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('test finished at ', get_time())\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh5CaGYNLErC",
        "colab_type": "code",
        "outputId": "f80edbb2-5be5-4810-9855-46f0b12cd653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "# call test function    \n",
        "test(dataloaders['test'], model_ft, criteria, device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test started at  (11, 19, 37)\n",
            "test finished at  (11, 21, 48)\n",
            "Test Loss: 1.883936\n",
            "\n",
            "\n",
            "Test Accuracy: 24% (875/3589)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUS0Xhf4pLc",
        "colab_type": "text"
      },
      "source": [
        "### Unused stuff ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY9tuHQsubgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-WTxtUsKc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model as a checkpoint file after every 5 epochs\n",
        "def save_model_checkpoint(model, optimizer, criteria, epochs):\n",
        "  model.to('cpu')\n",
        "  model.class_to_idx = datasets['train'].class_to_idx\n",
        "  checkpoint = {'input_size': 48*48*1,\n",
        "                'output_size': 7,\n",
        "                'model': model,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'criterion': criteria,\n",
        "                'epochs': epochs,\n",
        "                'class_to_idx': model.class_to_idx}\n",
        "\n",
        "  path = \"/content/gdrive/My Drive/facial_expressions.pth\"\n",
        "  torch.save(checkpoint,path)\n",
        "\n",
        "\n",
        "# load model function \n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath, map_location='cpu')\n",
        "    model = checkpoint[\"model\"]\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_4i2xcK_Lfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}