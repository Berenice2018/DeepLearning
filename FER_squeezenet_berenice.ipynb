{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER-squeezenet-berenice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "GcA_vwhUrURY",
        "rj5m7HOg3gHn",
        "I3leC5524UWz",
        "ajUS0Xhf4pLc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/FER_squeezenet_berenice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh9XQ8vR84zw",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xdgcVYCJpkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f4c5af99-6ead-4915-9425-30116fdf4133"
      },
      "source": [
        "# Imports here\n",
        "#!pip install git+https://github.com/pytorch/vision\n",
        "\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torchvision.models as models\n",
        "from torchvision.models.squeezenet import  model_urls\n",
        "squeezenet1_0_state_dict = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "import os,cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#from pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20, 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /root/.cache/torch/checkpoints/squeezenet1_0-a815701f.pth\n",
            "100%|██████████| 5017600/5017600 [00:00<00:00, 16207423.76it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCJINZX0Kcpk",
        "colab_type": "code",
        "outputId": "be634c19-05d9-4368-b4d8-d708941e6e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl8ynY8-MVOg",
        "colab_type": "code",
        "outputId": "91cc73d3-c488-49d9-c678-1363a0b40c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fer= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/fer2013.csv\"\n",
        "ferr= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset\"\n",
        "\n",
        "#!ls   '/content/gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.bib  fer2013.csv  PrivateTest  PublicTest  README  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lVhUAPOZa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcA_vwhUrURY",
        "colab_type": "text"
      },
      "source": [
        "### Convert and save images to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5WuBM0VOJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yAg9oU_radg",
        "colab_type": "text"
      },
      "source": [
        "### Load data , image transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvDN0ydqjQ-",
        "colab_type": "code",
        "outputId": "bb1fc400-7353-4282-c424-16efa42b3a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "data_dir = \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013\"\n",
        "train_dir = data_dir + '/Training'\n",
        "valid_dir = data_dir + '/PublicTest'\n",
        "test_dir = data_dir + '/PrivateTest'\n",
        "\n",
        "# original img size = 48 x48 px\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        #transforms.CenterCrop(256),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    }\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir,\n",
        "        'test': test_dir}\n",
        "\n",
        "datasets = {x: torchvision.datasets.ImageFolder(dirs[x], transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32, shuffle=True, num_workers=7) for x in ['train', 'valid','test']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) \n",
        "                              for x in ['train', 'valid','test']}\n",
        "print(dataset_sizes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 32556, 'valid': 3589, 'test': 3589}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9fxwj-f-wG",
        "colab_type": "code",
        "outputId": "86ebc428-337c-4192-b606-26a9055cbf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names = datasets['train'].classes\n",
        "print(class_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj5m7HOg3gHn",
        "colab_type": "text"
      },
      "source": [
        "### Show some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9_rLvF03kGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a batch of training images\n",
        "dataiter = iter(dataloaders['train'])\n",
        "images, _ = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy\n",
        "\n",
        "# plot the images of the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 16/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1gi4Auz4D_l",
        "colab_type": "text"
      },
      "source": [
        "### Model train helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMm_P_CERmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "    \n",
        "\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwzo4GzQsAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, name, criteria, optimizer, scheduler = None, epochs=50, device='cuda'):\n",
        "    h, m, s = get_time()\n",
        "    print('starting the training at {}:{}:{}'.format(h, m, s))\n",
        "    since = time.time()\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    # initialize tracker for accuracy \n",
        "    min_loss = np.Inf\n",
        "    TS_loss = pd.DataFrame(np.nan, index = range(1,epochs+1), columns = ['train loss','valid loss'])\n",
        "    TS_acc = pd.DataFrame(np.nan,index = range(1,epochs+1), columns = ['train acc','valid acc'])\n",
        "    \n",
        "    for epoch in range(1, epochs+1):        \n",
        "        # monitor loss/accuracy\n",
        "        train_loss_running = 0.0\n",
        "        valid_loss_running = 0.0\n",
        "        train_acc_running = 0.0\n",
        "        valid_acc_running = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        model.train() # prep model for training\n",
        "        \n",
        "        for data, target in dataloaders['train']:\n",
        "    \n",
        "            # Move input and data tensors to the default device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criteria(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss \n",
        "            train_loss_running += loss.item()*data.size(0)\n",
        "            # accuracy\n",
        "            _, preds = torch.max(output, 1)\n",
        "            train_acc_running  += torch.sum(preds == target.data)\n",
        "    \n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloaders['valid']:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criteria(output, target)\n",
        "                valid_loss_running += loss.item()*data.size(0)\n",
        "                \n",
        "                _, preds = torch.max(output, 1)\n",
        "                valid_acc_running  += torch.sum(preds == target.data)\n",
        "                #print('valid_acc_running {:.6f}'.format(valid_acc_running))\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                #ps = torch.exp(logps)\n",
        "                #top_p, top_class = ps.topk(1, dim=1)\n",
        "                #equals = top_class == labels.view(*top_class.shape)\n",
        "                #valid_loss_running += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        # statistics\n",
        "        train_loss = train_loss_running/ dataset_sizes['train']\n",
        "        valid_loss = valid_loss_running/ dataset_sizes['valid']\n",
        "        train_acc = train_acc_running.double()/ dataset_sizes['train']\n",
        "        valid_acc = valid_acc_running.double()/ dataset_sizes['valid']\n",
        "        \n",
        "        TS_loss.loc[epoch] = [train_loss, valid_loss]\n",
        "        TS_acc.loc[epoch] = [(train_acc.cpu().numpy()), (valid_acc.cpu().numpy())]                                         \n",
        "\n",
        "        # print training/validation statistics \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  train_loss,\n",
        "                  valid_loss,\n",
        "                  valid_acc \n",
        "        ))\n",
        "                                                             \n",
        "        # save model if validation acc has increased\n",
        "        # BC: using the lower validation loss as criterium, when saving a model\n",
        "        if valid_loss <= min_loss:\n",
        "            old_loss_min = min_loss\n",
        "            min_loss = valid_loss\n",
        "            save = True\n",
        "            \n",
        "            print('*** Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            old_loss_min, min_loss))        \n",
        "    \n",
        "    #End\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    #print('Best Valid Acc: {:4f}'.format(best_acc))\n",
        "                                                   \n",
        "    TS_loss.plot(title = 'loss')\n",
        "    TS_acc.plot(title = 'acc')\n",
        "                                                   \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model)\n",
        "    torch.save(model.state_dict(), name)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AGfumpM4Lik",
        "colab_type": "text"
      },
      "source": [
        "### Hyper params, start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeUCHPa_40ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a892f468-faab-4cf1-ee27-8fbce70f926e"
      },
      "source": [
        "#model = torch.hub.load_state_dict_from_url(model_urls['squeezenet1_0'])\n",
        "#model = torch.hub.load('pytorch/vision', 'squeezenet1_0', pretrained=True)\n",
        "\n",
        "no_of_classes = 7\n",
        "transfermodel = models.squeezenet1_0(pretrained =True)\n",
        "\n",
        "for param in transfermodel.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "transfermodel.classifier[1] = nn.Conv2d(512, no_of_classes, kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "#transfermodel.apply(weights_init_normal)\n",
        "\n",
        "#transfermodel.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transfermodel.to(device);\n",
        "\n",
        "transfermodel"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SqueezeNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (3): Fire(\n",
              "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (4): Fire(\n",
              "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (5): Fire(\n",
              "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (7): Fire(\n",
              "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (8): Fire(\n",
              "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (9): Fire(\n",
              "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (10): Fire(\n",
              "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (12): Fire(\n",
              "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Conv2d(512, 7, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU(inplace)\n",
              "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hrVk_TkscuM",
        "colab_type": "code",
        "outputId": "0cf2924d-098c-423b-d66d-00c1f5de7ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()    \n",
        "lr = 5e-3 #1e-2 #1e-3\n",
        "optimizer = optim.Adam(transfermodel.parameters(), lr=lr)\n",
        "\n",
        "stepsize = 4\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=stepsize, gamma=0.1)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [4, 7, 10, 12], 0.2)\n",
        "\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname = '{}squeeze1_0-{}-lr{}-{}{}-epo{}.pth'.format(save_path, 'Adam', lr, 'MultiStep4_7_10_12', stepsize, epochs)\n",
        "\n",
        "print(modelname)\n",
        "\n",
        "model_ft = train_model(transfermodel, modelname, criteria, optimizer, scheduler, epochs, device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/squeeze1_0-Adam-lr0.005-MultiStep4_7_10_124-epo15.pth\n",
            "starting the training at 10:12:30\n",
            "Epoch: 1 at 10:42:16 \tTrain. Loss: 1.513116 \tValid. Loss: 1.511674 \t Accur.: 0.4541655057\n",
            "*** Validation loss decreased (inf --> 1.511674).  Saving model ...\n",
            "Epoch: 2 at 10:44:53 \tTrain. Loss: 1.448081 \tValid. Loss: 1.468687 \t Accur.: 0.4745054333\n",
            "*** Validation loss decreased (1.511674 --> 1.468687).  Saving model ...\n",
            "Epoch: 3 at 10:47:29 \tTrain. Loss: 1.431797 \tValid. Loss: 1.503380 \t Accur.: 0.4714405127\n",
            "Epoch: 4 at 10:50:7 \tTrain. Loss: 1.387956 \tValid. Loss: 1.445675 \t Accur.: 0.4842574533\n",
            "*** Validation loss decreased (1.468687 --> 1.445675).  Saving model ...\n",
            "Epoch: 5 at 10:52:44 \tTrain. Loss: 1.382197 \tValid. Loss: 1.435690 \t Accur.: 0.4831429368\n",
            "*** Validation loss decreased (1.445675 --> 1.435690).  Saving model ...\n",
            "Epoch: 6 at 10:55:21 \tTrain. Loss: 1.372908 \tValid. Loss: 1.423354 \t Accur.: 0.4878796322\n",
            "*** Validation loss decreased (1.435690 --> 1.423354).  Saving model ...\n",
            "Epoch: 7 at 10:57:59 \tTrain. Loss: 1.349729 \tValid. Loss: 1.418597 \t Accur.: 0.4937308442\n",
            "*** Validation loss decreased (1.423354 --> 1.418597).  Saving model ...\n",
            "Epoch: 8 at 11:0:36 \tTrain. Loss: 1.352900 \tValid. Loss: 1.418894 \t Accur.: 0.4931735860\n",
            "Epoch: 9 at 11:3:14 \tTrain. Loss: 1.350776 \tValid. Loss: 1.416217 \t Accur.: 0.4923376985\n",
            "*** Validation loss decreased (1.418597 --> 1.416217).  Saving model ...\n",
            "Epoch: 10 at 11:5:52 \tTrain. Loss: 1.349158 \tValid. Loss: 1.412083 \t Accur.: 0.4931735860\n",
            "*** Validation loss decreased (1.416217 --> 1.412083).  Saving model ...\n",
            "Epoch: 11 at 11:8:30 \tTrain. Loss: 1.352658 \tValid. Loss: 1.412527 \t Accur.: 0.4942881025\n",
            "Epoch: 12 at 11:11:7 \tTrain. Loss: 1.351924 \tValid. Loss: 1.412019 \t Accur.: 0.4942881025\n",
            "*** Validation loss decreased (1.412083 --> 1.412019).  Saving model ...\n",
            "Epoch: 13 at 11:13:45 \tTrain. Loss: 1.349185 \tValid. Loss: 1.410998 \t Accur.: 0.4940094734\n",
            "*** Validation loss decreased (1.412019 --> 1.410998).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3leC5524UWz",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning, unfreeze layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0xb61JkZ0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1Y_b7XtXJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "#modelname = base_path +'resnext50-Adam-lr0.03-StepLR_4-epo15.pth'\n",
        "\n",
        "modely = models.resnext50_32x4d(pretrained=True)\n",
        "\n",
        "#modely.load_state_dict(torch.load(modelname),strict=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au_JXIwPuBe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(modely)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0wD2OUVkcwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in modely.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "fc_in = modely.fc.in_features\n",
        "\n",
        "transferclassifier = nn.Sequential(\n",
        "                        nn.BatchNorm1d(fc_in),\n",
        "                        nn.Linear(fc_in, 7),\n",
        "                        #nn.ReLU(),\n",
        "                        #nn.Linear(1024, 133)\n",
        "                        )\n",
        "\n",
        "#transfermodel.fc = transferclassifier # resnet\n",
        "modely.fc = transferclassifier\n",
        "modely.apply(weights_init_normal)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modely.to(device);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhOfpBFuEfh",
        "colab_type": "code",
        "outputId": "3a77a539-7138-458a-d52f-1ed0d7d3ace1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "\n",
        "criterion_tf = nn.CrossEntropyLoss()  \n",
        "\n",
        "lr_tf = 1e-3\n",
        "optimizer_tf = optim.Adam(modely.parameters(), lr=lr_tf)\n",
        "\n",
        "stepsize_tf = 7\n",
        "scheduler_tf = lr_scheduler.StepLR(optimizer_tf, step_size=stepsize_tf, gamma=0.1)\n",
        "\n",
        "epochs_ft = 20\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname_xy = '{}tf_resnext50-{}-lr{}-{}{}-epo{}.pth'.format(\n",
        "    save_path, \n",
        "    'Adam', \n",
        "    lr_tf, \n",
        "    'StepLR_', \n",
        "    stepsize_tf, \n",
        "    epochs_ft\n",
        ")\n",
        "\n",
        "print(modelname_xy)\n",
        "\n",
        "modelxy = train_model(\n",
        "    modely, \n",
        "    modelname_xy, \n",
        "    criterion_tf, \n",
        "    optimizer_tf, \n",
        "    scheduler_tf, \n",
        "    epochs_ft, \n",
        "    device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/tf_resnext50-Adam-lr0.001-StepLR_7-epo20.pth\n",
            "starting the training at 19:27:37\n",
            "Epoch: 1 at 19:42:33 \tTrain. Loss: 1.577323 \tValid. Loss: 1.562634 \t Accur.: 0.4001114517\n",
            "*** Validation loss decreased (inf --> 1.562634).  Saving model ...\n",
            "Epoch: 2 at 19:47:58 \tTrain. Loss: 1.507071 \tValid. Loss: 1.544317 \t Accur.: 0.4104207300\n",
            "*** Validation loss decreased (1.562634 --> 1.544317).  Saving model ...\n",
            "Epoch: 3 at 19:53:23 \tTrain. Loss: 1.481276 \tValid. Loss: 1.518490 \t Accur.: 0.4271384787\n",
            "*** Validation loss decreased (1.544317 --> 1.518490).  Saving model ...\n",
            "Epoch: 4 at 19:58:49 \tTrain. Loss: 1.468990 \tValid. Loss: 1.524944 \t Accur.: 0.4240735581\n",
            "Epoch: 5 at 20:4:14 \tTrain. Loss: 1.456688 \tValid. Loss: 1.507987 \t Accur.: 0.4329896907\n",
            "*** Validation loss decreased (1.518490 --> 1.507987).  Saving model ...\n",
            "Epoch: 6 at 20:9:40 \tTrain. Loss: 1.448987 \tValid. Loss: 1.507886 \t Accur.: 0.4335469490\n",
            "*** Validation loss decreased (1.507987 --> 1.507886).  Saving model ...\n",
            "Epoch: 7 at 20:15:6 \tTrain. Loss: 1.392051 \tValid. Loss: 1.465108 \t Accur.: 0.4458066314\n",
            "*** Validation loss decreased (1.507886 --> 1.465108).  Saving model ...\n",
            "Epoch: 8 at 20:20:31 \tTrain. Loss: 1.378714 \tValid. Loss: 1.458564 \t Accur.: 0.4474784062\n",
            "*** Validation loss decreased (1.465108 --> 1.458564).  Saving model ...\n",
            "Epoch: 9 at 20:25:57 \tTrain. Loss: 1.373702 \tValid. Loss: 1.451046 \t Accur.: 0.4471997771\n",
            "*** Validation loss decreased (1.458564 --> 1.451046).  Saving model ...\n",
            "Epoch: 10 at 20:31:22 \tTrain. Loss: 1.369122 \tValid. Loss: 1.453182 \t Accur.: 0.4494288103\n",
            "Epoch: 11 at 20:36:47 \tTrain. Loss: 1.369987 \tValid. Loss: 1.451697 \t Accur.: 0.4513792143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-666ce5f12355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mscheduler_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-7-9d0348e5d8ec>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, name, criteria, optimizer, scheduler, epochs, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0csjXEyJbjK",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcUMyEhJasV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loader, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    print('test started at ', get_time())\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('test finished at ', get_time())\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh5CaGYNLErC",
        "colab_type": "code",
        "outputId": "c44443f9-7c50-4e41-b27d-9d3ad8328c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\n",
        "# call test function    \n",
        "test(dataloaders['test'], model_ft, criteria, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test started at  (25, 11, 34)\n",
            "test finished at  (25, 14, 21)\n",
            "Test Loss: 1.965151\n",
            "\n",
            "\n",
            "Test Accuracy: 17% (633/3589)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajUS0Xhf4pLc",
        "colab_type": "text"
      },
      "source": [
        "### Unused stuff ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY9tuHQsubgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-WTxtUsKc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model as a checkpoint file after every 5 epochs\n",
        "def save_model_checkpoint(model, optimizer, criteria, epochs):\n",
        "  model.to('cpu')\n",
        "  model.class_to_idx = datasets['train'].class_to_idx\n",
        "  checkpoint = {'input_size': 48*48*1,\n",
        "                'output_size': 7,\n",
        "                'model': model,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'criterion': criteria,\n",
        "                'epochs': epochs,\n",
        "                'class_to_idx': model.class_to_idx}\n",
        "\n",
        "  path = \"/content/gdrive/My Drive/facial_expressions.pth\"\n",
        "  torch.save(checkpoint,path)\n",
        "\n",
        "\n",
        "# load model function \n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath, map_location='cpu')\n",
        "    model = checkpoint[\"model\"]\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_4i2xcK_Lfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}