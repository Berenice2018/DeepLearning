{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySyft_Simple_Flower102.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "WzEJcZWH1qlV",
        "sBCLPYO82KSA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/PySyft_Simple_Flower102.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdE3SBhPLvM",
        "colab_type": "text"
      },
      "source": [
        "### Imports, setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25q0ORpka9Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# save the model on Google Drive, link Google drive to this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# After executing this cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/gdrive/My Drive/Colab Notebooks/flower_data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH5hlOtZ0-DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf ./PySyft\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Q12ZfYFeQp",
        "colab_type": "text"
      },
      "source": [
        "### Manual installation of PySyft necessary due to a PySyft bug "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxzzJbMwPU99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-encrypted\n",
        "! URL=\"https://github.com/Berenice2018/PySyft-Bc.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b master --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /master/null\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('./PySyft-Bc'))\n",
        "if module_path not in sys.path:\n",
        "     sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYl5e5KDRzir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cat './PySyft-Bc/syft/frameworks/torch/pointers/pointer_tensor.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5qOcLUPFnIv",
        "colab_type": "text"
      },
      "source": [
        "### Imports, paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYwkx91pLr_h",
        "colab_type": "code",
        "outputId": "db05529d-4e8c-4024-8bf2-ea437037381a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import syft as sy\n",
        "from syft.frameworks.torch.federated import FederatedDataset, FederatedDataLoader, BaseDataset\n",
        "\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 19:36:59.264672 140009701873536 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0726 19:36:59.375264 140009701873536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FfPa7ijL94N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths to training and test data\n",
        "data_dir = '/content/gdrive/My Drive/Colab Notebooks/flower_data/'\n",
        "train_dir = data_dir + 'train' # 'train'\n",
        "valid_dir = data_dir + 'valid' #'valid'\n",
        "\n",
        "#os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/\")\n",
        "#test_dir = data_dir + 'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8qj0XFdPVaP",
        "colab_type": "text"
      },
      "source": [
        "### Architecture and helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42QrxlZWMFpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make data loader based on the selected pre-trained model\n",
        "def get_datasets():\n",
        "    print('returning datasets')\n",
        "    # ResNet, DenseNet expect 224, Inception expects 299\n",
        "    #img_size = 299 if base == 'Inception' else 224 \n",
        "    img_size = 128\n",
        "\n",
        "    transforms_train = transforms.Compose([\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomResizedCrop(img_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "    transforms_test = transforms.Compose([\n",
        "        transforms.Resize(img_size + 1),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "    # Load the datasets with ImageFolder\n",
        "    trainset = datasets.ImageFolder(train_dir, transform=transforms_train)\n",
        "    validationset = datasets.ImageFolder(valid_dir, transform=transforms_train)\n",
        "    testset = datasets.ImageFolder(valid_dir, transform=transforms_test)\n",
        "       \n",
        "    return trainset, validationset, testset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzv3X5EOsC2P",
        "colab_type": "code",
        "outputId": "7c3a772d-8529-4f46-eb0d-edcf7fe5a725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check length\n",
        "\n",
        "trainset, validationset, testset = get_datasets()\n",
        "print('trainset {}, validationset {}, testset {}'.format(len(trainset), len(validationset), len(testset)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "returning datasets\n",
            "trainset 5464, validationset 818, testset 818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pimMQCE-LfV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transforms a torch.Dataset or a sy.BaseDataset into a sy.FederatedDataset. \n",
        "def get_federated_dataset(dataset, workers):\n",
        "    print('get_federated_dataset â€¦')\n",
        "    \n",
        "    datasets = []\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, \n",
        "                                              #sampler=train_sampler,\n",
        "                                              drop_last=True)\n",
        "    \n",
        "    for dataset_idx, (data, targets) in enumerate(data_loader):\n",
        "        worker = workers[dataset_idx % len(workers)]\n",
        "        data = data.send(worker)\n",
        "        targets = targets.send(worker)\n",
        "        datasets.append(BaseDataset(data, targets))  # .send(worker)\n",
        "\n",
        "    print(\"dataset_federate Done!\")\n",
        "    return FederatedDataset(datasets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXMjxfOOJ60",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSmpivhrE_rG",
        "colab_type": "code",
        "outputId": "22d26cf0-0aea-43c6-ee6b-cf8e7e3e6a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*28*28, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 102)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 3*28*28)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "      \n",
        "      \n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 4, 2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 4, 2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 4, 2, padding=1)\n",
        "        \n",
        "        self.fc1 = nn.Linear(32*8*8, 102) # depth * height*width\n",
        "        #self.fc2 = nn.Linear(1024, 102)\n",
        "\n",
        "# (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #print('x {}, size {}'.format(x.shape, x.size(0))) # x torch.Size([32, 3, 128, 128]), size 0\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print('in {}'.format(x.shape))  # in torch.Size([32, 16, 64, 64])\n",
        "        \n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        #print('max_pool2d {}'.format(x.shape)) # max_pool2d torch.Size([32, 16, 32, 32])\n",
        "        \n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print('conv2 {}'.format(x.shape)) # conv2 torch.Size([32, 32, 16, 16])\n",
        "        \n",
        "        x = F.max_pool2d(x, 2, 2) \n",
        "        #print('max_pool2d {}'.format(x.shape)) # max_pool2d torch.Size([32, 32, 8, 8])\n",
        "        \n",
        "        #x = F.relu(self.conv3(x))\n",
        "        #x = F.max_pool2d(x, 2, 2) \n",
        "        #print('max_pool2d {}'.format(x.shape)) #max_pool2d torch.Size([32, 64, 2, 2])\n",
        "        \n",
        "        x = x.view(-1, 32*8*8) # depth * height*width after maxPool\n",
        "        #x = x.view(-1, 64*4*4)\n",
        "        \n",
        "        #x = F.relu(self.fc1(x))\n",
        "        #x = self.fc2(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "      \n",
        "\n",
        "\n",
        "'''We can compute the spatial size of the output volume as a function of \n",
        "the input volume size (W), \n",
        "the kernel/filter size (F), \n",
        "the stride with which they are applied (S), \n",
        "and the amount of zero padding used (P) on the border. \n",
        "The correct formula for calculating how many neurons define the output_W \n",
        "is given by (Wâˆ’F+2P)/S +1.\n",
        "\n",
        "For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 \n",
        "we would get a 5x5 output. With stride 2 we would get a 3x3 output.'''"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We can compute the spatial size of the output volume as a function of \\nthe input volume size (W), \\nthe kernel/filter size (F), \\nthe stride with which they are applied (S), \\nand the amount of zero padding used (P) on the border. \\nThe correct formula for calculating how many neurons define the output_W \\nis given by (Wâˆ’F+2P)/S +1.\\n\\nFor example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 \\nwe would get a 5x5 output. With stride 2 we would get a 3x3 output.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzEJcZWH1qlV",
        "colab_type": "text"
      },
      "source": [
        "### Helpers, visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBpwJAis1lV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions for printing oput training progress data\n",
        "def print_epoch_start_stats(e_start, e_end, current_lr, current_vmin):\n",
        "\n",
        "    print('*** Epoch [{}/{}]: Training with LR [{:.6f}], current VLoss Min [{:.4f}]'.format(\n",
        "    e_start, e_end, current_lr, current_vmin))\n",
        "\n",
        "def print_epoch_end_stats(train_loss, valid_loss, valid_acc, epoch_time):\n",
        "\n",
        "    print('   Train loss: \\t{:.6f}'.format(train_loss))\n",
        "    print('   Valid loss: \\t{:.6f}'.format(valid_loss))\n",
        "    print('   Valid acc: \\t{:.6f}'.format(valid_acc))\n",
        "    print('*** Epoch completed in {:.0f}m {:.0f}s'.format(epoch_time // 60, epoch_time % 60))   \n",
        "    \n",
        "    \n",
        "    \n",
        "import datetime\n",
        "\n",
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkC85U0D1pMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize plot\n",
        "def plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(14,6), ncols=2)\n",
        "    ax1.plot(valid_losses, label='Validation loss')\n",
        "    ax1.plot(train_losses, label='Training loss')\n",
        "    ax1.legend(frameon=False)\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    #x_ticks = [x for x in range(0,n_epochs,2)]\n",
        "    #plt.xticks(x_ticks)\n",
        "    \n",
        "    ax2.plot(valid_accuracies, label = 'Validation accuracy')\n",
        "    ax2.legend(frameon=False)\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    \n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfKVDOI17MC",
        "colab_type": "text"
      },
      "source": [
        "### Helpers train, validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GenUmE4x1-qY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)\n",
        "        \n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, train_on_gpu=False):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        # move to GPU\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        model.send(data.location) # send the model to the right location\n",
        "        \n",
        "        ## find the loss and update the model parameters accordingly\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        model.get() # get the model back\n",
        "        current_loss = loss.get()\n",
        "        \n",
        "        # get the loss per batch and accumulate\n",
        "        train_loss += current_loss.item()\n",
        "        \n",
        "        # get the class, highest probability\n",
        "        probabilities = torch.exp(output)\n",
        "        _, top_class = probabilities.topk(1, dim=1)\n",
        "        \n",
        "        # check if the predicted class is correct\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        \n",
        "        acc = torch.mean(torch.tensor(equals))\n",
        "        train_accuracy += acc\n",
        "    return train_loss , train_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, train_on_gpu=False):\n",
        "    valid_loss = 0.0\n",
        "    valid_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(dataloader):\n",
        "            # move to GPU\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output,target)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            #ps = torch.exp(output)\n",
        "            #_ , top_class = ps.topk(1,dim = 1)\n",
        "            #_, top_class = torch.max(ps, dim=1)\n",
        "            #equals = top_class == target.view(*top_class.shape) # shape is (batch size x 1)\n",
        "            #valid_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            #print('valid_accuracy {:.6f}'.format(valid_accuracy))\n",
        "            \n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "    return valid_loss, correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBEocBvn2INt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_my_model(n_epochs, loaders, model, optimizer, criterion, scheduler, use_cuda=False):\n",
        "    print('Training started at ', get_time())\n",
        "    \n",
        "    valid_losses = []\n",
        "    train_losses = []\n",
        "    valid_accuracies = []\n",
        "    \n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "         # initialize variables to monitor training and validation loss\n",
        "        training_loss = 0.0\n",
        "        training_accuracy = 0.0\n",
        "    \n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        training_loss, training_accuracy = train_epoch(model, loaders[0], criterion, optimizer, use_cuda)\n",
        "    \n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        validation_loss, validation_accuracy = validate_epoch(model, loaders[1], criterion, use_cuda) #validation_accuracy\n",
        "        \n",
        "        #if scheduler is not None:\n",
        "          #scheduler.step(validation_loss)\n",
        "        \n",
        "        ###### print training/validation statistics \n",
        "        # calculate the average loss per epoch\n",
        "        training_loss = training_loss/len_trainloader\n",
        "        train_losses.append(training_loss)\n",
        "        #temp_n1 = loaders[0].get()\n",
        "        #print('temp_n1 {}; shape: {}'.format(temp_n1, temp_n1.shape))\n",
        "        training_accuracy = training_accuracy/len_trainloader\n",
        "\n",
        "        validation_loss = validation_loss/len_validloader\n",
        "        valid_losses.append(validation_loss)\n",
        "        #temp_n = loaders[1]\n",
        "        \n",
        "        validation_accuracy = validation_accuracy/len_validloader\n",
        "        valid_accuracies.append(validation_accuracy)\n",
        "        \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.6f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  training_loss,\n",
        "                  #training_accuracy, \n",
        "                  validation_loss,\n",
        "                  validation_accuracy ))\n",
        "        \n",
        "        ###### TODO: save the model if validation loss has decreased\n",
        "        if validation_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased by {:.6f}'.format(validation_loss - valid_loss_min))\n",
        "            #torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = validation_loss\n",
        "            \n",
        "            \n",
        "    ##### visualize\n",
        "    plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCLPYO82KSA",
        "colab_type": "text"
      },
      "source": [
        "### Execute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXrWb7vbPjFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create workers, \n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "ada = sy.VirtualWorker(hook, 'ada')\n",
        "bob = sy.VirtualWorker(hook, 'bob')\n",
        "cyd = sy.VirtualWorker(hook, 'cyd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sif7E44LLnv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4589adb0-346f-48b0-a8bc-9989d4741fd9"
      },
      "source": [
        "# Create the data loaders, federated PySyft loader\n",
        "datasets.ImageFolder.federate = get_federated_dataset\n",
        "\n",
        "trainset, validset, _ = get_datasets()\n",
        "\n",
        "fed_train_loader = sy.FederatedDataLoader(trainset.federate((ada, bob, cyd)),\n",
        "                                          batch_size=32, shuffle=True)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=True, num_workers=4)\n",
        "#test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)\n",
        "  \n",
        "\n",
        "print(fed_train_loader.workers)\n",
        "\n",
        "len_trainloader = len(fed_train_loader)\n",
        "len_validloader = len(valid_loader)\n",
        "print(len_trainloader)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "returning datasets\n",
            "get_federated_dataset â€¦\n",
            "dataset_federate Done!\n",
            "['ada', 'bob', 'cyd']\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mteRI8pXBnlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b590916-c8b8-4f8f-9501-8b493f08ea9c"
      },
      "source": [
        "# for testing\n",
        "data, labels = next(iter(fed_train_loader))\n",
        "print(data)\n",
        "\n",
        "print(f'objects of ada= {len(ada._objects)}, bob= {len(bob._objects)}, cyd= {len(cyd._objects)}')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Wrapper)>[PointerTensor | me:23753482628 -> ada:64476506707]\n",
            "objects of ada= 4, bob= 2, cyd= 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfPMF2JZ05r",
        "colab_type": "text"
      },
      "source": [
        "## Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P6WWu0nNxny",
        "colab_type": "code",
        "outputId": "89bf3908-0d23-436b-9ded-3fe6893cd340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(f'objects of ada= {len(ada._objects)}, bob= {len(bob._objects)}, cyd= {len(cyd._objects)}')\n",
        "#print(device)\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = MyNet()\n",
        "model.apply(weights_init_normal)\n",
        "\n",
        "n_epochs = 20\n",
        "lr = 0.05\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr) # TODO momentum is not supported at the moment\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 4)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [5, 10, 14], 0.1)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "#model.to(device)\n",
        "print('')\n",
        "loaders = [fed_train_loader, valid_loader]\n",
        "\n",
        "trained_model = train_my_model(n_epochs, loaders, model, optimizer, criterion, scheduler)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "objects of ada= 15, bob= 2, cyd= 2\n",
            "\n",
            "Training started at  (22, 28, 50)\n",
            "x torch.Size([32, 3, 128, 128]), size 0\n",
            "in torch.Size([32, 16, 64, 64])\n",
            "max_pool2d torch.Size([32, 16, 32, 32])\n",
            "conv2 torch.Size([32, 32, 16, 16])\n",
            "max_pool2d torch.Size([32, 32, 8, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft-Bc/syft/frameworks/torch/hook/hook.py:764: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x torch.Size([32, 3, 128, 128]), size 0\n",
            "in torch.Size([32, 16, 64, 64])\n",
            "max_pool2d torch.Size([32, 16, 32, 32])\n",
            "conv2 torch.Size([32, 32, 16, 16])\n",
            "max_pool2d torch.Size([32, 32, 8, 8])\n",
            "x torch.Size([32, 3, 128, 128]), size 0\n",
            "in torch.Size([32, 16, 64, 64])\n",
            "max_pool2d torch.Size([32, 16, 32, 32])\n",
            "conv2 torch.Size([32, 32, 16, 16])\n",
            "max_pool2d torch.Size([32, 32, 8, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n",
            "    obj = _ForkingPickler.dumps(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
            "    cls(buf, protocol).dump(obj)\n",
            "_pickle.PicklingError: Can't pickle <class 'syft.frameworks.torch.tensors.interpreters.native.Tensor'>: attribute lookup Tensor on syft.frameworks.torch.tensors.interpreters.native failed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c01d45bab425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfed_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_my_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-abc1ecefbf5e>\u001b[0m in \u001b[0;36mtrain_my_model\u001b[0;34m(n_epochs, loaders, model, optimizer, criterion, scheduler, use_cuda)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# validate the model #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#validation_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#if scheduler is not None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-593ecef3016a>\u001b[0m in \u001b[0;36mvalidate_epoch\u001b[0;34m(model, dataloader, criterion, train_on_gpu)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;31m# move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NToncEuLt-ns",
        "colab_type": "text"
      },
      "source": [
        "### Clear the worker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1G7HggpsFE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b84b586-01a3-4541-83d7-0c0a7eab2da4"
      },
      "source": [
        "ada.clear_objects()\n",
        "bob.clear_objects()\n",
        "cyd.clear_objects()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:cyd #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJqOjhLI0gA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "fc_in = model.classifier.in_features\n",
        "\n",
        "transferclassifier = nn.Sequential(\n",
        "                        nn.BatchNorm1d(fc_in),\n",
        "                        nn.Linear(fc_in, 102)\n",
        "                        )\n",
        "\n",
        "#model.fc = transferclassifier # resnet\n",
        "model.classifier = transferclassifier'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}