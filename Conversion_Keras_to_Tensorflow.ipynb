{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conversion Keras to Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/Conversion_Keras_to_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5UsoUwzfOHm",
        "colab_type": "code",
        "outputId": "d1f8cccd-a4a4-4551-eefe-6280cacf3547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5cKB43ie2HV",
        "colab_type": "code",
        "outputId": "d069dac3-896c-483b-8c00-083d5e0b6193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Copyright (c) 2019, by the Authors: Amir H. Abdi\n",
        "This script is freely available under the MIT Public License.\n",
        "Please see the License file in the root for details.\n",
        "\n",
        "The following code snippet will convert the keras model files\n",
        "to the freezed .pb tensorflow weight file. The resultant TensorFlow model\n",
        "holds both the model architecture and its associated weights.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_util\n",
        "from tensorflow.python.framework import graph_io\n",
        "from pathlib import Path\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import model_from_json, model_from_yaml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ074AVDfsPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "base_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/' \n",
        "# ./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/keras-fer-bc.hdf5\n",
        "hdf5_name = 'fer2013/keras-fer-bc.hdf5'\n",
        "path_to_input_model = base_path + hdf5_name\n",
        "export_path_pb = base_path + \"keras-fer-bc.pb\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgTkoxXiiM0j",
        "colab_type": "code",
        "outputId": "ff16a65f-0c53-4e6b-e41e-626f4c6ec615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "K.set_learning_phase(0)\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "flags.DEFINE_string('input_model', path_to_input_model, 'Path to the input model.') # \n",
        "flags.DEFINE_string('input_model_json', None, 'Path to the input model architecture in json format.' ) # \n",
        "flags.DEFINE_string('input_model_yaml', None, 'Path to the input model architecture in yaml format.') # \n",
        "flags.DEFINE_string('output_model', export_path_pb, 'Path where the converted model will be stored.')\n",
        "\n",
        "flags.DEFINE_boolean('save_graph_def', True,\n",
        "                     'Whether to save the graphdef.pbtxt file which contains '\n",
        "                     'the graph definition in ASCII format.')\n",
        "    \n",
        "flags.DEFINE_string('output_nodes_prefix', 'node',\n",
        "                    'If set, the output nodes will be renamed to '\n",
        "                    '`output_nodes_prefix`+i, where `i` will numerate the '\n",
        "                    'number of of output nodes of the network.')\n",
        "      \n",
        "flags.DEFINE_boolean('quantize', False,\n",
        "                     'If set, the resultant TensorFlow graph weights will be '\n",
        "                     'converted from float into eight-bit equivalents. See '\n",
        "                     'documentation here: '\n",
        "                     'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms')\n",
        "        \n",
        "flags.DEFINE_boolean('channels_first', False,\n",
        "                     'Whether channels are the first dimension of a tensor. '\n",
        "                     'The default is TensorFlow behaviour where channels are '\n",
        "                     'the last dimension.')\n",
        "flags.DEFINE_boolean('output_meta_ckpt', False,\n",
        "                     'If set to True, exports the model as .meta, .index, and '\n",
        "                     '.data files, with a checkpoint file. These can be later '\n",
        "                     'loaded in TensorFlow to continue training.')\n",
        "\n",
        "flags.mark_flag_as_required('input_model')\n",
        "flags.mark_flag_as_required('output_model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DuplicateFlagError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6dfc09a563f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_input_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Path to the input model.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_model_json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Path to the input model architecture in json format.'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_model_yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Path to the input model architecture in yaml format.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[0;34m(name, default, help, flag_values, **args)\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m   \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \"\"\"\n\u001b[1;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[0;32m---> 82\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'input_model' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Path to the input model."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ublgIFj6ewqc",
        "colab_type": "code",
        "outputId": "030c7124-c68f-48f8-b8bd-998f248b2516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_model(input_model_path, input_json_path=None, input_yaml_path=None):\n",
        "    if not Path(input_model_path).exists():\n",
        "        raise FileNotFoundError(\n",
        "            'Model file `{}` does not exist.'.format(input_model_path))\n",
        "    try:\n",
        "        model = keras.models.load_model(input_model_path)\n",
        "        return model\n",
        "    except FileNotFoundError as err:\n",
        "        logging.error('Input mode file (%s) does not exist.', FLAGS.input_model)\n",
        "        raise err\n",
        "    except ValueError as wrong_file_err:\n",
        "        if input_json_path:\n",
        "            if not Path(input_json_path).exists():\n",
        "                raise FileNotFoundError(\n",
        "                    'Model description json file `{}` does not exist.'.format(\n",
        "                        input_json_path))\n",
        "            try:\n",
        "                model = model_from_json(open(str(input_json_path)).read())\n",
        "                model.load_weights(input_model_path)\n",
        "                return model\n",
        "            except Exception as err:\n",
        "                logging.error(\"Couldn't load model from json.\")\n",
        "                raise err\n",
        "        elif input_yaml_path:\n",
        "            if not Path(input_yaml_path).exists():\n",
        "                raise FileNotFoundError(\n",
        "                    'Model description yaml file `{}` does not exist.'.format(\n",
        "                        input_yaml_path))\n",
        "            try:\n",
        "                model = model_from_yaml(open(str(input_yaml_path)).read())\n",
        "                model.load_weights(input_model_path)\n",
        "                return model\n",
        "            except Exception as err:\n",
        "                logging.error(\"Couldn't load model from yaml.\")\n",
        "                raise err\n",
        "        else:\n",
        "            logging.error(\n",
        "                'Input file specified only holds the weights, and not '\n",
        "                'the model definition. Save the model using '\n",
        "                'model.save(filename.h5) which will contain the network '\n",
        "                'architecture as well as its weights. '\n",
        "                'If the model is saved using the '\n",
        "                'model.save_weights(filename) function, either '\n",
        "                'input_model_json or input_model_yaml flags should be set to '\n",
        "                'to import the network architecture prior to loading the '\n",
        "                'weights. \\n'\n",
        "                'Check the keras documentation for more details '\n",
        "                '(https://keras.io/getting-started/faq/)')\n",
        "            raise wrong_file_err\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # If output_model path is relative and in cwd, make it absolute from root\n",
        "    output_model = FLAGS.output_model\n",
        "    if str(Path(output_model).parent) == '.':\n",
        "        output_model = str((Path.cwd() / output_model))\n",
        "\n",
        "    output_fld = Path(output_model).parent\n",
        "    output_model_name = Path(output_model).name\n",
        "    output_model_stem = Path(output_model).stem\n",
        "    output_model_pbtxt_name = output_model_stem + '.pbtxt'\n",
        "\n",
        "    # Create output directory if it does not exist\n",
        "    Path(output_model).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if FLAGS.channels_first:\n",
        "        K.set_image_data_format('channels_first')\n",
        "    else:\n",
        "        K.set_image_data_format('channels_last')\n",
        "\n",
        "    model = load_model(FLAGS.input_model, FLAGS.input_model_json, FLAGS.input_model_yaml)\n",
        "\n",
        "    # TODO(amirabdi): Support networks with multiple inputs\n",
        "    orig_output_node_names = [node.op.name for node in model.outputs]\n",
        "    if FLAGS.output_nodes_prefix:\n",
        "        num_output = len(orig_output_node_names)\n",
        "        pred = [None] * num_output\n",
        "        converted_output_node_names = [None] * num_output\n",
        "\n",
        "        # Create dummy tf nodes to rename output\n",
        "        for i in range(num_output):\n",
        "            converted_output_node_names[i] = '{}{}'.format(\n",
        "                FLAGS.output_nodes_prefix, i)\n",
        "            pred[i] = tf.identity(model.outputs[i],\n",
        "                                  name=converted_output_node_names[i])\n",
        "    else:\n",
        "        converted_output_node_names = orig_output_node_names\n",
        "    logging.info('Converted output node names are: %s',\n",
        "                 str(converted_output_node_names))\n",
        "\n",
        "    sess = K.get_session()\n",
        "    if FLAGS.output_meta_ckpt:\n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, str(output_fld / output_model_stem))\n",
        "\n",
        "    if FLAGS.save_graph_def:\n",
        "        tf.train.write_graph(sess.graph.as_graph_def(), str(output_fld),\n",
        "                             output_model_pbtxt_name, as_text=True)\n",
        "        logging.info('Saved the graph definition in ascii format at %s',\n",
        "                     str(Path(output_fld) / output_model_pbtxt_name))\n",
        "\n",
        "    if FLAGS.quantize:\n",
        "        from tensorflow.tools.graph_transforms import TransformGraph\n",
        "        transforms = [\"quantize_weights\", \"quantize_nodes\"]\n",
        "        transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [],\n",
        "                                               converted_output_node_names,\n",
        "                                               transforms)\n",
        "        constant_graph = graph_util.convert_variables_to_constants(\n",
        "            sess,\n",
        "            transformed_graph_def,\n",
        "            converted_output_node_names)\n",
        "    else:\n",
        "        constant_graph = graph_util.convert_variables_to_constants(\n",
        "            sess,\n",
        "            sess.graph.as_graph_def(),\n",
        "            converted_output_node_names)\n",
        "\n",
        "    graph_io.write_graph(constant_graph, str(output_fld), output_model_name,\n",
        "                         as_text=False)\n",
        "    logging.info('Saved the freezed graph at %s',\n",
        "                 str(Path(output_fld) / output_model_name))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(main)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FATAL Flags parsing error: Unknown command line flag 'f'\n",
            "Pass --helpshort or --helpfull to see help on flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}