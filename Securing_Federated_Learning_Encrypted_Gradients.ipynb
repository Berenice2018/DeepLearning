{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Securing Federated Learning Encrypted Gradients.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/Securing_Federated_Learning_Encrypted_Gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWEFB2dxZ-1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nnYP_9qFBLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as th\n",
        "import syft as sy\n",
        "\n",
        "from torch import nn, optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JriK14HHFBLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class virtual_worker:\n",
        "    \n",
        "    def __init__(self, hook, name, data, target, lr=0.1, epochs=3):\n",
        "        self.worker = sy.VirtualWorker(hook, name) #create worker\n",
        "        self.epochs = epochs\n",
        "        self.name = name\n",
        "        self.model = nn.Linear(data.shape[1], 1) # worker's own model\n",
        "        self.optim = optim.SGD(self.model.parameters(), lr=lr) # worker's own optim\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "    \n",
        "    def send_data(self): # send train, weights & target to virtual worker\n",
        "        \n",
        "        self.data_ptr = self.data.send(self.worker)\n",
        "        self.target_ptr = self.target.send(self.worker) \n",
        "        self.model = self.model.send(self.worker) #send model to remote worker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygAEhk8qe0Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class federated_model:\n",
        "\n",
        "    def __init__(self, hook, weight_dims, remote_workers):\n",
        "        \n",
        "        self.remote_workers = remote_workers\n",
        "        self.secure_worker = sy.VirtualWorker(hook, \"secure_worker\")\n",
        "        self.model = nn.Linear(data.shape[1],1)\n",
        "        #self.weights_dims = weight_dims\n",
        "        self.remote_weights = []\n",
        "        self.remote_biases = []\n",
        "\n",
        "\n",
        "    def get_gradients(self): \n",
        "      \n",
        "        weights_data = th.stack([ptr for ptr in self.remote_weights]).get().child.child.float().mean(dim=0)\n",
        "        bias_data = th.stack([ptr for ptr in self.remote_biases]).get().child.child.float().mean()\n",
        "       \n",
        "        #copy weights_data and bias_data into secure model's weights and biases\n",
        "        with th.no_grad():\n",
        "            self.model.weight.set_(weights_data)\n",
        "            self.model.bias.set_(bias_data)\n",
        "\n",
        "        #for debugging: get loss of secure worker's model. Just a simple forward pass\n",
        "        data = self.remote_workers[-1].data\n",
        "        labels = self.remote_workers[-1].target\n",
        "        \n",
        "        predictions = self.model(data)\n",
        "        loss = ((predictions - labels)**2).sum()\n",
        "        print(\"\\n\\tloss of secure worker = {:.6f}\".format(loss))\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "    def train(self): # training func for remote workers\n",
        "        #train each remote worker with their models\n",
        "        weights = []\n",
        "        \n",
        "        for worker_obj in self.remote_workers: \n",
        "            worker_name = worker_obj.name\n",
        "            worker_epochs = worker_obj.epochs\n",
        "           \n",
        "            print(\"*\"*30)\n",
        "            print(\"\\n\\ttraining Model On Worker {}\\n\".format(worker_name.title()))\n",
        "            \n",
        "            for epoch in range(worker_epochs):\n",
        "\n",
        "                print(\"\\nepoch : {}/{}\".format(epoch, worker_epochs))\n",
        "                worker_obj.optim.zero_grad()\n",
        "                \n",
        "                preds_ptr = worker_obj.model(worker_obj.data_ptr) # forward pass\n",
        "                loss_ptr = ((preds_ptr - worker_obj.target_ptr)**2).sum() #  loss value\n",
        "                loss_ptr.backward()\n",
        "                \n",
        "                worker_obj.optim.step()\n",
        "                \n",
        "                loss_value = loss_ptr.get()\n",
        "                print(\"raw loss : {:.6f}\".format(loss_value))\n",
        "        \n",
        "        \n",
        "        # encrypt weights and biases before sending to secure worker\n",
        "        for worker_obj_index, worker_obj in enumerate(self.remote_workers):\n",
        "\n",
        "            print(\"\\n\\tEncrypting weights and biases of worker : {}\".format(worker_obj.name.title()))\n",
        "          \n",
        "            weights = worker_obj.model.weight.get()\n",
        "            weights_enc = weights.fix_prec()\n",
        "            bias = worker_obj.model.bias.get()\n",
        "            bias_enc = bias.fix_prec()\n",
        "            \n",
        "            #share the weights and biases of this worker with all other remote workers and secure worker\n",
        "            weights_ptr = weights_enc.share(self.remote_workers[0].worker,\n",
        "                                  self.remote_workers[1].worker,\n",
        "                                  self.remote_workers[2].worker,\n",
        "                                  self.secure_worker)\n",
        "            \n",
        "            bias_ptr = bias_enc.share(self.remote_workers[0].worker,\n",
        "                                  self.remote_workers[1].worker,\n",
        "                                  self.remote_workers[2].worker,\n",
        "                                  self.secure_worker)\n",
        "                        \n",
        "            self.remote_weights.append(weights_ptr)\n",
        "            self.remote_biases.append(bias_ptr)\n",
        "        \n",
        "        self.get_gradients() # accumulate all gradients\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQIN8cImdjnM",
        "colab_type": "text"
      },
      "source": [
        "### Mock dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9fc2YT6FBLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = 1\n",
        "features = 2\n",
        "\n",
        "target=th.rand(samples,1)\n",
        "data=th.rand(samples, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heiEsfqzFBLP",
        "colab_type": "text"
      },
      "source": [
        "###  workers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "941wvr3-FBLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a59159d7-c05c-4f79-aca5-47eb89ed44ce"
      },
      "source": [
        "hook=sy.TorchHook(th)\n",
        "\n",
        "worker_names=[\"ada\",\"bob\",\"cyd\"]\n",
        "\n",
        "workers=[]\n",
        "\n",
        "for name in worker_names:    \n",
        "    worker_obj=virtual_worker(hook,name,data,target)\n",
        "    worker_obj.send_data()\n",
        "    workers.append(worker_obj)\n",
        "    \n",
        "print(len(workers))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 21:28:06.355416 140295094265728 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w-CmkVYeAM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instatiate and start training\n",
        "\n",
        "federated_model(hook, features, workers).train()        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}