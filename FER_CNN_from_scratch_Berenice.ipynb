{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER CNN from scratch Berenice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "OwJzTTM1pe-s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berenice2018/DeepLearning/blob/master/FER_CNN_from_scratch_Berenice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV5Lz9WppDsP",
        "colab_type": "code",
        "outputId": "68338086-d9a8-49e7-bfea-f6e10feec9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os, cv2\n",
        "import pandas as pd\n",
        "#from pylab import rcParams\n",
        "#rcParams['figure.figsize'] = 20, 10\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpSbHOBSpRDR",
        "colab_type": "code",
        "outputId": "e8a67945-3572-4db2-9acd-c8baa484d10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwJzTTM1pe-s",
        "colab_type": "text"
      },
      "source": [
        "### Convert and save images to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RpGjhIHpdXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*-coding: utf-8-*-\n",
        "\n",
        "#!pip install mxnet\n",
        "\n",
        "__author__ = 'Moonkie'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "curdir = os.path.abspath(os.path.dirname(fer))\n",
        "\n",
        "def gen_record(csvfile,channel):\n",
        "    data = pd.read_csv(csvfile,delimiter=',',dtype='a')\n",
        "    labels = np.array(data['emotion'],np.float)\n",
        "    # print(labels,'\\n',data['emotion'])\n",
        "        \n",
        "    imagebuffer = np.array(data['pixels'])\n",
        "    images = np.array([np.fromstring(image,np.uint8,sep=' ') for image in imagebuffer])\n",
        "    del imagebuffer\n",
        "    num_shape = int(np.sqrt(images.shape[-1]))\n",
        "    images.shape = (images.shape[0],num_shape,num_shape)\n",
        "    # img=images[0];cv2.imshow('test',img);cv2.waitKey(0);cv2.destroyAllWindow();exit()\n",
        "    dirs = set(data['Usage'])\n",
        "    subdirs = set(labels)\n",
        "    class_dir = {}\n",
        "    for dr in dirs:\n",
        "        dest = os.path.join(curdir,dr)\n",
        "        class_dir[dr] = dest\n",
        "        if not os.path.exists(dest):\n",
        "            os.mkdir(dest)\n",
        "            \n",
        "    data = zip(labels,images,data['Usage'])\n",
        "    \n",
        "    for d in data:\n",
        "        destdir = os.path.join(class_dir[d[-1]],str(int(d[0])))\n",
        "        if not os.path.exists(destdir):\n",
        "            os.mkdir(destdir)\n",
        "        img = d[1]\n",
        "        filepath = unique_name(destdir,d[-1])\n",
        "        print('[^_^] Write image to %s' % filepath)\n",
        "        if not filepath:\n",
        "            continue\n",
        "        sig = cv2.imwrite(filepath,img)\n",
        "        if not sig:\n",
        "            print('Error')\n",
        "            exit(-1)\n",
        "\n",
        "\n",
        "def unique_name(pardir,prefix,suffix='jpg'):\n",
        "    filename = '{0}_{1}.{2}'.format(prefix,random.randint(1,10**8),suffix)\n",
        "    filepath = os.path.join(pardir,filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        return filepath\n",
        "    unique_name(pardir,prefix,suffix)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    filename = 'fer2013.csv'\n",
        "    filename = os.path.join(curdir,filename)\n",
        "    gen_record(filename,1)\n",
        "    \n",
        "    # ##################### test\n",
        "    # tmp = unique_name('./Training','Training')\n",
        "    # print(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd_klMuOpmWR",
        "colab_type": "text"
      },
      "source": [
        "### Load data , image transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC-QCr7SpVvS",
        "colab_type": "code",
        "outputId": "176b341d-f1e7-48bc-dd9b-001ad8e0d193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fer= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/fer2013.csv\"\n",
        "ferr= \"./gdrive/My Drive/Colab Notebooks/Fer-dataset\"\n",
        "\n",
        "!ls   '/content/gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013/'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.bib  fer2013.csv  PrivateTest  PublicTest  README  Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of9aDCc8pqY9",
        "colab_type": "code",
        "outputId": "50048459-da20-41e4-f1b2-50de4f1b97d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_dir = \"./gdrive/My Drive/Colab Notebooks/Fer-dataset/fer2013\"\n",
        "train_dir = data_dir + '/Training'\n",
        "valid_dir = data_dir + '/PublicTest'\n",
        "test_dir = data_dir + '/PrivateTest'\n",
        "\n",
        "# original img size = 48 x48 px\n",
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomResizedCrop(256),\n",
        "        transforms.Resize(256), #320\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,], \n",
        "                             [0.229, ])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        #transforms.CenterCrop(256),\n",
        "        transforms.Resize(256),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        #transforms.CenterCrop(224),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    }\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir,\n",
        "        'test': test_dir}\n",
        "\n",
        "datasets = {x: torchvision.datasets.ImageFolder(dirs[x],   transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=64, shuffle=True, num_workers=7) \n",
        "               for x in ['train', 'valid','test']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) \n",
        "                              for x in ['train', 'valid','test']}\n",
        "print(dataset_sizes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 32556, 'valid': 3589, 'test': 3589}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtTvsEhCpwyu",
        "colab_type": "code",
        "outputId": "d7a2c4c1-07e8-47f6-a43a-12e18f8eee9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_names = datasets['train'].classes\n",
        "print(class_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHGUaFNGpz6L",
        "colab_type": "text"
      },
      "source": [
        "### Show some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw2I5ywip2uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a batch of training images\n",
        "dataiter = iter(dataloaders['train'])\n",
        "images, _ = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy\n",
        "\n",
        "# plot the images of the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 16/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQVxEZpp56a",
        "colab_type": "text"
      },
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSNZ79L2p8bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_time():\n",
        "      hour = datetime.datetime.today().hour +2\n",
        "      minute = datetime.datetime.today().minute\n",
        "      second = datetime.datetime.today().second\n",
        "      return hour, minute, second\n",
        "    \n",
        "    \n",
        "def weights_init_normal(m):\n",
        "  '''Takes in a module and initializes all linear layers with weight\n",
        "     values taken from a normal distribution.'''\n",
        "  classname = m.__class__.__name__\n",
        "  # for every Linear layer in a model\n",
        "  if classname.find('Linear') != -1:\n",
        "      n = m.in_features\n",
        "      # m.weight.data shoud be taken from a normal distribution\n",
        "      m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "      # m.bias.data should be 0\n",
        "      m.bias.data.fill_(0)\n",
        "      \n",
        "      \n",
        "# Visualize plot\n",
        "def plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(14,6), ncols=2)\n",
        "    ax1.plot(valid_losses, label='Validation loss')\n",
        "    ax1.plot(train_losses, label='Training loss')\n",
        "    ax1.legend(frameon=False)\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    #x_ticks = [x for x in range(0,n_epochs,2)]\n",
        "    #plt.xticks(x_ticks)\n",
        "    \n",
        "    ax2.plot(valid_accuracies, label = 'Validation accuracy')\n",
        "    ax2.legend(frameon=False)\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    \n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiK7hITUqQDr",
        "colab_type": "text"
      },
      "source": [
        "### Architecture & train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgT9WO7aqR5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        n = m.in_features\n",
        "        # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0, 1/np.sqrt(n))\n",
        "        # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)\n",
        "        \n",
        "        \n",
        "# normalize each layer:\n",
        "class MyBatchNormLayer(nn.Module):\n",
        "    def __init__(self, input_number, filter_number, stride=2, kernel_size=3, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(input_number, filter_number, kernel_size=kernel_size,\n",
        "                             stride=stride, bias=False, padding=1)\n",
        "        self.normalized = nn.BatchNorm2d(filter_number)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        #print('MyBatchNormLayer x.shape= ', x.shape)\n",
        "        return self.normalized(x)\n",
        "\n",
        "    \n",
        "class ResnetLayer(MyBatchNormLayer):\n",
        "    def forward(self, x): return x + super().forward(x)\n",
        "    \n",
        "    \n",
        "class MyConvBnNet(nn.Module):\n",
        "    def __init__(self, layers, classes_number, dropout=0):\n",
        "        super().__init__()\n",
        "        # define the first convolutional layer manually\n",
        "        self.conv1 = MyBatchNormLayer(3, 64,kernel_size=7, stride=2, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(3,2)\n",
        "        \n",
        "        self.layers1 = nn.ModuleList([MyBatchNormLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
        "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers4 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers5 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers6 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers7 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        self.layers8 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
        "        \n",
        "        #self.linear1 = nn.Linear(layers[-1], 512)\n",
        "        self.outlayer = nn.Linear(layers[-1], classes_number)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        for lyr1 ,lyr2, lyr3, lyr4, lyr5, lyr6 in zip(\n",
        "            self.layers1, self.layers2, self.layers3, self.layers4, self.layers5, self.layers6): \n",
        "            x = lyr4(lyr3(lyr2(lyr1(x))))\n",
        "            x =  lyr6(lyr5(x)) # lyr8(lyr7(lyr6(lyr5(x))))\n",
        "        x = F.adaptive_max_pool2d(x,1)\n",
        "        #print('MyConvBnNet after adaptive_max_pool2d, x.shape=', x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        #x = self.linear1(x)\n",
        "        x = self.outlayer(x)\n",
        "        return F.log_softmax(x, dim= -1)\n",
        "\n",
        "\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('cuda available: ', use_cuda)\n",
        "\n",
        "# instantiate the CNN\n",
        "#model_scratch = MyConvBnNet([10, 20, 40], 133)\n",
        "model_scratch = MyConvBnNet([64, 128, 256, 512, 1024], 7, 0.1)\n",
        "print(model_scratch)\n",
        "\n",
        "model_scratch.apply(weights_init_normal)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()\n",
        "print('model is on cuda: ', next(model_scratch.parameters()).is_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO8eNmEDqmbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, train_on_gpu):\n",
        "    # initialize variables to monitor training and validation loss\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        # move to GPU\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        ## find the loss and update the model parameters accordingly\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # get the loss per batch and accumulate\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        # get the class, highest probability\n",
        "        probabilities = torch.exp(output)\n",
        "        _, top_class = probabilities.topk(1, dim=1)\n",
        "        # The following line is equivalent to the previous (?)\n",
        "        #_, top_class = torch.max(probabilities, dim=1)\n",
        "        \n",
        "        # check if the predicted class is correct\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        # \n",
        "        train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, train_on_gpu):\n",
        "    valid_loss = 0.0\n",
        "    valid_accuracy = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(dataloader):\n",
        "            # move to GPU\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output,target)\n",
        "            \n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            ps = torch.exp(output)\n",
        "            _ , top_class = ps.topk(1,dim = 1)\n",
        "            #_, top_class = torch.max(ps, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape) # shape is (batch size x 1)\n",
        "            valid_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return valid_loss, valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7vq3pCoqsqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, scheduler, use_cuda, save_path):\n",
        "    print('Training started at ', get_time())\n",
        "    \n",
        "    valid_losses = []\n",
        "    train_losses = []\n",
        "    valid_accuracies = []\n",
        "    \n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "         # initialize variables to monitor training and validation loss\n",
        "        training_loss = 0.0\n",
        "        training_accuracy = 0.0\n",
        "    \n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        training_loss, training_accuracy = train_epoch(model, loaders['train'], criterion, optimizer, use_cuda)\n",
        "    \n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        validation_loss, validation_accuracy = validate_epoch(model, loaders['valid'], criterion, use_cuda)\n",
        "        \n",
        "        #if scheduler is not None:\n",
        "          #scheduler.step(validation_loss)\n",
        "        \n",
        "        ###### print training/validation statistics \n",
        "        # calculate the average loss per epoch\n",
        "        training_loss = training_loss/len(loaders['train'])\n",
        "        train_losses.append(training_loss)\n",
        "        \n",
        "        training_accuracy = training_accuracy/len(loaders['train'])\n",
        "        \n",
        "        validation_loss = validation_loss/len(loaders['valid'])\n",
        "        valid_losses.append(validation_loss)\n",
        "        \n",
        "        validation_accuracy = validation_accuracy/len(loaders['valid'])\n",
        "        valid_accuracies.append(validation_accuracy)\n",
        "        \n",
        "        hour, minute, second = get_time()\n",
        "        print('Epoch: {} at {}:{}:{} \\tTrain. Loss: {:.6f} \\tValid. Loss: {:.6f} \\t Accur.: {:.10f}'.format(\n",
        "                  epoch,\n",
        "                  hour, minute, second,\n",
        "                  training_loss,\n",
        "                  #training_accuracy, \n",
        "                  validation_loss,\n",
        "                  validation_accuracy ))\n",
        "        \n",
        "        ###### TODO: save the model if validation loss has decreased\n",
        "        if validation_loss <= valid_loss_min:\n",
        "            '''print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_min,\n",
        "                validation_loss))'''\n",
        "            print('Validation loss decreased by {:.6f}'.format(validation_loss - valid_loss_min))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = validation_loss\n",
        "            \n",
        "            \n",
        "    ##### visualize\n",
        "    plot_loss_acc(n_epochs, train_losses, valid_losses, valid_accuracies)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZE5GhsaQtgD",
        "colab_type": "text"
      },
      "source": [
        "### Hyper params & Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kkR-Ef3qx2B",
        "colab_type": "code",
        "outputId": "93106737-b4aa-4466-fe49-b22ad3d4b7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "source": [
        "\n",
        "epochs = 2\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_scratch = nn.NLLLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "lr= 1e-4\n",
        "#optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=lr)\n",
        "######### change the position of optim.step() in the train section\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_scratch, patience = 3, factor=0.1)\n",
        "\n",
        "scheduler_scratch = optim.lr_scheduler.MultiStepLR(optimizer_scratch, [10, 18, 26, 32], 0.2)\n",
        "stepsize = '10_18_26_32'\n",
        "\n",
        "# create model name\n",
        "save_path = './gdrive/My Drive/Colab Notebooks/Fer-dataset/'\n",
        "modelname = '{}cnn-{}-lr{}-{}{}-epo{}.pt'.format(save_path, 'Adam', lr, 'Multi_', stepsize, epochs)\n",
        "\n",
        "\n",
        "######################################################\n",
        "############ start the training the model#############\n",
        "######################################################\n",
        "\n",
        "print(modelname)\n",
        "\n",
        "#def train(n_epochs, loaders, model, optimizer, criterion, scheduler, use_cuda, save_path):\n",
        "model_scratch = train(epochs, dataloaders, model_scratch, \n",
        "                      optimizer_scratch, criterion_scratch, scheduler_scratch,\n",
        "                      use_cuda, modelname)\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load(modelname))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gdrive/My Drive/Colab Notebooks/Fer-dataset/cnn-Adam-lr0.0001-Multi_10_18_26_32-epo2.pt\n",
            "Training started at  (16, 8, 53)\n",
            "Epoch: 0 at 16:15:14 \tTrain. Loss: 1.814801 \tValid. Loss: 2.318085 \t Accur.: 0.4303728044\n",
            "Validation loss decreased by -inf\n",
            "Epoch: 1 at 16:21:37 \tTrain. Loss: 1.489252 \tValid. Loss: 1.291046 \t Accur.: 0.5194627047\n",
            "Validation loss decreased by -1.027040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAGoCAYAAADVZM+hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlywAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdtJmNd9tU_0",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeubTQlptWyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    print('test started at ', get_time())\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('test finished at ', get_time())\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3J2KYkRtZ-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# call test function    \n",
        "test(dataloaders, model_scratch, criterion_scratch, use_cuda)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}